{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b340499",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /Applications/anaconda3\r\n",
      "phd                   *  /Applications/anaconda3/envs/phd\r\n",
      "\r\n",
      "Python 3.10.0\r\n",
      "/Applications/anaconda3/envs/phd/bin/python\n"
     ]
    }
   ],
   "source": [
    "!conda env list\n",
    "!python -V\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f95399",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table of Contents\n",
    "* [Library](#1)\n",
    "    * [Model Function](#1.1)\n",
    "    * [Inference Code](#1.2)\n",
    "    * [Process Samples](#1.3)\n",
    "    * [Plot](#1.4)\n",
    "* [Murder Mystery](#2)\n",
    "* [Lung](#3)\n",
    "    * [Rejection Sampler](#3.1)\n",
    "    * [Message Passing](#3.2)\n",
    "    * [Gibbs Sampling](#3.3)\n",
    "* [Toy Model](#4)\n",
    "* [Toy Model 2](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75eeb988",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DATA ANALYSIS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "\n",
    "# PLOTS\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# OTHERS\n",
    "import math\n",
    "import statistics as stats\n",
    "import time as t\n",
    "#import pickle\n",
    "import functools as fc # contains reduce\n",
    "\n",
    "# DEBUGGER\n",
    "from IPython.core.debugger import set_trace\n",
    "# For executing line by line use n and \n",
    "# for step into a function use s and \n",
    "# to exit from debugging prompt use c.\n",
    "# REFACTOR: uninstall jupyter packages that I installed before, not using PyCharm built in debugger\n",
    "\n",
    "\n",
    "# import color blind colors\n",
    "colorblind = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "              '#f781bf', '#a65628', '#984ea3',\n",
    "              '#999999', '#e41a1c', '#dede00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a1b6d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Library <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a856d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "%load utils.py\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06171c79",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inference Code <a class=\"anchor\" id=\"1.2\"></a>\n",
    "Creates a *rejection sampler*. Samples from a dist. Rejects the samples that do not match obs, accepts samples that match it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdeb6b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def inferenceCode(modelToRun, processData, obs, obs_label, n_samples = 10000):\n",
    "  \"\"\"\n",
    "  modelToRun: model function name\n",
    "  obs: inference query dict\n",
    "  obs_label: observation label for graph\n",
    "  \"\"\"\n",
    "    samples = []\n",
    "    n_iter = 0\n",
    "\n",
    "    # create joint samples\n",
    "    while len(samples) < n_samples:\n",
    "        sample = modelToRun()\n",
    "        n_match = 0\n",
    "        n_iter += 1\n",
    "        # check how many keys in common\n",
    "        for key in obs.keys():\n",
    "            if sample[key] == obs[key]:\n",
    "                n_match += 1\n",
    "        # save sample if all key match\n",
    "        if n_match == len(obs): samples.append(sample)\n",
    "    print(n_iter,'iterations performed to get', n_samples, 'samples matching the following inference query:', obs)\n",
    "\n",
    "    # process data\n",
    "    cleanedData = processData(samples, obs_label)\n",
    "    return cleanedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e95257",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Process samples <a class=\"anchor\" id=\"1.3\"></a>\n",
    "The samples are processed to compute the probability of the analysed event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3235a8ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def processData(samples, obs_label):\n",
    "  \"\"\"\n",
    "  obs_label: observation label\n",
    "  \"\"\"\n",
    "\n",
    "    # find the first key of a sample\n",
    "    first_key = next(iter(samples[0]))\n",
    "    \n",
    "    m = []\n",
    "    for sample in samples:\n",
    "        m.append(sample[first_key])\n",
    "    \n",
    "    # create data frame with output\n",
    "    df = pd.Series(m, name = 'Count').value_counts()\n",
    "\n",
    "    df = df.reset_index().rename(columns={'index':first_key})\n",
    "    # normalise counts to [0,1]\n",
    "    df[\"P(\" + first_key + \")\"] = df[\"Count\"].apply(lambda x: x/df[\"Count\"].sum())\n",
    "    # add category \n",
    "    df['Label'] = obs_label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51304ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot <a class=\"anchor\" id=\"1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fdd1e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plotFigure(df, name=\"Label\", column=0, title=\"Probability for various inference queries\", height=400, width=700):\n",
    "    # The first column of the df should have the event name\n",
    "    event = df.columns[column]\n",
    "    fig = px.bar(df,\n",
    "                 x=name,\n",
    "                 y=\"P(\" + event + \")\",\n",
    "                 color=event,\n",
    "                 #barmode=\"group\",\n",
    "                 title=title,\n",
    "                 width=width,\n",
    "                 height=height)\n",
    "    fig.update_layout(\n",
    "        font_color=\"black\",\n",
    "        font_size=9,\n",
    "        title_font_size=14\n",
    "    )\n",
    "    return fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf876da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Murder Mystery <a class=\"anchor\" id=\"2\"></a>\n",
    "The model outputs three variables\n",
    "- `murderer`: Grey or Auburn\n",
    "- `weapon`: revolver or dagger\n",
    "- `hair`: true or false\n",
    "\n",
    "The probability of success for the Benoulli trial for the variables `weapon` and `hair` are conditionnaly dependent on the outcome of `murderer`\n",
    "\n",
    "Definitions:\n",
    "- random variate: particular outcome of a random variable\n",
    "\n",
    "Functions:\n",
    "- `bernoulli.rvs(p)`: generates a random variates for a randome variable following a Bernoulli distribution of probability p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34b855d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'murderer': 'Auburn', 'weapon': 'dagger', 'hair': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Function\n",
    "def murderMysteryModel():\n",
    "    murderer = nStatesSample([0.7, 0.3], [\"Auburn\", \"Grey\"]) # testing nStatesSamples\n",
    "    revolver_p = {\n",
    "        \"Grey\": 0.9,\n",
    "        \"Auburn\": 0.2\n",
    "    }\n",
    "    weapon = bernoulliSample(revolver_p.get(murderer), \"revolver\", \"dagger\")\n",
    "    hair_p = {\n",
    "        \"Grey\": 0.5,\n",
    "        \"Auburn\": 0.05\n",
    "    }\n",
    "    hair = bernoulliSample(hair_p.get(murderer), True, False)\n",
    "    return {\n",
    "        \"murderer\" : murderer,\n",
    "        \"weapon\" : weapon,\n",
    "        \"hair\" : hair\n",
    "    }\n",
    "# 1 sample for the murder mystery model\n",
    "murderMysteryModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1885d10",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 iterations performed to get 10000 samples matching the following inference query: {}\n",
      "24456 iterations performed to get 10000 samples matching the following inference query: {'weapon': 'revolver'}\n",
      "54673 iterations performed to get 10000 samples matching the following inference query: {'hair': True}\n",
      "70845 iterations performed to get 10000 samples matching the following inference query: {'weapon': 'revolver', 'hair': True}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>murderer</th>\n",
       "      <th>Count</th>\n",
       "      <th>P(murderer)</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>7013</td>\n",
       "      <td>0.7013</td>\n",
       "      <td>Prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grey</td>\n",
       "      <td>2987</td>\n",
       "      <td>0.2987</td>\n",
       "      <td>Prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grey</td>\n",
       "      <td>6623</td>\n",
       "      <td>0.6623</td>\n",
       "      <td>After observing weapon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>3377</td>\n",
       "      <td>0.3377</td>\n",
       "      <td>After observing weapon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grey</td>\n",
       "      <td>8009</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>After observing hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>After observing hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grey</td>\n",
       "      <td>9529</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>After observing weapon and hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>471</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>After observing weapon and hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  murderer  Count  P(murderer)                            Label\n",
       "0   Auburn   7013       0.7013                            Prior\n",
       "1     Grey   2987       0.2987                            Prior\n",
       "0     Grey   6623       0.6623           After observing weapon\n",
       "1   Auburn   3377       0.3377           After observing weapon\n",
       "0     Grey   8009       0.8009             After observing hair\n",
       "1   Auburn   1991       0.1991             After observing hair\n",
       "0     Grey   9529       0.9529  After observing weapon and hair\n",
       "1   Auburn    471       0.0471  After observing weapon and hair"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rejection sampler for 4 observations\n",
    "m = inferenceCode(murderMysteryModel,\n",
    "                  processData,\n",
    "                  {}, \n",
    "                  'Prior')\n",
    "mw = inferenceCode(murderMysteryModel,\n",
    "                  processData,\n",
    "                  {'weapon': 'revolver'}, \n",
    "                   'After observing weapon')\n",
    "mh = inferenceCode(murderMysteryModel,\n",
    "                  processData,\n",
    "                  {'hair': True}, \n",
    "                   'After observing hair')\n",
    "mwh = inferenceCode(murderMysteryModel,\n",
    "                  processData,\n",
    "                  {'weapon': 'revolver', 'hair': True}, \n",
    "                   'After observing weapon and hair')\n",
    "# concatenate\n",
    "murderers = pd.concat([m, mw, mh, mwh])\n",
    "murderers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed60ac1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotFigure' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Plot results\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mplotFigure\u001B[49m(murderers)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plotFigure' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot results\n",
    "plotFigure(murderers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f1372e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10,5))\n",
    "sns.set_theme(style=\"darkgrid\",palette=\"colorblind\")\n",
    "sns.barplot(x=\"Label\", \n",
    "            y=\"P(murderer)\", \n",
    "            hue=\"murderer\", \n",
    "            data=murderers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d229b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lung <a class=\"anchor\" id=\"3\"></a>\n",
    "### Rejection sampler <a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9c3914",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lungModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zq/v2r6yn111s3gpdf8lzf72xvw0000gn/T/ipykernel_39638/269014.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0;34m\"FEV1\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mFEV1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     }\n\u001B[0;32m---> 34\u001B[0;31m \u001B[0mlungModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'lungModel' is not defined"
     ]
    }
   ],
   "source": [
    "# Lung Function Model\n",
    "def continuousLungModel():\n",
    "    inflammation = utils.threeStatesSample([0.3, 0.5, 0.2], [\"absent\", \"small\", \"heavy\"])\n",
    "    \n",
    "    wellness_p = {\n",
    "        \"absent\": [0.01, 0.09, 0.2, 0.3, 0.5],\n",
    "        \"small\": [0.2, 0.3, 0.3, 0.1, 0.1],\n",
    "        \"heavy\": [0.4, 0.3, 0.15, 0.1, 0.05]\n",
    "    }\n",
    "    wellness = utils.nStatesSample(wellness_p.get(inflammation), [1, 2, 3, 4, 5])\n",
    "    \n",
    "    bacterial_load_p = {\n",
    "        \"absent\": [0.6, 0.3, 0.1],\n",
    "        \"small\": [0.3, 0.3, 0.4],\n",
    "        \"heavy\": [0.1, 0.3, 0.6]\n",
    "    }\n",
    "    bacterial_load = utils.threeStatesSample(bacterial_load_p.get(inflammation), [\"low\", \"medium\", \"high\"])\n",
    "    \n",
    "    FEV1_p = {\n",
    "        \"low\": [90, 10],\n",
    "        \"medium\": [70, 20] ,\n",
    "        \"high\": [60, 20]\n",
    "    }\n",
    "    \n",
    "    nDecimals=2 # precision of the real world data from the spirometer\n",
    "    FEV1 = utils.gaussianSample(FEV1_p.get(bacterial_load), nDecimals)\n",
    "    \n",
    "    return {\n",
    "        \"Inflammation\": inflammation,\n",
    "        \"Wellness\": wellness,\n",
    "        \"Bacterial load\": bacterial_load,\n",
    "        \"FEV1\": FEV1\n",
    "    }\n",
    "lungModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96b4c831",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3392 iterations performed to get 1000 samples matching the following inference query: {'Bacterial load': 'medium'}\n",
      "in 0.03s\n",
      "18344 iterations performed to get 1000 samples matching the following inference query: {'Bacterial load': 'medium', 'Wellness': 5}\n",
      "in 0.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zq/v2r6yn111s3gpdf8lzf72xvw0000gn/T/ipykernel_39638/419270342.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mt2\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"in \"\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt2\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m\"s\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m df3 = inferenceCode(continuousLungModel, processData, \n\u001B[0m\u001B[1;32m     14\u001B[0m               \u001B[0;34m{\u001B[0m\u001B[0;34m'FEV1'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m85.23\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m               'After observing FEV1',  n_samples=1000)\n",
      "\u001B[0;32m/var/folders/zq/v2r6yn111s3gpdf8lzf72xvw0000gn/T/ipykernel_39638/3988431443.py\u001B[0m in \u001B[0;36minferenceCode\u001B[0;34m(modelToRun, processData, obs, obs_label, n_samples)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;31m# create joint samples\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mwhile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0msample\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodelToRun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m         \u001B[0mn_match\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mn_iter\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zq/v2r6yn111s3gpdf8lzf72xvw0000gn/T/ipykernel_39638/269014.py\u001B[0m in \u001B[0;36mcontinuousLungModel\u001B[0;34m()\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0mnDecimals\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m \u001B[0;31m# precision of the real world data from the spirometer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0mFEV1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgaussianSample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mFEV1_p\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbacterial_load\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnDecimals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     return {\n",
      "\u001B[0;32m/var/folders/zq/v2r6yn111s3gpdf8lzf72xvw0000gn/T/ipykernel_39638/981809309.py\u001B[0m in \u001B[0;36mgaussianSample\u001B[0;34m(moments, nDecimals)\u001B[0m\n\u001B[1;32m     32\u001B[0m     \u001B[0mmoments\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstandard\u001B[0m \u001B[0mdeviation\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mby\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mthe\u001B[0m \u001B[0msecond\u001B[0m \u001B[0mmoment\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mvariance\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m     '''\n\u001B[0;32m---> 34\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmoments\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmoments\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnDecimals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Test - Analysing difference between bacterial load and fev1\n",
    "t0=t.time()\n",
    "df1 = inferenceCode(continuousLungModel, processData, \n",
    "              {'Bacterial load': 'medium'}, \n",
    "              'After observing bacterial load',  n_samples=1000)\n",
    "t1=t.time()\n",
    "print(\"in \"+str(round(t1-t0,2))+\"s\")\n",
    "df2 = inferenceCode(continuousLungModel, processData, \n",
    "              {'Bacterial load': 'medium', 'Wellness': 5}, \n",
    "              'After observing bacterial load and wellness',  n_samples=1000)\n",
    "t2=t.time()\n",
    "print(\"in \"+str(round(t2-t1,2))+\"s\")\n",
    "df3 = inferenceCode(continuousLungModel, processData, \n",
    "              {'FEV1': 85.23}, \n",
    "              'After observing FEV1',  n_samples=1000)\n",
    "t3=t.time()\n",
    "print(\"in \"+str(round(t3-t2,2))+\"s\")\n",
    "df4 = inferenceCode(continuousLungModel, processData, \n",
    "              {'FEV1': 85.23, 'Bacterial load': 'medium'}, \n",
    "              'After observing FEV1, bacterial load', n_samples=1000)\n",
    "t4=t.time()\n",
    "print(\"in \"+str(round(t4-t3,2))+\"s\")\n",
    "df5 = inferenceCode(continuousLungModel, processData, \n",
    "              {'FEV1': 85.23, 'Bacterial load': 'medium', 'Wellness': 5}, \n",
    "              'After observing FEV1, bacterial load and wellness', n_samples=1000)\n",
    "t5=t.time()\n",
    "print(\"in \"+str(round(t5-t4,2))+\"s\")\n",
    "out = pd.concat([df1, df2, df2, df3, df5])\n",
    "plotFigure(out, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f8baf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Expected results - validated!\n",
    "For variables v1, v2 with n1, n2 outcomes, the time taken scales like the total number of possibilities (n1xn2), meaning in a power law. Hence the time weight for each observation is roughly:\n",
    "1. bacterial load = 3\n",
    "2. bacterial load + wellness = 15 = 5x more time than 1. → validated\n",
    "3. FEV1 = 20x100 = 2k → 133x more time than 2. (assuming possibilities are within the std range)\n",
    "4. bacterial load + FEV1 = 3x20x100 = 6k → 3x more time than 3.\n",
    "5. bacterial load + wellness + FEV1 = 3x5x20x100 = 30k → 15x more time than 3 or 5x more time than 4.\n",
    "\n",
    "#### Results\n",
    "Looking at BRDataDemographics, the (mean, avg) FEV1% variance is (5,4). Hence simulating a std dev of 10 (hence, 20x100 possibilities) is reasonnable.\n",
    "Number of continuous variables, time of inference: 1 takes 30\", 2 takes 1', 120 takes 1h, \n",
    "Note: this is to get 1k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9e839",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot time of computations vs number of continuous vars\n",
    "nVar = np.arange(1,20)\n",
    "time1Var = 26 # seconds\n",
    "nPossibilitiesPerVar = 2000\n",
    "time = time1Var * pow(nPossibilitiesPerVar, nVar-1)/(3600*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88a647",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(x=nVar, y=time, labels={'x':'Number of continuous variables', 'y':'Model inference time in days (with my personal computer)'}, \n",
    "                 log_y=True, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbed17f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Belief propagation <a class=\"anchor\" id=\"3.2\"></a>\n",
    "Also known as message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d99e61e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Inflammation': 'absent',\n 'Wellness': 4,\n 'Bacterial load': 'low',\n 'FEV1': 'high'}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lung Function Model\n",
    "class lungModel:\n",
    "    \n",
    "    # Names\n",
    "    \"\"\"\n",
    "    i: inflammation\n",
    "    bl: bacterial load\n",
    "    w: wellness\n",
    "    \"\"\"\n",
    "    # Marginal distributions\n",
    "    marginal_i = {\n",
    "        \"absent\": 0.3,\n",
    "        \"small\": 0.5,\n",
    "        \"heavy\": 0.2\n",
    "    }\n",
    "    # Conditional probability table (cpt) of varB knowing varA\n",
    "    cpt_bl_i = {\n",
    "        \"absent\": {\n",
    "            \"low\": 0.6,\n",
    "            \"medium\": 0.2,\n",
    "            \"high\": 0.2\n",
    "        },\n",
    "        \"small\": {\n",
    "            \"low\": 0.3,\n",
    "            \"medium\": 0.3,\n",
    "            \"high\": 0.4\n",
    "        },\n",
    "        \"heavy\": {\n",
    "            \"low\": 0.1,\n",
    "            \"medium\": 0.3,\n",
    "            \"high\": 0.6\n",
    "        }\n",
    "    }\n",
    "    cpt_w_i = {\n",
    "        \"absent\": {\n",
    "            1: 0.01,\n",
    "            2: 0.09,\n",
    "            3: 0.2,\n",
    "            4: 0.3,\n",
    "            5: 0.4\n",
    "        },\n",
    "        \"small\": {\n",
    "            1: 0.2,\n",
    "            2: 0.3,\n",
    "            3: 0.3,\n",
    "            4: 0.1,\n",
    "            5: 0.1\n",
    "        },\n",
    "        \"heavy\": {\n",
    "            1: 0.4,\n",
    "            2: 0.3,\n",
    "            3: 0.15,\n",
    "            4: 0.1,\n",
    "            5: 0.05\n",
    "        }\n",
    "    }\n",
    "    cpt_FEV1_bl = {\n",
    "        'low': {\n",
    "            'low': 0.6,\n",
    "            'medium': 0.3,\n",
    "            'high': 0.2,\n",
    "        },\n",
    "        'medium': {\n",
    "            'low': 0.3,\n",
    "            'medium': 0.4,\n",
    "            'high': 0.3,\n",
    "        },\n",
    "        'high': {\n",
    "            'low': 0.1,\n",
    "            'medium': 0.4,\n",
    "            'high': 0.5,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def sample(self):\n",
    "        inflammation = utils.threeStatesSample(list(self.marginal_i.values()),\n",
    "                                               list(self.marginal_i.keys()))\n",
    "        \n",
    "        wellness = utils.nStatesSample(list(self.cpt_w_i[inflammation].values()),\n",
    "                                 list(self.cpt_w_i[inflammation].keys()))\n",
    "        \n",
    "        bacterial_load = utils.threeStatesSample(list(self.cpt_bl_i[inflammation].values()),\n",
    "                                            list(self.cpt_bl_i[inflammation].keys()))\n",
    "        \n",
    "        FEV1 = utils.threeStatesSample(list(self.cpt_FEV1_bl[bacterial_load].values()),\n",
    "                                list(self.cpt_FEV1_bl[bacterial_load].keys()))\n",
    "        \n",
    "        return {\n",
    "            \"Inflammation\": inflammation,\n",
    "            \"Wellness\": wellness,\n",
    "            \"Bacterial load\": bacterial_load,\n",
    "            \"FEV1\": FEV1\n",
    "        }\n",
    "model = lungModel()\n",
    "model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ea9ced9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inference code\n",
    "def get_cpt_obs(obs_B, cpt_B_A):\n",
    "\n",
    "    cpt_B_A_bis = cpt_B_A\n",
    "    for key_A, items_B in cpt_B_A.items():\n",
    "        for key_B, p_B in items_B.items():\n",
    "            # observed variable has probability 1, unobserved are 0\n",
    "            if key_B != obs_B: cpt_B_A_bis[key_A][key_B] = 0\n",
    "            else: cpt_B_A_bis[key_A][key_B] = p_B\n",
    "    \n",
    "    return cpt_B_A_bis\n",
    "    \n",
    "def get_second_level_keys(cpt_B_A):\n",
    "    \"\"\"\n",
    "    returns a dict with second level keys and values set to 0\n",
    "    \"\"\"\n",
    "    return {key : 0 for key in cpt_B_A[next(iter(cpt_B_A))]}\n",
    "\n",
    "def get_first_level_keys(cpt_B_A):\n",
    "    return {key : 0 for key in cpt_B_A.keys()}\n",
    "    \n",
    "def marginalise(cpt_B_A, dist_A):\n",
    "    \"\"\"\n",
    "    marginalise out B out of cpt_B_A\n",
    "    TODO: implement case where A is not marginal (recursion?)\n",
    "    \"\"\"\n",
    "    \n",
    "    dist_B = get_second_level_keys(cpt_B_A)\n",
    "    # P(B) = sum_A(P(B | A) * P(A))\n",
    "    for key_A, B_A in cpt_B_A.items():\n",
    "        for key_B, B_value in B_A.items():\n",
    "            dist_B[key_B] += B_value * dist_A[key_A]\n",
    "    \n",
    "    return dist_B\n",
    "\n",
    "# factor node message\n",
    "def message_down(dist, disp=1, label_A='A'):\n",
    "    \"\"\"\n",
    "    dist: marginal distribution\n",
    "    \"\"\"\n",
    "    if disp==1: print('marginal distribution: P(', label_A, ') =', dist, '\\n')\n",
    "    print(\"message down: \", dist)\n",
    "    return dist\n",
    "\n",
    "def message_up(A_dist, cpt_B_A, disp=1, label_A='A', label_B='B'):\n",
    "    \n",
    "    # compute normalisers, sum_B(P(B|A) * P(A))\n",
    "    normalisers = get_first_level_keys(cpt_B_A)\n",
    "    print(cpt_B_A)\n",
    "    for key_A, items_B in cpt_B_A.items():\n",
    "        for key_B, p_B_A in items_B.items():\n",
    "            normalisers[key_A] += p_B_A * A_dist[key_A]\n",
    "\n",
    "    normaliser = sum(list(normalisers.values()))\n",
    "    \n",
    "    # compute posteriors P(A|B) = P(B|A) * P(A) / sum_B(P(B|A))\n",
    "    posteriors = get_first_level_keys(cpt_B_A)\n",
    "    for key_A, items_B in cpt_B_A.items():\n",
    "        for key_B, p_B_A in items_B.items():\n",
    "            if p_B_A != 0:\n",
    "                posteriors[key_A] = p_B_A * A_dist[key_A] / normaliser\n",
    "    print(\"posteriors: \",posteriors)\n",
    "    return posteriors\n",
    "\n",
    "# variable node message\n",
    "def propagate_belief(messages):\n",
    "    # Multiply all messages\n",
    "    beliefs=[]\n",
    "    for key in messages[0].keys():\n",
    "        belief=1\n",
    "        for message in messages:\n",
    "            print(\"message\",message[key])\n",
    "            belief *= message[key]\n",
    "        print(\"belief\", belief)\n",
    "        beliefs.append(belief)\n",
    "    \n",
    "    # Normalise and format\n",
    "    normalised_beliefs = utils.normalise_list(beliefs)\n",
    "    p_A_given_B = dict(zip(messages[0].keys(), normalised_beliefs))\n",
    "    \n",
    "    print('Result of belief propagation:', p_A_given_B)\n",
    "    return p_A_given_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9aa74f40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absent': {'low': 0, 'medium': 0.2, 'high': 0}, 'small': {'low': 0, 'medium': 0.3, 'high': 0}, 'heavy': {'low': 0, 'medium': 0.3, 'high': 0}}\n",
      "posteriors:  {'absent': 0.2222222222222222, 'small': 0.5555555555555555, 'heavy': 0.2222222222222222}\n",
      "marginal distribution: P( A ) = {'absent': 0.3, 'small': 0.5, 'heavy': 0.2} \n",
      "\n",
      "message down:  {'absent': 0.3, 'small': 0.5, 'heavy': 0.2}\n",
      "message 0.2222222222222222\n",
      "message 0.3\n",
      "belief 0.06666666666666667\n",
      "message 0.5555555555555555\n",
      "message 0.5\n",
      "belief 0.27777777777777773\n",
      "message 0.2222222222222222\n",
      "message 0.2\n",
      "belief 0.044444444444444446\n",
      "Result of belief propagation: {'absent': 0.17142857142857146, 'small': 0.7142857142857143, 'heavy': 0.11428571428571431}\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "m = lungModel()\n",
    "\n",
    "# CASE 1\n",
    "\n",
    "obs_bacterial_load = 'medium'\n",
    "\n",
    "cpt_bl_obs_i = get_cpt_obs(obs_bacterial_load,m.cpt_bl_i)\n",
    "\n",
    "# belief propagation\n",
    "i_bl = message_up(m.marginal_i, cpt_bl_obs_i)\n",
    "\n",
    "i = message_down(m.marginal_i)\n",
    "\n",
    "belief1 = propagate_belief([i_bl, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absent': {'low': 0, 'medium': 0.2, 'high': 0}, 'small': {'low': 0, 'medium': 0.3, 'high': 0}, 'heavy': {'low': 0, 'medium': 0.3, 'high': 0}}\n",
      "posteriors:  {'absent': 0.2222222222222222, 'small': 0.5555555555555555, 'heavy': 0.2222222222222222}\n",
      "{'absent': {1: 0.01, 2: 0, 3: 0, 4: 0, 5: 0}, 'small': {1: 0.2, 2: 0, 3: 0, 4: 0, 5: 0}, 'heavy': {1: 0.4, 2: 0, 3: 0, 4: 0, 5: 0}}\n",
      "posteriors:  {'absent': 0.016393442622950817, 'small': 0.5464480874316939, 'heavy': 0.43715846994535523}\n",
      "marginal distribution: P( A ) = {'absent': 0.3, 'small': 0.5, 'heavy': 0.2} \n",
      "\n",
      "message down:  {'absent': 0.3, 'small': 0.5, 'heavy': 0.2}\n",
      "message 0.2222222222222222\n",
      "message 0.016393442622950817\n",
      "message 0.3\n",
      "belief 0.0010928961748633878\n",
      "message 0.5555555555555555\n",
      "message 0.5464480874316939\n",
      "message 0.5\n",
      "belief 0.15179113539769273\n",
      "message 0.2222222222222222\n",
      "message 0.43715846994535523\n",
      "message 0.2\n",
      "belief 0.01942926533090468\n",
      "Result of belief propagation: {'absent': 0.006342494714587738, 'small': 0.8809020436927413, 'heavy': 0.11275546159267094}\n"
     ]
    }
   ],
   "source": [
    "# CASE 2\n",
    "\n",
    "obs_bacterial_load = 'medium'\n",
    "obs_wellness = 1\n",
    "\n",
    "cpt_bl_obs_i = get_cpt_obs(obs_bacterial_load,m.cpt_bl_i)\n",
    "cpt_w_obs_i = get_cpt_obs(obs_wellness,m.cpt_w_i)\n",
    "\n",
    "# belief propagation\n",
    "i_bl = message_up(m.marginal_i, cpt_bl_obs_i)\n",
    "i_w = message_up(m.marginal_i, cpt_w_obs_i)\n",
    "i = message_down(m.marginal_i)\n",
    "\n",
    "belief1 = propagate_belief([i_bl, i_w, i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5acb08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CASE 3\n",
    "# observations\n",
    "obs_FEV1 = 'low'\n",
    "obs_wellness = 1\n",
    "\n",
    "cpt_bl_obs_i = get_cpt_obs(obs_bacterial_load, m.cpt_FEV1_bl)\n",
    "\n",
    "# belief propagation\n",
    "bl_FEV1 = message_up(m.cpt_FEV1_bl, cpt_bl_obs_i)\n",
    "i_w = message_up(m.marginal_i, m.cpt_w_i, obs_wellness)\n",
    "i = message_down(m.marginal_i)\n",
    "\n",
    "belief1 = propagate_belief([i_bl, i_w, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122d35f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gibbs sampling <a class=\"anchor\" id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ee71e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gibbs inference code\n",
    "def gibbs_inference_code(target_X, target_Y, modelToRun=lungModel, n=100000):\n",
    "\n",
    "\n",
    "    # Random initialisation\n",
    "    sample = modelToRun()\n",
    "    i = [sample[target_X]]\n",
    "    b = [sample[target_Y]]\n",
    "    print('Initial state:', I, '=', i, ',', B, '=', b)\n",
    "\n",
    "    # Loop\n",
    "    # TODO  review function arguments to avoid global variables\n",
    "    for j in np.arange(n):\n",
    "        b.append(threeStatesSample(bacterial_load_p.get(i[j]), [\"low\", \"medium\", \"high\"]))\n",
    "        i_posteriors = compute_posterior(I, B, b[j+1], conditional_probability_table, disp=0)\n",
    "        i.append(threeStatesSample([i_posteriors[key] for key in i_posteriors.keys()], list(i_posteriors.keys())))\n",
    "\n",
    "    return b, i\n",
    "\n",
    "# Data processing\n",
    "def get_marginal(name, list):\n",
    "    '''\n",
    "    name: identifier\n",
    "    list: a list of values\n",
    "    output: distinct values count in list, and related proportions (probability estimate)\n",
    "    '''\n",
    "    marginal = pd.DataFrame(data={name: list})\n",
    "    marginal = pd.DataFrame(data={'count': marginal.value_counts()}).reset_index()\n",
    "    marginal['P(count)'] = marginal['count']/marginal['count'].sum()\n",
    "    \n",
    "    return marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a5e81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gibbs sampling implementation for two variables\n",
    "\n",
    "# Variables\n",
    "I = 'Inflammation'\n",
    "B = 'Bacterial load'\n",
    "    \n",
    "n_high=100000; n_low=1000\n",
    "b, i = gibbs_inference_code(I, B, n=n_high)\n",
    "b_fuzzy, i_fuzzy = gibbs_inference_code(I, B, n=n_low)\n",
    "\n",
    "# Marginal distribution of inflammation\n",
    "i_marginal = get_marginal(I, i)\n",
    "i_marginal_fuzzy = get_marginal(I, i_fuzzy)\n",
    "i_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7762540",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Marginal distribution of bacterial load\n",
    "b_marginal = get_marginal(B, b)\n",
    "b_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d75bb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotFigure(i_marginal, I, column=1, title=\"Marginal distribution for inflammation for \"+str(n_high)+\" iterations\")\n",
    "plotFigure(i_marginal_fuzzy, I, column=1, title=\"Marginal distribution for inflammation \"+str(n_low)+\" iterations\")\n",
    "plotFigure(b_marginal, B, column=1, title=\"Marginal distribution for inflammation for \"+str(n_high)+\" iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2caa12b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Toy Model <a class=\"anchor\" id=\"4\"></a>\n",
    "## Set up\n",
    "A coin is tricked to give heads with a probability p. The coin is tossed n times and we record the number of heads. We repeat this a couple of times to get a series of number of heads recorded (nTrials). We then plot the distribution of the number of heads observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdba9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def toyModel(p, n=10):\n",
    "    '''\n",
    "    p: probability of coin toss\n",
    "    n: number of coin tosses\n",
    "    return p and number of observed heads\n",
    "    '''\n",
    "    samples=[]\n",
    "    for _ in range(n):\n",
    "        samples.append(bernoulliSample(p, \"heads\", \"tails\"))\n",
    "    nHeads = samples.count(\"heads\")\n",
    "    return nHeads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c2b4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot function\n",
    "def processToyModel(p = rand.random(), nToss = 10, nTrials=100):\n",
    "    coin = pd.DataFrame([toyModel(p=p, n=nToss) for _ in range(nTrials)], \n",
    "                 columns=[\"number of heads observed\"])\n",
    "    coin[\"p\"] = p\n",
    "    \n",
    "    fig = px.histogram(coin, x='number of heads observed', height=300, \n",
    "             range_x=(0,nToss),\n",
    "             title=\"Distribution after \"+str(nToss)+\" tosses\")\n",
    "    return fig, coin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a318c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = rand.random()\n",
    "nToss1 = 10\n",
    "nToss2 = 1000\n",
    "fig1, data1 = processToyModel(p = p, nToss = nToss1, nTrials=20)\n",
    "fig2, data2 = processToyModel(p = p, nToss = nToss2, nTrials=20)\n",
    "fig1.show()\n",
    "print(\"Inferred probability p = \", round(stats.mean(data1[\"number of heads observed\"])/nToss1,3))\n",
    "fig2.show()\n",
    "print(\"Inferred probability p = \", round(stats.mean(data2[\"number of heads observed\"])/nToss2,3))\n",
    "print(\"Unknown probability p =\", round(p,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4d9e28",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Observations\n",
    "- When the number of tosses increases, the dispersion of the number of heads observed gets smaller. When nToss → ∞, the distribution converges to a point mass, which is the unknown probability.\n",
    "- The number of trials controls the quality of the distribution. The higher nTrials, the smoother the distribution.\n",
    "\n",
    "## Conclusion\n",
    "One can infer the probability of an event by looking at the distribution of its observations.\n",
    "The more observations are made, the more accurate is the inferred probability.\n",
    "\n",
    "$ P(toss\\ outcome\\ =\\ head) = \\frac{avg_{trials}(Heads\\ count)}{Number\\ of\\ tosses\\ per\\ trial} $\n",
    "\n",
    "**Parallel with lungs**: we want to infer the probability that a human has an FEV1 over 103%. Take a group of people. For each person, measure the FEV1 for n days. The inferred probability is:\n",
    "\n",
    "$ P(FEV_1>103\\%) = \\frac{avg_{participants}(FEV1>103\\%\\ count)}{Number\\ of\\ measurements} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7993b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Toy Model 2 <a class=\"anchor\" id=\"5\"></a>\n",
    "- Observations: number of heads M and number of tosses N per trial\n",
    "- For each trial p(heads) ~ U(0,1)\n",
    "- We reject the trial if M is not matched\n",
    "- Have T points in the distribution\n",
    "- Plot the distribution of p\n",
    "\n",
    "Expectations: for M=7, N=8, p will be centered close to 7/8 (=M/N) if sufficient trials are done.\n",
    "1. M=0, distribution is linear with max on p=0 and 0 on p=1\n",
    "2. The distribution of p should be close to M/N\n",
    "3. The higher N, the more reproductible the experiment\n",
    "\n",
    "Results:\n",
    "- The higher N, the lower the variance of p = the lower the uncertainty of p\n",
    "- Each sample is drawn from a Beta distribution with parameters M and N\n",
    "    - M/N controls the mean\n",
    "    - N controls the spread/dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa4ed2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def processToyModel2(M=7 , N=8, T=10):\n",
    "    i=0\n",
    "    p = []\n",
    "    t0=t.time()\n",
    "    while(len(p) < T):\n",
    "        i=i+1\n",
    "        p_temp = rand.random()\n",
    "        m = toyModel(p_temp, N)\n",
    "        if M == m: p.append(p_temp)\n",
    "    t1=t.time()\n",
    "    fig = px.histogram(p, height=300,\n",
    "             title=str(i)+\" trials in \"+str(round(t1-t0,1))+\"s to obtain \"+str(T)+\" datapoints for \"+str(N)+\" tosses and \"+str(M)+\" heads\",\n",
    "            range_x=(0,1))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f5441",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig1 = processToyModel2(M=7 , N=8, T=1000)\n",
    "fig1.show()\n",
    "fig2 = processToyModel2(M=0 , N=8, T=1000)\n",
    "fig2.show()\n",
    "fig3 = processToyModel2(M=0 , N=30, T=1000)\n",
    "fig3.show()\n",
    "fig4 = processToyModel2(M=0 , N=8, T=10)\n",
    "fig4.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}