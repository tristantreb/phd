{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.models.helpers as mh\n",
    "import plotly.graph_objects as go\n",
    "import src.modelling_fev1.uecfev1 as uecfev1\n",
    "import src.data.breathe_data as bd\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import src.data.helpers as dh\n",
    "import src.models.cpts.helpers as cpth\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick std gauss from the FEV1 variability study (msc thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 6, 0.05, prior={\"type\": \"uniform\"})\n",
    "uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 6, 0.05, prior=None)\n",
    "# std_gauss = 0.3\n",
    "# median std gauss is 0.068\n",
    "\n",
    "# Plot the PDF of ecFEV1 given the middle bin of uecFEV1\n",
    "uecfev1_bin = uecFEV1.get_bins_arr()[uecFEV1.card // 2]\n",
    "print(\"uecFEV1 bin\", uecfev1_bin)\n",
    "# Get the PDF\n",
    "pdf = np.zeros(ecFEV1.card)\n",
    "for i, z in enumerate(ecFEV1.midbins):\n",
    "    pdf[i] = uecfev1.PDF_conv_uni_gausian(z, uecfev1_bin[0], uecfev1_bin[1], std_gauss)\n",
    "# Norm the pdf\n",
    "pdf /= np.sum(pdf)\n",
    "# Plot pdf with graph objects library\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=ecFEV1.midbins, y=pdf))\n",
    "title = f\"P(ecFEV1 | uecFEV1={uecfev1_bin} L)\"\n",
    "fig.update_layout(title=title, height=300, width=650)\n",
    "fig.update_xaxes(title_text=ecFEV1.name)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot of individul level std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick healthy individuals\n",
    "def get_std(df):\n",
    "    \"\"\"\n",
    "    If there are more than 10 values, compute the standard deviation\n",
    "    Else, return NaN\n",
    "    \"\"\"\n",
    "    if len(df) > 10:\n",
    "        return df.std()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_boxplot_of_std_per_healthy_individual(\n",
    "    df, health_threshold=80, ecFEV1_col=\"ecFEV1\"\n",
    "):\n",
    "    # Remove unhealthy individuals\n",
    "    # Compute avg predicted fev1 per id\n",
    "    stmp = df.groupby(\"ID\")[\"ecFEV1 % Predicted\"].agg(\"mean\").sort_values()\n",
    "    ids_healthy = stmp[stmp > health_threshold].index\n",
    "\n",
    "    # Filter healthy individuals\n",
    "    df_healhiest = df[df[\"ID\"].isin(ids_healthy)]\n",
    "    stds = df_healhiest.groupby(\"ID\")[ecFEV1_col].agg(get_std).dropna().sort_values()\n",
    "\n",
    "    # Print avg std\n",
    "    print(f\"Average std: {stds.mean()}\")\n",
    "    print(f\"Median std: {stds.median()}\")\n",
    "\n",
    "    # Plost histogram of stds\n",
    "    fig = px.box(stds, x=ecFEV1_col, orientation=\"h\")\n",
    "    # Improve boxplot colouring\n",
    "    # More x axis ticks\n",
    "    fig.update_xaxes(tick0=0, dtick=0.05)\n",
    "    # fig = px.histogram(stds, nbins=80)  # , marginal=\"box\")\n",
    "    # Update x axis\n",
    "    # fig.update_xaxes(\n",
    "    #     title_text=f\"Standard deviation of the individual's<br> O2 saturation measurements\"\n",
    "    # )\n",
    "    # fig.update_yaxes(title_text=\"Individuals count\")\n",
    "    title = f\"Boxplot of individual-level std ({len(stds)} individuals)\"\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        height=180,\n",
    "        width=500,\n",
    "        showlegend=False,\n",
    "        font=dict(size=9),\n",
    "        plot_bgcolor=\"white\",\n",
    "    )\n",
    "    # Grey grid\n",
    "    fig.update_xaxes(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        linecolor=\"black\",\n",
    "        linewidth=1,\n",
    "        mirror=True,\n",
    "        title=f\"{ecFEV1_col} std\",\n",
    "    )\n",
    "    # Same on y\n",
    "    fig.update_yaxes(linecolor=\"black\", linewidth=1, mirror=True)\n",
    "    fig.show()\n",
    "    return df_healhiest\n",
    "\n",
    "\n",
    "# Median std: 0.1\n",
    "# df_healhiest = get_boxplot_of_std_per_healthy_individual(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement FEV1 variability model\n",
    "\n",
    "Model from the msc thesis: noise = measurement - signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_ma = bd.load_meas_from_excel(\n",
    "    \"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx_MA_31_7\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 31\n",
    "t = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP IF ALREADY LOADED THE DATA\n",
    "# Noise model\n",
    "def moving_average_for_ID(df, w, t, fev1_col=\"FEV1\"):\n",
    "    def moving_average(row, w, t):\n",
    "        \"\"\"\n",
    "        Compute the moving average of an array with window w and threshold t\n",
    "        \"\"\"\n",
    "        date = row[\"Date Recorded\"]\n",
    "        n_days_ago = date - pd.Timedelta(days=(w - 1) / 2)\n",
    "        n_days_later = date + pd.Timedelta(days=(w - 1) / 2)\n",
    "        # Get the values within the window\n",
    "        df_ma = df.loc[:, [\"Date Recorded\", fev1_col]][\n",
    "            (df[\"Date Recorded\"] >= n_days_ago) & (df[\"Date Recorded\"] <= n_days_later)\n",
    "        ]\n",
    "        # If there are more than t values, compute average of t closest values\n",
    "        if len(df_ma) > t:\n",
    "            # Compute number of days reference on the date\n",
    "            df_ma[\"N days away\"] = (df_ma[\"Date Recorded\"] - date).abs()\n",
    "            # Sort by the absolute value of the days away\n",
    "            df_ma = df_ma.sort_values(\"N days away\")\n",
    "            # Take mean of first t values\n",
    "            return df_ma[fev1_col].head(t).mean()\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    # Compute moving average\n",
    "    df[f\"MA{fev1_col}\"] = df.apply(moving_average, args=(w, t), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# df_out = df.groupby(\"ID\").apply(lambda df: moving_average_for_ID(df, w, t, \"ecFEV1\"))\n",
    "df_out = df.groupby(\"ID\").apply(lambda df: moving_average_for_ID(df, w, t, \"FEV1\"))\n",
    "df_out = df_out.drop(columns=[\"ID\"]).reset_index().drop(columns=[\"level_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df\n",
    "# df_ma.to_excel(\n",
    "#     f\"{dh.get_path_to_main()}ExcelFiles/BR/BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx_MA_{w}_{t}.xlsx\",\n",
    "#     index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join MAFEV1 from df_out into df_ma\n",
    "df_ma = pd.merge(\n",
    "    df_ma, df_out[[\"ID\", \"Date Recorded\", \"MAFEV1\"]], on=[\"ID\", \"Date Recorded\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ma[\"MAFEV1\"] - df_ma[\"FEV1\"])\n",
    "# Compute difference, remove nans and sort\n",
    "diff = (df_ma[\"MAFEV1\"] - df_ma[\"FEV1\"]).dropna().sort_values()\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using plotly go, plot scatter of initiall values and moving average\n",
    "\n",
    "# mafev1_col = \"MAecFEV1\"\n",
    "mafev1_col = \"MAFEV1\"\n",
    "\n",
    "for id in [\"101\"]:  # df_ma[\"ID\"].unique():\n",
    "    dftmp = df_ma[df_ma[\"ID\"] == id]\n",
    "    df_smoothed = dftmp.dropna(subset=[mafev1_col])\n",
    "    df_isna = dftmp[dftmp[mafev1_col].isna()]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=dftmp[\"Date Recorded\"],\n",
    "            y=dftmp[mafev1_col],\n",
    "            mode=\"markers\",\n",
    "            name=\"Moving average\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_smoothed[\"Date Recorded\"],\n",
    "            y=df_smoothed[\"ecFEV1\"],\n",
    "            mode=\"markers\",\n",
    "            name=\"Initial ecFEV1 values\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_isna[\"Date Recorded\"],\n",
    "            y=df_isna[\"ecFEV1\"],\n",
    "            mode=\"markers\",\n",
    "            name=\"Values excluded from the moving average\",\n",
    "        )\n",
    "    )\n",
    "    for trace in fig.data:\n",
    "        if trace.name == \"Moving average\":\n",
    "            trace.marker.color = \"red\"\n",
    "            trace.marker.size = 6\n",
    "        elif trace.name == \"Values excluded from the moving average\":\n",
    "            trace.marker.color = \"grey\"\n",
    "            trace.marker.size = 3\n",
    "        elif trace.name == \"Initial ecFEV1 values\":\n",
    "            trace.marker.color = \"blue\"\n",
    "            trace.marker.size = 3\n",
    "    title = f\"{id} - Moving average of ecFEV1 with window {w} and threshold {t}\"\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"ecFEV1 (L)\",\n",
    "        width=1600,\n",
    "        height=500,\n",
    "        font=dict(size=16),\n",
    "    )\n",
    "    # Put legend on top\n",
    "    fig.update_layout(legend=dict(y=1.1, orientation=\"h\"))\n",
    "    # fig.write_image(\n",
    "    #     f\"{dh.get_path_to_main()}PlotsBreathe/FEV1_modelling/Moving averages/{title}.pdf\"\n",
    "    # )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "\n",
    "mafev1_col = \"MAecFEV1\"\n",
    "# mafev1_col = \"MAFEV1\"\n",
    "\n",
    "print(f\"{len(df_ma)} measurements, {df_ma.ID.nunique()} individuals\")\n",
    "df_ma = df_ma.dropna(subset=[mafev1_col])\n",
    "print(\n",
    "    f\"{len(df_ma)} measurements, {df_ma.ID.nunique()} individuals after dropping NA values in the moving average\"\n",
    ")\n",
    "# Drop counts < 10 values\n",
    "df_ma = df_ma.groupby(\"ID\").filter(lambda x: len(x) > 10)\n",
    "print(\n",
    "    f\"{len(df_ma)} measurements, {df_ma.ID.nunique()} individuals after dropping individuals with less than 10 values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma[\"MAecFEV1 residuals\"] = (df_ma[\"ecFEV1\"] - df_ma[\"MAecFEV1\"]).abs()\n",
    "df_ma_healthiest = get_boxplot_of_std_per_healthy_individual(\n",
    "    df_ma, 0, \"MAecFEV1 residuals\"\n",
    ")\n",
    "df_ma[\"MAFEV1 residuals\"] = (df_ma[\"FEV1\"] - df_ma[\"MAFEV1\"]).abs()\n",
    "df_ma_healthiest = get_boxplot_of_std_per_healthy_individual(\n",
    "    df_ma, 0, \"MAFEV1 residuals\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How wrong is the additive std gauss?\n",
    "\n",
    "#### Overall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and std per individual\n",
    "def get_df_ids_from_df_ma(df_ma, fev1_col):\n",
    "    s_stds = df_ma.groupby(\"ID\")[f\"MA{fev1_col} residuals\"].agg(get_std)\n",
    "    df_ids = pd.DataFrame(s_stds).reset_index()\n",
    "    df_ids.columns = [\"ID\", f\"MA{fev1_col} residuals std\"]\n",
    "    df_ids[f\"Mean {fev1_col}\"] = df_ma.groupby(\"ID\")[f\"{fev1_col}\"].mean().values\n",
    "    # Remove outlier\n",
    "    df_ids = df_ids[df_ids[f\"MA{fev1_col} residuals std\"] < 0.3]\n",
    "    return df_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "df_ids = get_df_ids_from_df_ma(df_ma, \"FEV1\")\n",
    "df_ids = get_df_ids_from_df_ma(df_ma, \"ecFEV1\")\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_ids,\n",
    "    x=\"Mean ecFEV1\",\n",
    "    y=\"MAecFEV1 residuals std\",\n",
    ")\n",
    "\n",
    "title = \"How wrong is additive noise? (removed one outlier)\"\n",
    "\n",
    "# Update x-axis and y-axis properties\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Mean ecFEV1 (L)\",\n",
    "    range=[0, 6],\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"lightgrey\",\n",
    "    linecolor=\"black\",\n",
    "    mirror=True,\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"lightgrey\",\n",
    "    linecolor=\"black\",\n",
    "    mirror=True,\n",
    "    title_text=\"Individual-level standard deviation<br>of the ecFEV1 moving average residuals (L)\",\n",
    ")\n",
    "\n",
    "# Update marker size and layout\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.update_layout(plot_bgcolor=\"white\", width=600, height=450, title=title)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratify by different FEV1 levels, and check the avg std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fev1_col = \"ecFEV1\"\n",
    "fev1_col = \"FEV1\"\n",
    "\n",
    "fev1_prct_pred_col = f\"{fev1_col} % Predicted\"\n",
    "ma_fev1_res_std_col = f\"MA{fev1_col} residuals std\"\n",
    "\n",
    "\n",
    "df1 = df_ma\n",
    "health_threshold = 0\n",
    "df1 = df1[df1[f\"{fev1_col} % Predicted\"] > health_threshold]\n",
    "\n",
    "# Cut the data in 3 bins of FEV1 values between 0 and 6\n",
    "min = np.floor(df1[fev1_col].min() * 10) / 10\n",
    "max = np.ceil(df1[fev1_col].max() * 10) / 10\n",
    "bins = [min, 2, 3, max]\n",
    "print(bins)\n",
    "cat1 = f\"[{bins[0]}; {bins[1]}) L\"\n",
    "cat2 = f\"[{bins[1]}; {bins[2]}) L\"\n",
    "cat3 = f\"[{bins[2]}; {bins[3]}) L\"\n",
    "cat1_midbin = (bins[0] + bins[1]) / 2\n",
    "cat2_midbin = (bins[1] + bins[2]) / 2\n",
    "cat3_midbin = (bins[2] + bins[3]) / 2\n",
    "\n",
    "# Create dataframe\n",
    "# s_std = df1.groupby(\"ID\")[\"ecFEV1\"].mean()\n",
    "# df_std = pd.DataFrame(s_std)\n",
    "# # Compute mean of predicted FEV1\n",
    "# df_std[\"Mean ecFEV1%\"] = df1.groupby(\"ID\")[\"ecFEV1 % Predicted\"].mean()\n",
    "# # Rename column\n",
    "# df_std = df_std.rename(columns={\"ecFEV1\": \"Mean ecFEV1\"})\n",
    "# # Compute the std for those individuals\n",
    "# df_std[\"individual-level std<br>of ecFEV1 measurement\"] = df1.groupby(\"ID\")[\n",
    "#     \"ecFEV1\"\n",
    "# ].std()\n",
    "df_std = get_df_ids_from_df_ma(df1, fev1_col)\n",
    "\n",
    "# print median and mean for the std\n",
    "print(f\"Median std: {df_std[f'MA{fev1_col} residuals std'].median()}\")\n",
    "print(f\"Mean std: {df_std[f'MA{fev1_col} residuals std'].mean()}\")\n",
    "# Cut the avg FEV1 in 3 bins\n",
    "df_std[f\"{fev1_col} category\"] = pd.cut(\n",
    "    df_std[f\"Mean {fev1_col}\"], bins, labels=[cat1, cat2, cat3]\n",
    ")\n",
    "value_counts = df_std.value_counts(f\"{fev1_col} category\")\n",
    "cat1_val = f\"{cat1}<br>(#{value_counts[cat1]})\"\n",
    "cat2_val = f\"{cat2}<br>(#{value_counts[cat2]})\"\n",
    "cat3_val = f\"{cat3}<br>(#{value_counts[cat3]})\"\n",
    "# Rename the bins in {fev1_col} category\n",
    "df_std[f\"{fev1_col} category\"] = df_std[f\"{fev1_col} category\"].replace(\n",
    "    {cat1: cat1_val, cat2: cat2_val, cat3: cat3_val}\n",
    ")\n",
    "\n",
    "# Using px plot boxplots for each category\n",
    "# fig = px.box(dftmp, x=\"{fev1_col} category\", y=\"{fev1_col}\", color=\"{fev1_col} category\", title=\"{fev1_col} distribution per FEV1 category\")\n",
    "title = f\"How wrong is the additive std for {fev1_col}?\"\n",
    "# title = f\"How wrong is the additive std for {fev1_col}?<br>(individuals with {health_threshold}%+ avg predicted FEV1)\"\n",
    "fig = px.box(\n",
    "    df_std,\n",
    "    x=f\"{fev1_col} category\",\n",
    "    y=f\"MA{fev1_col} residuals std\",\n",
    "    color=f\"{fev1_col} category\",\n",
    "    title=title,\n",
    ")\n",
    "\n",
    "# Enforce cat order on plot\n",
    "fig.update_xaxes(categoryorder=\"array\", categoryarray=[cat1_val, cat2_val, cat3_val])\n",
    "# Apply colors to cat1_val in red\n",
    "for i in range(3):\n",
    "    if fig.data[i].name == cat1_val:\n",
    "        fig.data[i].marker.color = \"#EF553B\"\n",
    "    elif fig.data[i].name == cat2_val:\n",
    "        fig.data[i].marker.color = \"#AB63FA\"\n",
    "    elif fig.data[i].name == cat3_val:\n",
    "        fig.data[i].marker.color = \"#636EFA\"\n",
    "    else:\n",
    "        fig.data[i].marker.color = \"#00CC96\"\n",
    "\n",
    "\n",
    "# Hide legend\n",
    "fig.update_layout(showlegend=False, width=500, height=400)\n",
    "fig.show()\n",
    "# Write image\n",
    "fig.write_image(f\"{dh.get_path_to_main()}PlotsBreathe/FEV1_modelling/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNUSED\n",
    "\n",
    "# Same within 1 individual\n",
    "df1 = df1[df1.ID == \"108\"]\n",
    "\n",
    "# Cut the data in 3 bins of FEV1 values between 0 and 6\n",
    "min = np.floor(df1.ecFEV1.min() * 10) / 10\n",
    "max = np.ceil(df1.ecFEV1.max() * 10) / 10\n",
    "bins = [min, 2.4, max]\n",
    "print(bins)\n",
    "cat1 = f\"[{bins[0]}; {bins[1]}) L\"\n",
    "cat2 = f\"[{bins[1]}; {bins[2]}) L\"\n",
    "# cat3 = f\"[{bins[2]}; {bins[3]}) L\"\n",
    "cat1_midbin = (bins[0] + bins[1]) / 2\n",
    "cat2_midbin = (bins[1] + bins[2]) / 2\n",
    "# cat3_midbin = (bins[2] + bins[3]) / 2\n",
    "\n",
    "# Create dataframe\n",
    "s_std = df1.groupby(\"ID\")[\"ecFEV1\"].mean()\n",
    "df_std = pd.DataFrame(s_std)\n",
    "# Compute mean of predicted FEV1\n",
    "df_std[\"Mean ecFEV1%\"] = df1.groupby(\"ID\")[\"ecFEV1 % Predicted\"].mean()\n",
    "# Rename column\n",
    "df_std = df_std.rename(columns={\"ecFEV1\": \"Mean ecFEV1\"})\n",
    "# Compute the std for those individuals\n",
    "df_std[\"individual-level std<br>of ecFEV1 measurement\"] = df1.groupby(\"ID\")[\n",
    "    \"ecFEV1\"\n",
    "].std()\n",
    "# Cut the avg FEV1 in 3 bins\n",
    "df_std[\"ecFEV1 category\"] = pd.cut(df_std[\"Mean ecFEV1\"], bins, labels=[cat1, cat2])\n",
    "value_counts = df_std.value_counts(\"ecFEV1 category\")\n",
    "cat1_val = f\"{cat1}<br>(#{value_counts[cat1]})\"\n",
    "cat2_val = f\"{cat2}<br>(#{value_counts[cat2]})\"\n",
    "# cat3_val = f\"{cat3}<br>(#{value_counts[cat3]})\"\n",
    "# Rename the bins in ecFEV1 category\n",
    "df_std[\"ecFEV1 category\"] = df_std[\"ecFEV1 category\"].replace(\n",
    "    {cat1: cat1_val, cat2: cat2_val}\n",
    ")\n",
    "\n",
    "# Using px plot boxplots for each category\n",
    "# fig = px.box(dftmp, x=\"ecFEV1 category\", y=\"ecFEV1\", color=\"ecFEV1 category\", title=\"ecFEV1 distribution per FEV1 category\")\n",
    "title = f\"How wrong is the additive std for ecFEV1?<br>(individuals with {health_threshold}%+ avg predicted FEV1)\"\n",
    "fig = px.box(\n",
    "    df_std,\n",
    "    x=\"ecFEV1 category\",\n",
    "    y=\"individual-level std<br>of ecFEV1 measurement\",\n",
    "    color=\"ecFEV1 category\",\n",
    "    title=title,\n",
    ")\n",
    "\n",
    "# Enforce cat order on plot\n",
    "fig.update_xaxes(categoryorder=\"array\", categoryarray=[cat1_val, cat2_val])\n",
    "# Apply colors to cat1_val in red\n",
    "for i in range(2):\n",
    "    if fig.data[i].name == cat1_val:\n",
    "        fig.data[i].marker.color = \"#EF553B\"\n",
    "    elif fig.data[i].name == cat2_val:\n",
    "        fig.data[i].marker.color = \"#AB63FA\"\n",
    "\n",
    "\n",
    "# Hide legend\n",
    "fig.update_layout(showlegend=False, width=500, height=400)\n",
    "fig.show()\n",
    "# Write image\n",
    "fig.write_image(f\"{dh.get_path_to_main()}PlotsBreathe/FEV1_modelling/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNUSED\n",
    "stmp = df.groupby(\"ID\")[\"ecFEV1 % Predicted\"].agg(\"mean\").sort_values()\n",
    "\n",
    "# Remove unhealthy individuals\n",
    "health_threshold = 80\n",
    "ids_healthy = stmp[stmp > health_threshold].index\n",
    "df1 = df[df.ID.isin(ids_healthy)]\n",
    "\n",
    "# Remove individuals with less than 10 measurements\n",
    "df1 = df1.groupby(\"ID\").filter(lambda x: len(x) > 10)\n",
    "\n",
    "# Cut the data in 3 bins of FEV1 values between 0 and 6\n",
    "min = np.floor(df1.ecFEV1.min() * 10) / 10\n",
    "max = np.ceil(df1.ecFEV1.max() * 10) / 10\n",
    "bins = [min, 2.5, 3, 4, max]\n",
    "cat1 = f\"[{bins[0]}; {bins[1]}) L\"\n",
    "cat2 = f\"[{bins[1]}; {bins[2]}) L\"\n",
    "cat3 = f\"[{bins[2]}; {bins[3]}) L\"\n",
    "cat4 = f\"[{bins[3]}; {bins[4]}) L\"\n",
    "cat1_midbin = (bins[0] + bins[1]) / 2\n",
    "cat2_midbin = (bins[1] + bins[2]) / 2\n",
    "cat3_midbin = (bins[2] + bins[3]) / 2\n",
    "cat4_midbin = (bins[3] + bins[4]) / 2\n",
    "\n",
    "# Create dataframe\n",
    "s_std = df1.groupby(\"ID\")[\"ecFEV1\"].mean()\n",
    "df_std = pd.DataFrame(s_std)\n",
    "# Compute the std for those individuals\n",
    "df_std[\"individual-level std<br>of ecFEV1 measurement\"] = df1.groupby(\"ID\")[\n",
    "    \"ecFEV1\"\n",
    "].std()\n",
    "# Cut the avg FEV1 in 3 bins\n",
    "df_std[\"ecFEV1 category\"] = pd.cut(\n",
    "    df_std[\"ecFEV1\"], bins, labels=[cat1, cat2, cat3, cat4]\n",
    ")\n",
    "value_counts = df_std.value_counts(\"ecFEV1 category\")\n",
    "cat1_val = f\"{cat1}<br>(#{value_counts[cat1]})\"\n",
    "cat2_val = f\"{cat2}<br>(#{value_counts[cat2]})\"\n",
    "cat3_val = f\"{cat3}<br>(#{value_counts[cat3]})\"\n",
    "cat4_val = f\"{cat4}<br>(#{value_counts[cat4]})\"\n",
    "# Rename the bins in ecFEV1 category\n",
    "df_std[\"ecFEV1 category\"] = df_std[\"ecFEV1 category\"].replace(\n",
    "    {cat1: cat1_val, cat2: cat2_val, cat3: cat3_val, cat4: cat4_val}\n",
    ")\n",
    "\n",
    "# Using px plot boxplots for each category\n",
    "# fig = px.box(dftmp, x=\"ecFEV1 category\", y=\"ecFEV1\", color=\"ecFEV1 category\", title=\"ecFEV1 distribution per FEV1 category\")\n",
    "title = f\"How wrong is the additive std for ecFEV1?<br>(individuals with {health_threshold}%+ avg predicted FEV1)\"\n",
    "fig = px.box(\n",
    "    df_std,\n",
    "    x=\"ecFEV1 category\",\n",
    "    y=\"individual-level std<br>of ecFEV1 measurement\",\n",
    "    color=\"ecFEV1 category\",\n",
    "    title=title,\n",
    ")\n",
    "\n",
    "# Enforce cat order on plot\n",
    "fig.update_xaxes(\n",
    "    categoryorder=\"array\", categoryarray=[cat1_val, cat2_val, cat3_val, cat4_val]\n",
    ")\n",
    "# Apply colors to cat1_val in red\n",
    "for i in range(4):\n",
    "    if fig.data[i].name == cat1_val:\n",
    "        fig.data[i].marker.color = \"#EF553B\"\n",
    "    elif fig.data[i].name == cat2_val:\n",
    "        fig.data[i].marker.color = \"#AB63FA\"\n",
    "    elif fig.data[i].name == cat3_val:\n",
    "        fig.data[i].marker.color = \"#636EFA\"\n",
    "    else:\n",
    "        fig.data[i].marker.color = \"#00CC96\"\n",
    "\n",
    "\n",
    "# Hide legend\n",
    "fig.update_layout(showlegend=False, width=500, height=400)\n",
    "fig.show()\n",
    "# Write image\n",
    "fig.write_image(f\"{dh.get_path_to_main()}PlotsBreathe/FEV1_modelling/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids\n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute median of stds for each category\n",
    "\n",
    "fev1_col = \"FEV1\"\n",
    "# fev1_col = \"ecFEV1\"\n",
    "\n",
    "std_col = f\"individual-level std<br>of {fev1_col} measurement\"\n",
    "std_col = f\"MA{fev1_col} residuals std\"\n",
    "\n",
    "df_ids = df_std\n",
    "s_stds = df_ids.groupby(f\"{fev1_col} category\")[std_col].agg(\"median\")\n",
    "df_cats = pd.DataFrame(s_stds)\n",
    "# Rename col to \"Median ...\"\n",
    "# median_col = f\"Median of the individual-level std<br>of the {fev1_col} residuals (L)\"\n",
    "median_col = f\"Noise per individual (L)<br>(Q1, median, Q3)\"\n",
    "df_cats.columns = [median_col]\n",
    "# Compute 0.25 percentile and 0.75 percentile\n",
    "df_cats[\"Q1\"] = df_ids.groupby(f\"{fev1_col} category\")[std_col].agg(\n",
    "    lambda x: np.percentile(x, 25)\n",
    ")\n",
    "df_cats[\"Q3\"] = df_ids.groupby(f\"{fev1_col} category\")[std_col].agg(\n",
    "    lambda x: np.percentile(x, 75)\n",
    ")\n",
    "# Compute Q1\n",
    "df_cats[\"Q1 err\"] = df_cats[median_col] - df_cats[\"Q1\"]\n",
    "# Compute Q3\n",
    "df_cats[\"Q3 err\"] = df_cats[\"Q3\"] - df_cats[median_col]\n",
    "df_cats.reset_index(inplace=True)\n",
    "\n",
    "# Compute trendline\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add category midbins\n",
    "df_cats[f\"{fev1_col} category midbin\"] = [cat1_midbin, cat2_midbin, cat3_midbin]\n",
    "# df_cats[f\"{fev1_col} category midbin\"] = [cat1_midbin, cat2_midbin, cat3_midbin, cat4_midbin]\n",
    "\n",
    "# Fit a trendline using statsmodels\n",
    "X = sm.add_constant(df_cats[f\"{fev1_col} category midbin\"])\n",
    "model = sm.OLS(df_cats[median_col], X).fit()\n",
    "df_cats[\"trendline\"] = model.predict(X)\n",
    "print(model.summary())\n",
    "print(model._results.params)\n",
    "\n",
    "# Scatter plot with median of stds\n",
    "title = f\"Individual-level std of {fev1_col} measurements\"\n",
    "fig = px.scatter(\n",
    "    df_cats,\n",
    "    x=f\"{fev1_col} category midbin\",\n",
    "    y=median_col,\n",
    "    color=f\"{fev1_col} category\",\n",
    "    title=title,\n",
    "    error_y=\"Q3 err\",\n",
    "    error_y_minus=\"Q1 err\",\n",
    ")\n",
    "# Use same color for scatter plot\n",
    "for i in range(3):\n",
    "    # for i in range(4):\n",
    "    fig.data[i].marker.color = \"#636EFA\"\n",
    "# fig.add_traces(\n",
    "#     px.line(df_cats, x=f\"{fev1_col} category midbin\", y=\"trendline\")\n",
    "#     .update_traces(line=dict(color=\"black\", dash=\"dot\"))\n",
    "#     .data\n",
    "# )\n",
    "# Best fit for ecFEV1\n",
    "# [0.03032977 0.00510174]\n",
    "# Best fit for FEV1\n",
    "# [0.03396603 0.00527939]\n",
    "# Add line of best fit with a = 0.03032977 , b = 0.00510174. y=bx+a\n",
    "# fig.add_traces(\n",
    "#     px.line(df_cats, x=f\"{fev1_col} category midbin\", y=0.00510174 * df_cats[f\"{fev1_col} category midbin\"] + 0.03032977)\n",
    "#     .update_traces(line=dict(color=\"black\", dash=\"dot\"))\n",
    "#     .data\n",
    "# )\n",
    "fig.add_traces(\n",
    "    px.line(\n",
    "        df_cats,\n",
    "        x=f\"{fev1_col} category midbin\",\n",
    "        y=0.00527939 * df_cats[f\"{fev1_col} category midbin\"] + 0.03396603,\n",
    "    )\n",
    "    .update_traces(line=dict(color=\"black\", dash=\"dot\"))\n",
    "    .data\n",
    ")\n",
    "\n",
    "# Replace x axis labels byf {fev1_col} category\n",
    "fig.update_xaxes(\n",
    "    title_text=f\"Mean {fev1_col} group (L)<br>(#individuals)\",\n",
    "    tickvals=df_cats[f\"{fev1_col} category midbin\"],\n",
    "    ticktext=df_cats[f\"{fev1_col} category\"],\n",
    ")\n",
    "# X range from min ecfev1 in df to max ecfev1 in df\n",
    "# fig.update_xaxes(range=[min, max])\n",
    "# Remove legend\n",
    "fig.update_layout(showlegend=False, width=650, height=400)\n",
    "fig.show()\n",
    "df_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate uniform x gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 6, 0.05, prior=None)\n",
    "ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 6, 0.05, prior={\"type\": \"uniform\"})\n",
    "\n",
    "bin_idx = 60\n",
    "bin = uecFEV1.get_bins_arr()[bin_idx]\n",
    "print(f\"bins uecFEV1: {bin}\")\n",
    "\n",
    "# Sample from bin\n",
    "fev1_means = uecFEV1.sample_from_bin(bin, 5000000)\n",
    "# Add gaussian noise\n",
    "ecfev1_vals = np.random.normal(fev1_means, uecfev1.sigma_fn(fev1_means))\n",
    "\n",
    "# Numerical solution\n",
    "cpt_dbl = np.zeros(ecFEV1.card)\n",
    "cpt_s = np.zeros(ecFEV1.card)\n",
    "for i, z in enumerate(ecFEV1.get_bins_arr()):\n",
    "    cpt_dbl[i] = uecfev1.p_uniform_x_gauss_add_mult_noise(\n",
    "        z[0], z[1], bin[0], bin[1], abserr_tol=1e-8\n",
    "    )\n",
    "    cpt_s[i] = uecfev1.PDF_conv_uni_gausian_add_mult(\n",
    "        (z[0] + z[1]) / 2, bin[0], bin[1], abserr_tol=1e-8\n",
    "    )\n",
    "\n",
    "cpt_dbl /= np.sum(cpt_dbl)\n",
    "cpt_s /= np.sum(cpt_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = go.Figure()\n",
    "xbins = dict(start=0, end=6, size=0.05)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=ecfev1_vals, xbins=xbins, histnorm=\"probability\", name=\"Sampling\")\n",
    ")\n",
    "fig.add_trace(go.Bar(x=ecFEV1.midbins, y=cpt_dbl, name=\"Double integral\"))\n",
    "fig.add_trace(go.Bar(x=ecFEV1.midbins, y=cpt_s, name=\"Midbin approximation\"))\n",
    "\n",
    "hist, _ = np.histogram(ecfev1_vals, bins=ecFEV1.midbins)\n",
    "\n",
    "# Print diff between sampling and double integral\n",
    "# print(f\"Diff between sampling and double integral: {cpt_dbl - cpt_s}\")\n",
    "\n",
    "title = f\"ecFEV1 noise for uecFEV1 = {bin}L\"\n",
    "fig.update_layout(title=title, height=300, width=700)\n",
    "fig.update_xaxes(title_text=ecFEV1.name, range=[2.7, 3.3])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show error nbetween dbl and sampling\n",
    "ecfev1_binned = ecFEV1.bin_up(ecfev1_vals, normalise=True)\n",
    "cpt_dbl - ecfev1_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute CPT with additive (symmetric) gauss noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong: this is the variability beteen 5-95th percentiles\n",
    "# std_gauss = 0.23\n",
    "# Median std from the variability analysis\n",
    "std_gauss = 0.068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 6, 0.05, prior={\"type\": \"uniform\"})\n",
    "uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 6, 0.05, prior=None)\n",
    "# ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 6, 1, prior=None)\n",
    "# uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 6, 1, prior=None)\n",
    "\n",
    "# Select bin that's no troubled by borders\n",
    "uecfev1_bin = uecFEV1.get_bins_arr()[uecFEV1.card // 2]\n",
    "print(\"uecFEV1 bin\", uecfev1_bin)\n",
    "# Get the PDF\n",
    "pdf = np.zeros(ecFEV1.card)\n",
    "for i, z in enumerate(ecFEV1.midbins):\n",
    "    pdf[i] = uecfev1.PDF_conv_uni_gausian_additive(\n",
    "        z, uecfev1_bin[0], uecfev1_bin[1], std_gauss, abserr_tol=1e-8\n",
    "    )\n",
    "# Norm the pdf\n",
    "pdf /= np.sum(pdf)\n",
    "pdftmp = pdf\n",
    "pdf = mh.get_p_in_log(uecFEV1, pdftmp)\n",
    "\n",
    "# The same PDF will be shifted across all uecFEV1/ ecFEV1 pairs\n",
    "# When hitting a border, the PDF will be truncated\n",
    "cpt = np.zeros((ecFEV1.card, uecFEV1.card))\n",
    "pdf_peek_idx = uecFEV1.card // 2\n",
    "for uecFEV1_idx, uecfev1_bin in enumerate(uecFEV1.get_bins_arr()):\n",
    "    pdf_trunc = np.zeros(len(pdf))\n",
    "    ecFEV1_idx_peek = uecFEV1_idx\n",
    "    peek_diff = pdf_peek_idx - ecFEV1_idx_peek\n",
    "    if peek_diff == 0:\n",
    "        pdf_trunc = pdf\n",
    "    elif peek_diff > 0:\n",
    "        pdf_trunc[0:-peek_diff] = pdf[peek_diff:]\n",
    "    else:\n",
    "        pdf_trunc[-peek_diff:] = pdf[:peek_diff]\n",
    "    # Norm the pdf\n",
    "    pdf_trunc /= np.sum(pdf_trunc)\n",
    "    cpt[:, uecFEV1_idx] = pdf_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.inference.helpers as ih\n",
    "\n",
    "# Import make subplots\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pdf with bins in ecFEV1\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "ih.plot_histogram(fig, ecFEV1, pdf, ecFEV1.a, 1, 1, 1)\n",
    "fig.update_xaxes(type=\"log\", row=1, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.cpts.helpers as cpth\n",
    "import src.data.helpers as dh\n",
    "\n",
    "fig, title = cpth.plot_2d_cpt(\n",
    "    cpt,\n",
    "    ecFEV1,\n",
    "    uecFEV1,\n",
    "    height=5500,\n",
    "    y_label_two_lines=True,\n",
    "    p_range=[0, 0.4],\n",
    "    vspace=0.003,\n",
    "    invert=False,\n",
    ")\n",
    "title = title + f\" for an ecFEV1 variability of {std_gauss}\"\n",
    "fig.update_layout(title=title)\n",
    "fig.show()\n",
    "\n",
    "# fig.write_image(f\"{dh.get_path_to_main()}PlotsBreathe/CPTs/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth.save_cpt([ecFEV1, uecFEV1], cpt, suffix=f\"_std_{std_gauss}_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute CPT with multiplicative (asymmetric) gauss noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 6, 0.05, prior={\"type\": \"uniform\"})\n",
    "uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 6, 0.05, prior=None)\n",
    "# ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 7, 0.2, prior=None)\n",
    "# uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 7, 0.2, prior=None)\n",
    "\n",
    "cpt = np.zeros((ecFEV1.card, uecFEV1.card))\n",
    "# Can't integrate from uecFEV1 = 0 to 0.05 because error is too big\n",
    "# I have to go through all states, because the std is prop to the value of uecFEV1\n",
    "for j, y in enumerate(uecFEV1.get_bins_arr()):\n",
    "    for i, z in enumerate(ecFEV1.get_bins_arr()):\n",
    "        cpt[i, j] = uecfev1.p_uniform_x_gauss_add_mult_noise(\n",
    "            z[0], z[1], y[0], y[1], abserr_tol=1e-8\n",
    "        )\n",
    "        # cpt[i, j] = uecfev1.PDF_conv_uni_gausian_add_mult(\n",
    "        #     (z[0] + z[1]) / 2, y[0], y[1], abserr_tol=1e-8\n",
    "        # )\n",
    "\n",
    "cpt /= cpt.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth.save_cpt([ecFEV1, uecFEV1], cpt, suffix=f\"_std_add_mult_ecfev1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute CPT with additive noise (for light model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecFEV1 = mh.VariableNode(\"ecFEV1 (L)\", 0, 6, 1, prior={\"type\": \"uniform\"})\n",
    "uecFEV1 = mh.VariableNode(\"Underlying ecFEV1 (L)\", 0, 6, 1, prior=None)\n",
    "\n",
    "std = 0.7\n",
    "cpt = np.zeros((ecFEV1.card, uecFEV1.card))\n",
    "# Can't integrate from uecFEV1 = 0 to 0.05 because error is too big\n",
    "# I have to go through all states, because the std is prop to the value of uecFEV1\n",
    "for j, y in enumerate(uecFEV1.get_bins_arr()):\n",
    "    for i, z in enumerate(ecFEV1.get_bins_arr()):\n",
    "        cpt[i, j] = uecfev1.p_uniform_x_gauss_add_noise(\n",
    "            z[0], z[1], y[0], y[1], std, abserr_tol=1e-8\n",
    "        )\n",
    "\n",
    "cpt /= cpt.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth.save_cpt([ecFEV1, uecFEV1], cpt, suffix=f\"_std{std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cpt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_midbin = cpth.get_cpt([ecFEV1, uecFEV1], suffix=f\"_std_add_mult_ecfev1_midbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_ecfev1 = cpth.get_cpt([ecFEV1, uecFEV1], suffix=f\"_std_add_mult_ecfev1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that cpt_midbin and cpt_ecfev1 are the same\n",
    "np.allclose(cpt_midbin, cpt_ecfev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLot the cpt\n",
    "import src.models.cpts.helpers as cpth\n",
    "\n",
    "fig, title = cpth.plot_2d_cpt(\n",
    "    cpt,\n",
    "    ecFEV1,\n",
    "    uecFEV1,\n",
    "    height=2000,\n",
    "    y_label_two_lines=True,\n",
    "    p_range=[0, 0.95],\n",
    "    vspace=0.002,\n",
    "    invert=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
