{"cells":[{"cell_type":"markdown","metadata":{},"source":["Idea of cutset conditioning: it's a way to run exact inference on a model with loops. You cut the loop by observing one of the variables in the loop to all the possible states, then fuse the results in a smart way.\n","\n"," Cutset Conditioning is a technique for solving nearly-tree-structured CSPs in which some variables are assigned to separately from the rest, removed from the constraint graph, and leaving a tree-structured CSP for those remaining.\n","\n"," Cutsets are some set of variables that are cut (severing edges) from the original constraint graph and solved separately.\n","\n"," Conditioning is the process of assigning a value to some variable in a cutset, performing forward checking on its neighbor domains before cutting, and finally, severing it from the original graph.\n","\n","https://forns.lmu.build/classes/spring-2019/cmsi-282/lecture-13M.html#backtracking++"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import src.data.breathe_data as bd\n","\n","# import src.inference.long_inf_slicing as slicing\n","import src.models.builders as mb\n","import src.data.helpers as dh\n","\n","# import src.models.var_builders as var_builders\n","import src.inference.helpers as ih\n","from plotly.subplots import make_subplots\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# import src.models.helpers as mh\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Figure per entry that has the AR from obs FEF2575 on top and on the bottom the point mass AR obtained by repeating model runs with several point mass HFEV1 (3, 3.5, 4, 4.5, 5, etc)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:* Checking for same day measurements *\n"]}],"source":["df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx\")\n","# df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_with_idx\")"]},{"cell_type":"markdown","metadata":{},"source":["# Visualisations of the alignment between the message from FEF25-75 and from FEV1/HFEV1 factors to AR"]},{"cell_type":"markdown","metadata":{},"source":["### Two plots"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# With each run I should retrieve\n","# 1/ the message from FEF25-75%FEFV1 to AR\n","# 2/ the point mass message from the factor ecFEV1, HFEV1 to AR\n","# Use the point in time model, there is no shared variables.\n","\n","\n","def can_messages_align_for_ID(df_for_ID):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    id = df_for_ID.loc[0, \"ID\"]\n","    (\n","        model,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    FEV_to_AR_key = \"['ecFEV1 (L)', 'Healthy FEV1 (L)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    FEF2575_to_AR_key = (\n","        \"['ecFEF25-75 % ecFEV1 (%)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    )\n","\n","    HFEV1_obs_list = [2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5]\n","    colour_list = px.colors.sample_colorscale(\n","        \"YlGnBu\", [i / (len(HFEV1_obs_list) - 1) for i in range(len(HFEV1_obs_list))]\n","    )\n","\n","    df_for_ID = df_for_ID.sort_values(by=\"ecFEF2575%ecFEV1\", ascending=True)\n","    # Take 4 idx in 5, 30, 60, 95 percentiles of the data\n","    idx_list = list((len(df_for_ID) * np.array([0.05, 0.5, 0.95])).astype(int))\n","    df_for_ID_sub = df_for_ID.iloc[idx_list, :]\n","\n","    res_per_idx = []\n","\n","    for idx in df_for_ID_sub.index:\n","        FEV1_obs = df_for_ID.loc[idx, \"ecFEV1\"]\n","        FEF2575prctFEV1_obs = df_for_ID.loc[idx, \"ecFEF2575%ecFEV1\"]\n","        FEV_m_list = []\n","\n","        # Query AR\n","        for HFEV1_obs in HFEV1_obs_list:\n","            # HFEV1_obs must be > ecFEV1_obs\n","            evidence = [\n","                [ecFEV1, FEV1_obs],\n","                [ecFEF2575prctecFEV1, FEF2575prctFEV1_obs],\n","                [HFEV1, HFEV1_obs],\n","            ]\n","            _, messages = ih.infer_on_factor_graph(\n","                inf_alg, [AR], evidence, get_messages=True\n","            )\n","\n","            FEV_m_list.append(messages[FEV_to_AR_key])\n","            FEF2575_m = messages[FEF2575_to_AR_key]\n","\n","        res_per_idx.append([FEV1_obs, FEF2575prctFEV1_obs, FEV_m_list, FEF2575_m])\n","\n","    fig = make_subplots(rows=6, cols=1, vertical_spacing=0.05)\n","    plot_row = 1\n","    for FEV1_obs, FEF2575prctFEV1_obs, FEV_m_list, FEF2575_m in res_per_idx:\n","\n","        for HFEV1_obs, FEV_m, colour in zip(HFEV1_obs_list, FEV_m_list, colour_list):\n","            ih.plot_histogram(\n","                fig,\n","                AR,\n","                FEV_m,\n","                AR.a,\n","                AR.b,\n","                plot_row,\n","                1,\n","                name=f\"HFEV1 = {HFEV1_obs}\",\n","                annot=False,\n","            )\n","            # Change the last trace's colour\n","            fig.data[-1].marker.color = colour\n","            # Hide legend if plot_row > 1\n","            if plot_row > 1:\n","                fig.data[-1].showlegend = False\n","\n","        ih.plot_histogram(\n","            fig,\n","            AR,\n","            FEF2575_m,\n","            AR.a,\n","            AR.b,\n","            plot_row + 1,\n","            1,\n","            annot=False,\n","            title=AR.name,\n","            colour=\"grey\",\n","        )\n","        # hide this last trace's legend\n","        fig.data[-1].showlegend = False\n","        # Add message from ecFEV1/HFEV1 factor on y axis row 1 title\n","        fig.update_yaxes(title_text=f\"ecFEV1<br>{FEV1_obs:.2f}L\", row=plot_row, col=1)\n","        fig.update_yaxes(\n","            title_text=f\"ecFEF25-75%ecFEV1<br>{FEF2575prctFEV1_obs:.2f}%\",\n","            row=plot_row + 1,\n","            col=1,\n","        )\n","        plot_row += 2\n","\n","    # Reduce font size and margins\n","    title = f\"ID {id} - Can points mass messages from HFEV1, ecFEV1 align with messages from FEF25-75\"\n","    # Reduce margins between plots\n","    fig.update_layout(\n","        font=dict(size=8),\n","        margin=dict(l=10, r=10, t=30, b=10),\n","        height=750,\n","        width=600,\n","        barmode=\"overlay\",\n","        bargap=0.1,\n","        title=title,\n","    )\n","    fig.update_xaxes(title_standoff=6)\n","\n","    fig.write_image(\n","        dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.pdf\"\n","    )\n","    # fig.show()\n","\n","\n","interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","# df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(can_messages_align_for_ID)\n","\n","df_for_ID = df[df.ID == \"101\"]\n","can_messages_align_for_ID(df_for_ID)"]},{"cell_type":"markdown","metadata":{},"source":["### Heatmaps of FEF2575 messages vs FEV1 messages for different HFEV1"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n"]},{"data":{"text/plain":["ID\n","101    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","117    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","131    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","132    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","134    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","139    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","146    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","177    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","180    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","191    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","201    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","202    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","203    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","253    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","272    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","405    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","527    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# With each run I should retrieve\n","# 1/ the message from FEF25-75%FEFV1 to AR\n","# 2/ the point mass message from the factor ecFEV1, HFEV1 to AR\n","# Use the point in time model, there is no shared variables.\n","\n","\n","def can_messages_align_for_ID_heatmap(df_for_ID, save=True):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    (\n","        model,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    FEV_to_AR_key = \"['ecFEV1 (L)', 'Healthy FEV1 (L)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    FEF2575_to_AR_key = (\n","        \"['ecFEF25-75 % ecFEV1 (%)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    )\n","\n","    HFEV1_obs_list = [2, 3, 4, 5]\n","    # Compare obs list to min obs fev1\n","    min_obs_fev1 = df_for_ID.ecFEV1.min()\n","    HFEV1_obs_list = [\n","        HFEV1_obs for HFEV1_obs in HFEV1_obs_list if HFEV1_obs > min_obs_fev1\n","    ]\n","\n","    # Dates on the xaxis, AR on the y axis\n","    FEV_m_arr = np.zeros((AR.card, len(df_for_ID)))\n","    FEF2575_m_arr = np.zeros((AR.card, len(df_for_ID)))\n","\n","    for i, row in df_for_ID.iterrows():\n","        FEV1_obs = row.ecFEV1\n","        FEF2575prctFEV1_obs = row[\"ecFEF2575%ecFEV1\"]\n","\n","        # Query AR\n","        FEV_m_one_day = np.zeros(AR.card)\n","        for HFEV1_obs in HFEV1_obs_list:\n","            # HFEV1_obs must be > ecFEV1_obs\n","            evidence = [\n","                [ecFEV1, FEV1_obs],\n","                [ecFEF2575prctecFEV1, FEF2575prctFEV1_obs],\n","                [HFEV1, HFEV1_obs],\n","            ]\n","            _, messages = ih.infer_on_factor_graph(\n","                inf_alg, [AR], evidence, get_messages=True\n","            )\n","\n","            # Since the messages are \"almost\" point mass (max over 2 bins)\n","            # we'll just put the value for the heatmap at the location of the mean\n","            AR_mean_val = AR.get_mean(messages[FEV_to_AR_key])\n","            AR_mean_idx = AR.get_bin_for_value(AR_mean_val)[1]\n","            # Add intensity value at the location of the AR mean\n","            FEV_m_one_day[AR_mean_idx] = HFEV1_obs\n","\n","        FEV_m_arr[:, i] = FEV_m_one_day\n","        fef2575_m = messages[FEF2575_to_AR_key]\n","        # Make sure the messages are normalised - yes it is the case indeed\n","        fef2575_m = fef2575_m / fef2575_m.sum()\n","        FEF2575_m_arr[:, i] = fef2575_m\n","\n","    df_for_ID[\"Date\"] = pd.to_datetime(df_for_ID[\"Date Recorded\"]).copy()\n","    df_for_ID[\"Date\"] = df_for_ID[\"Date\"].dt.strftime(\"%d-%m-%Y\")\n","\n","    fig = go.Figure(\n","        data=go.Heatmap(\n","            z=FEF2575_m_arr,\n","            x=df_for_ID[\"Date\"],\n","            y=AR.get_bins_str(),\n","            opacity=0.8,\n","            colorscale=\"Blues\",\n","            # Exclude from colour bar\n","            showscale=False,\n","        )\n","    )\n","\n","    colorscale = [\n","        [0, \"rgba(0, 0, 0, 0)\"],  # Transparent for value 0\n","        [1 / 5, \"rgba(0, 0, 0, 0)\"],  # Transparent for value 0\n","        [1 / 5, \"rgb(255, 245, 235)\"],  # Light orange for value 2\n","        [2 / 5, \"rgb(255, 245, 235)\"],  # Light orange for value 2\n","        [2 / 5, \"rgb(254, 230, 206)\"],  # Medium-light orange for value 3\n","        [3 / 5, \"rgb(254, 230, 206)\"],  # Medium-light orange for value 3\n","        [3 / 5, \"rgb(253, 174, 107)\"],  # Medium orange for value 4\n","        [4 / 5, \"rgb(253, 174, 107)\"],  # Medium orange for value 4\n","        [4 / 5, \"rgb(241, 105, 19)\"],  # Dark orange for value 5\n","        # [5/5, 'rgb(241, 105, 19)'],  # Dark orange for value 5\n","        # [5/5, 'rgb(217, 72, 1)'],  # Darker orange for value 6\n","        [1, \"rgb(217, 72, 1)\"],  # Darker orange for value 6\n","    ]\n","\n","    fig.add_traces(\n","        go.Heatmap(\n","            z=FEV_m_arr,\n","            x=df_for_ID[\"Date\"],\n","            y=AR.get_bins_str(),\n","            # Change colour\n","            colorscale=colorscale,\n","        )\n","    )\n","\n","    title = f\"{df_for_ID.loc[0, 'ID']} - Heatmaps messages alignment from HFEV1, ecFEV1 to AR and FEF25-75 to AR\"\n","    fig.update_layout(\n","        font=dict(size=6), height=600, width=len(df_for_ID) + 400, title=title\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=\"Date\", tickangle=45)\n","    fig.update_yaxes(title_text=\"Airway resistance (%)\")\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.png\",\n","            scale=3,\n","        )\n","    else:\n","        fig.show()\n","\n","    return fig, FEV_m_arr, FEF2575_m_arr\n","\n","\n","interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(can_messages_align_for_ID_heatmap)\n","\n","# df_for_ID = df[df.ID == \"191\"]\n","# fig, FEV_m_arr, FEF2575_m_arr = can_messages_align_for_ID_heatmap(df_for_ID, save=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Fusing the weights"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate computational speedup by avoiding to calculate doublons"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["(\n","    model,\n","    inf_alg,\n","    HFEV1,\n","    ecFEV1,\n","    AR,\n","    HO2Sat,\n","    O2SatFFA,\n","    IA,\n","    UO2Sat,\n","    O2Sat,\n","    ecFEF2575prctecFEV1,\n",") = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(120, 12, \"Male\")\n","\n","df[\"idx ecFEF2575%ecFEV1\"] = df.apply(\n","    lambda row: ecFEF2575prctecFEV1.get_bin_for_value(row[\"ecFEF2575%ecFEV1\"])[1],\n","    axis=1,\n",")"]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before: 688 min, After: 390 min. Speedup: 1.76\n"]}],"source":["def get_speedup_prct_for_id(df_for_ID):\n","    # How many entries have the same bin in ecFEV1 and ecFEF2575%ecFEV1\n","    # This trick wouldn't improve the computation time much\n","    n_repetitions = len(\n","        df_for_ID.groupby([\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"])\n","        .size()\n","        .sort_values(ascending=False)\n","    )\n","    # 10 min for 600 entries\n","    time_per_entry = 10 / 600\n","    return (\n","        len(df_for_ID) * time_per_entry,\n","        (1 - n_repetitions / len(df_for_ID)) * len(df_for_ID) * time_per_entry,\n","    )\n","\n","\n","times = df.groupby(\"ID\").apply(get_speedup_prct_for_id).sort_values(ascending=False)\n","\n","before = 0\n","after = 0\n","for i in range(len(times)):\n","    b, a = times.values[i]\n","    before += b\n","    after += a\n","print(f\"Before: {before:.0f} min, After: {after:.0f} min. Speedup: {before/after:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Actually fusing weights"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["def compute_log_p_D_given_M_per_entry_per_HFEV1_obs(df_for_ID, debug=False, save=False):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    (\n","        _,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        _,\n","        _,\n","        _,\n","        _,\n","        _,\n","        _,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    # HFEV1 can't be above max observed ecFEV1\n","    HFEV1_obs_list = HFEV1.midbins[\n","        HFEV1.midbins - HFEV1.bin_width / 2 >= df_for_ID.ecFEV1.max()\n","    ]\n","    print(\n","        f\"Number of observed states: {len(HFEV1_obs_list)}, max ecFEV1: {df_for_ID.ecFEV1.max()}, first possible bin for HFEV1: {HFEV1.get_bin_for_value(HFEV1_obs_list[0])[0]}\"\n","    )\n","\n","    ###\n","    # Speed up code by removing duplicates and adding them later on\n","    df_for_ID = df_for_ID.sort_values(by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], ascending=False)\n","    df_duplicates = df_for_ID.groupby([\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"]).size().reset_index()\n","    df_duplicates.columns = [\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\", \"n duplicates\"]\n","    df_duplicates = df_duplicates.sort_values(by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], ascending=False).reset_index(drop=True)\n","    n_dups = df_duplicates[\"n duplicates\"].values\n","    # Keep only the first entry for each pair of ecFEV1 and ecFEF2575%ecFEV1\n","    df_for_ID_no_duplicates = df_for_ID.drop_duplicates(subset=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], keep=\"first\")\n","    ###\n","\n","    log_p_D_given_M = np.zeros((len(HFEV1_obs_list), len(df_for_ID_no_duplicates)))\n","\n","    # Get the joint probability of ecFEV1 and ecFEF2575 given the model for this individual\n","    # For each entry\n","    for idx_row, row in df_for_ID_no_duplicates.iterrows():\n","        if debug:\n","            print(f\"Processing row {idx_row}\")\n","\n","        # For each model given an HFEV1 observation\n","        for idx_hfev1_bin, HFEV1_obs in enumerate(HFEV1_obs_list):\n","            # Getting the joint probability of ecFEF2575 and ecFEV1 under the model\n","            model_observation = [[HFEV1, HFEV1_obs]]\n","            res, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEV1, ecFEF2575prctecFEV1],\n","                model_observation,\n","                get_messages=True,\n","            )\n","            res_ecFEV1 = res[ecFEV1.name]\n","            res_ecFEF2575prctecFEV1 = res[ecFEF2575prctecFEV1.name]\n","\n","            # The probability of the data given the model is the expectation of the data given the model\n","            idx_obs_ecFEV1 = ecFEV1.get_bin_for_value(row.ecFEV1)[1]\n","            idx_obs_ecFEF2575 = ecFEF2575prctecFEV1.get_bin_for_value(\n","                row[\"ecFEF2575%ecFEV1\"]\n","            )[1]\n","\n","            # Get the probability of the data given the model\n","            p_ecFEV1 = res_ecFEV1.values[idx_obs_ecFEV1]\n","            p_ecFEF2575 = res_ecFEF2575prctecFEV1.values[idx_obs_ecFEF2575]\n","\n","            log_p_D_given_M[idx_hfev1_bin, idx_row] = np.log(p_ecFEV1) + np.log(\n","                p_ecFEF2575\n","            )\n","\n","    # Compute the constant Cn_arr\n","    H = len(HFEV1_obs_list)\n","    N = len(df_for_ID_no_duplicates)\n","    Cn_arr = np.zeros(N)\n","    for n, row in df_for_ID_no_duplicates.iterrows():\n","        Cn_arr[n] = -1 / H * (np.sum(log_p_D_given_M[:, n]) + 1)\n","    Cn_avg = np.mean(Cn_arr)\n","\n","    ###\n","    # Put back the duplicates\n","    # Repeat each element in the array by the number in the array dups\n","    Cn_avg = np.repeat(Cn_avg, n_dups)\n","    log_p_D_given_M = np.repeat(log_p_D_given_M, n_dups, axis=1)\n","    ###\n","\n","    # For each HFEV1 model, given HFEV1_obs_list, we compute the log probability of the model given the data\n","    log_p_M_given_D = np.zeros(H)\n","    for h, HFEV1_obs in enumerate(HFEV1_obs_list):\n","        log_p_M = np.log(HFEV1.cpt[HFEV1.get_bin_for_value(HFEV1_obs)[1]])\n","        log_p_M_given_D[h] = 1 / N * log_p_D_given_M[h, :].sum() + Cn_avg + log_p_M\n","\n","    # Exponentiating very negative numbers gives too small numbers\n","    # Setting the highest number to 1\n","    shift = 1 - log_p_M_given_D.max()\n","    log_p_M_given_D_shifted = log_p_M_given_D + shift\n","\n","    # Exponentiate and normalise\n","    p_M_given_D = np.exp(log_p_M_given_D_shifted)\n","    p_M_given_D = p_M_given_D / p_M_given_D.sum()\n","\n","    p_M_given_D_plot = np.zeros(HFEV1.card)\n","    HFEV1_obs_idx = [HFEV1.get_bin_for_value(HFEV1_obs)[1] for HFEV1_obs in HFEV1_obs_list]\n","    p_M_given_D_plot[HFEV1_obs_idx] = p_M_given_D\n","\n","    # Add plot\n","    fig = make_subplots(rows=1, cols=1)\n","\n","    ih.plot_histogram(fig, HFEV1, p_M_given_D_plot, 0, 6, 1, 1)\n","\n","    title = f\"{df_for_ID.loc[0, 'ID']} - Posterior probability of HFEV1 given the data (with speedup)\"\n","    fig.update_layout(\n","        font=dict(size=6),\n","        height=200,\n","        width=600,\n","        title=title,\n","        margin=dict(l=10, r=10, t=30, b=10),\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=HFEV1.name)\n","    fig.update_yaxes(title_text=\"p\")\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main()\n","            + f\"/PlotsBreathe/Cutset_conditioning/{title}.pdf\"\n","        )\n","    else:\n","        fig.show()\n","\n","    return p_M_given_D_plot, fig"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of observed states: 100, max ecFEV1: 0.92, first possible bin for HFEV1: [1.00; 1.05)\n"]},{"ename":"IndexError","evalue":"index 4 is out of bounds for axis 1 with size 4","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_for_ID \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mID \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m527\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m----> 2\u001b[0m p_M_given_D, fig \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_log_p_D_given_M_per_entry_per_HFEV1_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_for_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[83], line 70\u001b[0m, in \u001b[0;36mcompute_log_p_D_given_M_per_entry_per_HFEV1_obs\u001b[0;34m(df_for_ID, debug, save)\u001b[0m\n\u001b[1;32m     67\u001b[0m         p_ecFEV1 \u001b[38;5;241m=\u001b[39m res_ecFEV1\u001b[38;5;241m.\u001b[39mvalues[idx_obs_ecFEV1]\n\u001b[1;32m     68\u001b[0m         p_ecFEF2575 \u001b[38;5;241m=\u001b[39m res_ecFEF2575prctecFEV1\u001b[38;5;241m.\u001b[39mvalues[idx_obs_ecFEF2575]\n\u001b[0;32m---> 70\u001b[0m         log_p_D_given_M[idx_hfev1_bin, idx_row] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(p_ecFEV1) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m     71\u001b[0m             p_ecFEF2575\n\u001b[1;32m     72\u001b[0m         )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Compute the constant Cn_arr\u001b[39;00m\n\u001b[1;32m     75\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(HFEV1_obs_list)\n","\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"]}],"source":["df_for_ID = df[df.ID == \"527\"].reset_index()\n","p_M_given_D, fig = compute_log_p_D_given_M_per_entry_per_HFEV1_obs(df_for_ID, debug=False, save=True)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>ID</th>\n","      <th>Date Recorded</th>\n","      <th>FEV1</th>\n","      <th>O2 Saturation</th>\n","      <th>FEF2575</th>\n","      <th>ecFEV1</th>\n","      <th>ecFEF2575</th>\n","      <th>Sex</th>\n","      <th>Height</th>\n","      <th>...</th>\n","      <th>Predicted FEV1</th>\n","      <th>Healthy O2 Saturation</th>\n","      <th>ecFEV1 % Predicted</th>\n","      <th>FEV1 % Predicted</th>\n","      <th>O2 Saturation % Healthy</th>\n","      <th>ecFEF2575%ecFEV1</th>\n","      <th>Max ecFEV1</th>\n","      <th>Max ecFEF2575</th>\n","      <th>idx ecFEV1 (L)</th>\n","      <th>idx ecFEF2575%ecFEV1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40695</td>\n","      <td>527</td>\n","      <td>2022-05-24</td>\n","      <td>0.91</td>\n","      <td>93</td>\n","      <td>0.42</td>\n","      <td>0.91</td>\n","      <td>0.42</td>\n","      <td>Male</td>\n","      <td>182.0</td>\n","      <td>...</td>\n","      <td>4.845064</td>\n","      <td>96.988672</td>\n","      <td>18.782001</td>\n","      <td>18.782001</td>\n","      <td>95.887487</td>\n","      <td>46.153846</td>\n","      <td>0.92</td>\n","      <td>0.43</td>\n","      <td>18</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>40696</td>\n","      <td>527</td>\n","      <td>2022-05-25</td>\n","      <td>0.92</td>\n","      <td>94</td>\n","      <td>0.43</td>\n","      <td>0.92</td>\n","      <td>0.43</td>\n","      <td>Male</td>\n","      <td>182.0</td>\n","      <td>...</td>\n","      <td>4.845064</td>\n","      <td>96.988672</td>\n","      <td>18.988397</td>\n","      <td>18.988397</td>\n","      <td>96.918535</td>\n","      <td>46.739130</td>\n","      <td>0.92</td>\n","      <td>0.43</td>\n","      <td>18</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>40697</td>\n","      <td>527</td>\n","      <td>2022-05-26</td>\n","      <td>0.90</td>\n","      <td>95</td>\n","      <td>0.47</td>\n","      <td>0.90</td>\n","      <td>0.47</td>\n","      <td>Male</td>\n","      <td>182.0</td>\n","      <td>...</td>\n","      <td>4.845064</td>\n","      <td>96.988672</td>\n","      <td>18.575606</td>\n","      <td>18.575606</td>\n","      <td>97.949584</td>\n","      <td>52.222222</td>\n","      <td>0.92</td>\n","      <td>0.43</td>\n","      <td>18</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>40698</td>\n","      <td>527</td>\n","      <td>2022-05-27</td>\n","      <td>0.84</td>\n","      <td>93</td>\n","      <td>0.39</td>\n","      <td>0.84</td>\n","      <td>0.50</td>\n","      <td>Male</td>\n","      <td>182.0</td>\n","      <td>...</td>\n","      <td>4.845064</td>\n","      <td>96.988672</td>\n","      <td>17.337232</td>\n","      <td>17.337232</td>\n","      <td>95.887487</td>\n","      <td>46.428571</td>\n","      <td>0.92</td>\n","      <td>0.43</td>\n","      <td>16</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>40699</td>\n","      <td>527</td>\n","      <td>2022-05-30</td>\n","      <td>0.92</td>\n","      <td>90</td>\n","      <td>0.50</td>\n","      <td>0.92</td>\n","      <td>0.50</td>\n","      <td>Male</td>\n","      <td>182.0</td>\n","      <td>...</td>\n","      <td>4.845064</td>\n","      <td>96.988672</td>\n","      <td>18.988397</td>\n","      <td>18.988397</td>\n","      <td>92.794342</td>\n","      <td>54.347826</td>\n","      <td>0.92</td>\n","      <td>0.43</td>\n","      <td>18</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 21 columns</p>\n","</div>"],"text/plain":["   index   ID Date Recorded  FEV1  O2 Saturation  FEF2575  ecFEV1  ecFEF2575  \\\n","0  40695  527    2022-05-24  0.91             93     0.42    0.91       0.42   \n","1  40696  527    2022-05-25  0.92             94     0.43    0.92       0.43   \n","2  40697  527    2022-05-26  0.90             95     0.47    0.90       0.47   \n","3  40698  527    2022-05-27  0.84             93     0.39    0.84       0.50   \n","4  40699  527    2022-05-30  0.92             90     0.50    0.92       0.50   \n","\n","    Sex  Height  ...  Predicted FEV1  Healthy O2 Saturation  \\\n","0  Male   182.0  ...        4.845064              96.988672   \n","1  Male   182.0  ...        4.845064              96.988672   \n","2  Male   182.0  ...        4.845064              96.988672   \n","3  Male   182.0  ...        4.845064              96.988672   \n","4  Male   182.0  ...        4.845064              96.988672   \n","\n","   ecFEV1 % Predicted  FEV1 % Predicted  O2 Saturation % Healthy  \\\n","0           18.782001         18.782001                95.887487   \n","1           18.988397         18.988397                96.918535   \n","2           18.575606         18.575606                97.949584   \n","3           17.337232         17.337232                95.887487   \n","4           18.988397         18.988397                92.794342   \n","\n","   ecFEF2575%ecFEV1  Max ecFEV1  Max ecFEF2575  idx ecFEV1 (L)  \\\n","0         46.153846        0.92           0.43              18   \n","1         46.739130        0.92           0.43              18   \n","2         52.222222        0.92           0.43              18   \n","3         46.428571        0.92           0.43              16   \n","4         54.347826        0.92           0.43              18   \n","\n","   idx ecFEF2575%ecFEV1  \n","0                    23  \n","1                    23  \n","2                    26  \n","3                    23  \n","4                    27  \n","\n","[5 rows x 21 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_for_ID.head()"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["dups = df_duplicates[\"n duplicates\"].values"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["1680"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["dups = df_duplicates[\"n duplicates\"].values\n","a = np.arange(135)\n","# Repeat each element in the array by the number in the array dups\n","\n","b = np.repeat(a, dups)\n","len(b)"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"data":{"text/plain":["array([  2,   4,  12,   8,  21,  22,  13,   4,   2,   1,   3,   9,  24,\n","        50,  84, 115,  90,  86,  57,  21,   5,   1,   1,   1,   3,   4,\n","        15,  33,  45,  60,  71,  50,  28,  13,   8,   2,   1,   2,   6,\n","         6,  19,   7,  10,   6,   3,   3,   1,   1,   1,   2,   2,   1,\n","         4,   1,   1,   1,   1,   2,  12,  23,  51,  29,  14,   9,   4,\n","         1,   8,  13,   9,  14,   6,   5,   5,   3,   1,   1,   2,   6,\n","         4,  12,  11,   8,   6,   7,   6,   4,   4,   2,   6,   1,   1,\n","         1,   1,  13,  14,  31,  17,  39,  21,  12,   6,   8,   9,   5,\n","         1,   2,   1,   1,   3,   1,   6,   7,  11,  14,  14,  12,   7,\n","         4,  12,  13,  10,   4,   1,   1,   2,   2,   4,   5,   6,   7,\n","         5,   4,   4,   1,   1])"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["dups"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"phd","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
