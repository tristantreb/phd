{"cells":[{"cell_type":"markdown","metadata":{},"source":["Idea of cutset conditioning: it's a way to run exact inference on a model with loops. You cut the loop by observing one of the variables in the loop to all the possible states, then fuse the results in a smart way.\n","\n"," Cutset Conditioning is a technique for solving nearly-tree-structured CSPs in which some variables are assigned to separately from the rest, removed from the constraint graph, and leaving a tree-structured CSP for those remaining.\n","\n"," Cutsets are some set of variables that are cut (severing edges) from the original constraint graph and solved separately.\n","\n"," Conditioning is the process of assigning a value to some variable in a cutset, performing forward checking on its neighbor domains before cutting, and finally, severing it from the original graph.\n","\n","https://forns.lmu.build/classes/spring-2019/cmsi-282/lecture-13M.html#backtracking++"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import src.data.breathe_data as bd\n","\n","# import src.inference.long_inf_slicing as slicing\n","import src.models.builders as mb\n","import src.data.helpers as dh\n","\n","# import src.models.var_builders as var_builders\n","import src.inference.helpers as ih\n","from plotly.subplots import make_subplots\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# import src.models.helpers as mh\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Figure per entry that has the AR from obs FEF2575 on top and on the bottom the point mass AR obtained by repeating model runs with several point mass HFEV1 (3, 3.5, 4, 4.5, 5, etc)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:* Checking for same day measurements *\n"]}],"source":["df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx\")\n","# df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_with_idx\")"]},{"cell_type":"markdown","metadata":{},"source":["# Visualisations of the alignment between the message from FEF25-75 and from FEV1/HFEV1 factors to AR"]},{"cell_type":"markdown","metadata":{},"source":["### Two plots"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# With each run I should retrieve\n","# 1/ the message from FEF25-75%FEFV1 to AR\n","# 2/ the point mass message from the factor ecFEV1, HFEV1 to AR\n","# Use the point in time model, there is no shared variables.\n","\n","\n","def can_messages_align_for_ID(df_for_ID):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    id = df_for_ID.loc[0, \"ID\"]\n","    (\n","        model,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    FEV_to_AR_key = \"['ecFEV1 (L)', 'Healthy FEV1 (L)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    FEF2575_to_AR_key = (\n","        \"['ecFEF25-75 % ecFEV1 (%)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    )\n","\n","    HFEV1_obs_list = [2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5]\n","    colour_list = px.colors.sample_colorscale(\n","        \"YlGnBu\", [i / (len(HFEV1_obs_list) - 1) for i in range(len(HFEV1_obs_list))]\n","    )\n","\n","    df_for_ID = df_for_ID.sort_values(by=\"ecFEF2575%ecFEV1\", ascending=True)\n","    # Take 4 idx in 5, 30, 60, 95 percentiles of the data\n","    idx_list = list((len(df_for_ID) * np.array([0.05, 0.5, 0.95])).astype(int))\n","    df_for_ID_sub = df_for_ID.iloc[idx_list, :]\n","\n","    res_per_idx = []\n","\n","    for idx in df_for_ID_sub.index:\n","        FEV1_obs = df_for_ID.loc[idx, \"ecFEV1\"]\n","        FEF2575prctFEV1_obs = df_for_ID.loc[idx, \"ecFEF2575%ecFEV1\"]\n","        FEV_m_list = []\n","\n","        # Query AR\n","        for HFEV1_obs in HFEV1_obs_list:\n","            # HFEV1_obs must be > ecFEV1_obs\n","            evidence = [\n","                [ecFEV1, FEV1_obs],\n","                [ecFEF2575prctecFEV1, FEF2575prctFEV1_obs],\n","                [HFEV1, HFEV1_obs],\n","            ]\n","            _, messages = ih.infer_on_factor_graph(\n","                inf_alg, [AR], evidence, get_messages=True\n","            )\n","\n","            FEV_m_list.append(messages[FEV_to_AR_key])\n","            FEF2575_m = messages[FEF2575_to_AR_key]\n","\n","        res_per_idx.append([FEV1_obs, FEF2575prctFEV1_obs, FEV_m_list, FEF2575_m])\n","\n","    fig = make_subplots(rows=6, cols=1, vertical_spacing=0.05)\n","    plot_row = 1\n","    for FEV1_obs, FEF2575prctFEV1_obs, FEV_m_list, FEF2575_m in res_per_idx:\n","\n","        for HFEV1_obs, FEV_m, colour in zip(HFEV1_obs_list, FEV_m_list, colour_list):\n","            ih.plot_histogram(\n","                fig,\n","                AR,\n","                FEV_m,\n","                AR.a,\n","                AR.b,\n","                plot_row,\n","                1,\n","                name=f\"HFEV1 = {HFEV1_obs}\",\n","                annot=False,\n","            )\n","            # Change the last trace's colour\n","            fig.data[-1].marker.color = colour\n","            # Hide legend if plot_row > 1\n","            if plot_row > 1:\n","                fig.data[-1].showlegend = False\n","\n","        ih.plot_histogram(\n","            fig,\n","            AR,\n","            FEF2575_m,\n","            AR.a,\n","            AR.b,\n","            plot_row + 1,\n","            1,\n","            annot=False,\n","            title=AR.name,\n","            colour=\"grey\",\n","        )\n","        # hide this last trace's legend\n","        fig.data[-1].showlegend = False\n","        # Add message from ecFEV1/HFEV1 factor on y axis row 1 title\n","        fig.update_yaxes(title_text=f\"ecFEV1<br>{FEV1_obs:.2f}L\", row=plot_row, col=1)\n","        fig.update_yaxes(\n","            title_text=f\"ecFEF25-75%ecFEV1<br>{FEF2575prctFEV1_obs:.2f}%\",\n","            row=plot_row + 1,\n","            col=1,\n","        )\n","        plot_row += 2\n","\n","    # Reduce font size and margins\n","    title = f\"ID {id} - Can points mass messages from HFEV1, ecFEV1 align with messages from FEF25-75\"\n","    # Reduce margins between plots\n","    fig.update_layout(\n","        font=dict(size=8),\n","        margin=dict(l=10, r=10, t=30, b=10),\n","        height=750,\n","        width=600,\n","        barmode=\"overlay\",\n","        bargap=0.1,\n","        title=title,\n","    )\n","    fig.update_xaxes(title_standoff=6)\n","\n","    fig.write_image(\n","        dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.pdf\"\n","    )\n","    # fig.show()\n","\n","\n","interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","# df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(can_messages_align_for_ID)\n","\n","df_for_ID = df[df.ID == \"101\"]\n","can_messages_align_for_ID(df_for_ID)"]},{"cell_type":"markdown","metadata":{},"source":["### Heatmaps of FEF2575 messages vs FEV1 messages for different HFEV1"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n"]},{"data":{"text/plain":["ID\n","101    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","117    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","131    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","132    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","134    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","139    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","146    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","177    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","180    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","191    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","201    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","202    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","203    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","253    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","272    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","405    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","527    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# With each run I should retrieve\n","# 1/ the message from FEF25-75%FEFV1 to AR\n","# 2/ the point mass message from the factor ecFEV1, HFEV1 to AR\n","# Use the point in time model, there is no shared variables.\n","\n","\n","def can_messages_align_for_ID_heatmap(df_for_ID, save=True):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    (\n","        model,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    FEV_to_AR_key = \"['ecFEV1 (L)', 'Healthy FEV1 (L)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    FEF2575_to_AR_key = (\n","        \"['ecFEF25-75 % ecFEV1 (%)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    )\n","\n","    HFEV1_obs_list = [2, 3, 4, 5]\n","    # Compare obs list to min obs fev1\n","    min_obs_fev1 = df_for_ID.ecFEV1.min()\n","    HFEV1_obs_list = [\n","        HFEV1_obs for HFEV1_obs in HFEV1_obs_list if HFEV1_obs > min_obs_fev1\n","    ]\n","\n","    # Dates on the xaxis, AR on the y axis\n","    FEV_m_arr = np.zeros((AR.card, len(df_for_ID)))\n","    FEF2575_m_arr = np.zeros((AR.card, len(df_for_ID)))\n","\n","    for i, row in df_for_ID.iterrows():\n","        FEV1_obs = row.ecFEV1\n","        FEF2575prctFEV1_obs = row[\"ecFEF2575%ecFEV1\"]\n","\n","        # Query AR\n","        FEV_m_one_day = np.zeros(AR.card)\n","        for HFEV1_obs in HFEV1_obs_list:\n","            # HFEV1_obs must be > ecFEV1_obs\n","            evidence = [\n","                [ecFEV1, FEV1_obs],\n","                [ecFEF2575prctecFEV1, FEF2575prctFEV1_obs],\n","                [HFEV1, HFEV1_obs],\n","            ]\n","            _, messages = ih.infer_on_factor_graph(\n","                inf_alg, [AR], evidence, get_messages=True\n","            )\n","\n","            # Since the messages are \"almost\" point mass (max over 2 bins)\n","            # we'll just put the value for the heatmap at the location of the mean\n","            AR_mean_val = AR.get_mean(messages[FEV_to_AR_key])\n","            AR_mean_idx = AR.get_bin_for_value(AR_mean_val)[1]\n","            # Add intensity value at the location of the AR mean\n","            FEV_m_one_day[AR_mean_idx] = HFEV1_obs\n","\n","        FEV_m_arr[:, i] = FEV_m_one_day\n","        fef2575_m = messages[FEF2575_to_AR_key]\n","        # Make sure the messages are normalised - yes it is the case indeed\n","        fef2575_m = fef2575_m / fef2575_m.sum()\n","        FEF2575_m_arr[:, i] = fef2575_m\n","\n","    df_for_ID[\"Date\"] = pd.to_datetime(df_for_ID[\"Date Recorded\"]).copy()\n","    df_for_ID[\"Date\"] = df_for_ID[\"Date\"].dt.strftime(\"%d-%m-%Y\")\n","\n","    fig = go.Figure(\n","        data=go.Heatmap(\n","            z=FEF2575_m_arr,\n","            x=df_for_ID[\"Date\"],\n","            y=AR.get_bins_str(),\n","            opacity=0.8,\n","            colorscale=\"Blues\",\n","            # Exclude from colour bar\n","            showscale=False,\n","        )\n","    )\n","\n","    colorscale = [\n","        [0, \"rgba(0, 0, 0, 0)\"],  # Transparent for value 0\n","        [1 / 5, \"rgba(0, 0, 0, 0)\"],  # Transparent for value 0\n","        [1 / 5, \"rgb(255, 245, 235)\"],  # Light orange for value 2\n","        [2 / 5, \"rgb(255, 245, 235)\"],  # Light orange for value 2\n","        [2 / 5, \"rgb(254, 230, 206)\"],  # Medium-light orange for value 3\n","        [3 / 5, \"rgb(254, 230, 206)\"],  # Medium-light orange for value 3\n","        [3 / 5, \"rgb(253, 174, 107)\"],  # Medium orange for value 4\n","        [4 / 5, \"rgb(253, 174, 107)\"],  # Medium orange for value 4\n","        [4 / 5, \"rgb(241, 105, 19)\"],  # Dark orange for value 5\n","        # [5/5, 'rgb(241, 105, 19)'],  # Dark orange for value 5\n","        # [5/5, 'rgb(217, 72, 1)'],  # Darker orange for value 6\n","        [1, \"rgb(217, 72, 1)\"],  # Darker orange for value 6\n","    ]\n","\n","    fig.add_traces(\n","        go.Heatmap(\n","            z=FEV_m_arr,\n","            x=df_for_ID[\"Date\"],\n","            y=AR.get_bins_str(),\n","            # Change colour\n","            colorscale=colorscale,\n","        )\n","    )\n","\n","    title = f\"{df_for_ID.loc[0, 'ID']} - Heatmaps messages alignment from HFEV1, ecFEV1 to AR and FEF25-75 to AR\"\n","    fig.update_layout(\n","        font=dict(size=6), height=600, width=len(df_for_ID) + 400, title=title\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=\"Date\", tickangle=45)\n","    fig.update_yaxes(title_text=\"Airway resistance (%)\")\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.png\",\n","            scale=3,\n","        )\n","    else:\n","        fig.show()\n","\n","    return fig, FEV_m_arr, FEF2575_m_arr\n","\n","\n","interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(can_messages_align_for_ID_heatmap)\n","\n","# df_for_ID = df[df.ID == \"191\"]\n","# fig, FEV_m_arr, FEF2575_m_arr = can_messages_align_for_ID_heatmap(df_for_ID, save=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Fusing the weights"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate computational speedup by avoiding to calculate doublons"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["AR cpt shape: (45,), AR card 45\n"]}],"source":["(\n","    model,\n","    inf_alg,\n","    HFEV1,\n","    ecFEV1,\n","    AR,\n","    HO2Sat,\n","    O2SatFFA,\n","    IA,\n","    UO2Sat,\n","    O2Sat,\n","    ecFEF2575prctecFEV1,\n",") = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(120, 12, \"Male\")\n","\n","df[\"idx ecFEF2575%ecFEV1\"] = df.apply(\n","    lambda row: ecFEF2575prctecFEV1.get_bin_for_value(row[\"ecFEF2575%ecFEV1\"])[1],\n","    axis=1,\n",")"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before: 688 min, After: 298 min. Speedup: 2.31\n"]},{"data":{"text/plain":["ID\n","101                              (1680, 28.0, 135, 2.25)\n","123                 (1128, 18.8, 340, 5.666666666666667)\n","240                              (1101, 18.35, 228, 3.8)\n","133    (1066, 17.766666666666666, 343, 5.716666666666...\n","405                               (1035, 17.25, 60, 1.0)\n","                             ...                        \n","222    (1, 0.016666666666666666, 1, 0.016666666666666...\n","167    (1, 0.016666666666666666, 1, 0.016666666666666...\n","516    (1, 0.016666666666666666, 1, 0.016666666666666...\n","429    (1, 0.016666666666666666, 1, 0.016666666666666...\n","428    (1, 0.016666666666666666, 1, 0.016666666666666...\n","Length: 352, dtype: object"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["def get_speedup_prct_for_id(df_for_ID):\n","    # How many entries have the same bin in ecFEV1 and ecFEF2575%ecFEV1\n","    # This trick wouldn't improve the computation time much\n","    n_data_no_duplicates = len(\n","        df_for_ID.groupby([\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"])\n","        .size()\n","        .sort_values(ascending=False)\n","    )\n","    # 10 min for 600 entries\n","    time_per_entry = 10 / 600\n","    return (\n","        len(df_for_ID),\n","        len(df_for_ID) * time_per_entry,\n","        n_data_no_duplicates,\n","        n_data_no_duplicates * time_per_entry,\n","    )\n","\n","\n","times = df.groupby(\"ID\").apply(get_speedup_prct_for_id).sort_values(ascending=False)\n","\n","before = 0\n","after = 0\n","for i in range(len(times)):\n","    _, b, _, a = times.values[i]\n","    before += b\n","    after += a\n","print(f\"Before: {before:.0f} min, After: {after:.0f} min. Speedup: {before/after:.2f}\")\n","\n","times"]},{"cell_type":"markdown","metadata":{},"source":["### Actually fusing weights"]},{"cell_type":"code","execution_count":315,"metadata":{},"outputs":[],"source":["def compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","    df_for_ID_in, debug=False, save=False, speedup=True, ar_prior=\"uniform\"\n","):\n","    df_for_ID_in = df_for_ID_in.copy().reset_index(drop=True)\n","    id = df_for_ID_in.loc[0, \"ID\"]\n","    height = df_for_ID_in.loc[0, \"Height\"]\n","    age = df_for_ID_in.loc[0, \"Age\"]\n","    sex = df_for_ID_in.loc[0, \"Sex\"]\n","\n","    (\n","        _,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        _,\n","        _,\n","        _,\n","        _,\n","        _,\n","        _,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n","        height, age, sex, ar_prior=ar_prior\n","    )\n","\n","    # HFEV1 can't be above max observed ecFEV1\n","    HFEV1_obs_list = HFEV1.midbins[\n","        HFEV1.midbins - HFEV1.bin_width / 2 >= df_for_ID_in.ecFEV1.max()\n","    ]\n","    print(\n","        f\"ID {id} - Number of HFEV1 specific models: {len(HFEV1_obs_list)}, max ecFEV1: {df_for_ID_in.ecFEV1.max()}, first possible bin for HFEV1: {HFEV1.get_bin_for_value(HFEV1_obs_list[0])[0]}\"\n","    )\n","\n","    N = len(df_for_ID_in)\n","    df_for_ID = df_for_ID_in.copy()\n","\n","    # Speed up code by removing duplicates and adding them later on\n","    if speedup:\n","        print(f\"{N} entries before speedup\")\n","        df_for_ID = df_for_ID.sort_values(\n","            by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], ascending=False\n","        )\n","        df_duplicates = (\n","            df_for_ID.groupby([\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"])\n","            .size()\n","            .reset_index()\n","        )\n","        df_duplicates.columns = [\n","            \"idx ecFEV1 (L)\",\n","            \"idx ecFEF2575%ecFEV1\",\n","            \"n duplicates\",\n","        ]\n","        df_duplicates = df_duplicates.sort_values(\n","            by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], ascending=False\n","        ).reset_index(drop=True)\n","        n_dups = df_duplicates[\"n duplicates\"].values\n","        # Keep only the first entry for each pair of ecFEV1 and ecFEF2575%ecFEV1]\n","        # Create df_for_ID without duplicates\n","        df_for_ID = df_for_ID.drop_duplicates(\n","            subset=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], keep=\"first\"\n","        ).reset_index(drop=True)\n","        print(f\"{len(df_for_ID)} entries after speedup\")\n","        print(\n","            f\"Number of duplicates {N - len(df_for_ID)}, speedup removes {(N-len(df_for_ID))/N*100:.2f}% of entries\"\n","        )\n","\n","    H = len(HFEV1_obs_list)\n","    N_maybe_no_dups = len(df_for_ID) if speedup else N\n","    log_p_D_given_M = np.zeros((N_maybe_no_dups, H))\n","    p_D_given_M = np.zeros((N_maybe_no_dups, H))\n","    AR_dist_given_M_matrix = np.zeros((N_maybe_no_dups, AR.card, H))\n","\n","    # Get the joint probability of ecFEV1 and ecFEF2575 given the model for this individual\n","    # For each entry\n","    for n, row in df_for_ID.iterrows():\n","        if debug:\n","            print(f\"Processing row {n+1}/{N_maybe_no_dups}\")\n","\n","        # For each model given an HFEV1 observation\n","        for h, HFEV1_obs in enumerate(HFEV1_obs_list):\n","\n","            # Getting the joint probabilities of ecFEF2575 and ecFEV1 under the model\n","            res1, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEV1, ecFEF2575prctecFEV1],\n","                [[HFEV1, HFEV1_obs]],\n","                get_messages=True,\n","            )\n","            dist_ecFEV1 = res1[ecFEV1.name].values\n","\n","            # Observe both HFEV1 and ecFEV1 to compute the joint probability\n","            # P(ecFEV1, ecFEF2575 | HFEV1) = P(ecFEV1 | HFEV1) * P( ecFEF2575 | HFEV1, ecFEV1)\n","            res2, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEF2575prctecFEV1],\n","                [[HFEV1, HFEV1_obs], [ecFEV1, row.ecFEV1]],\n","                get_messages=True,\n","            )\n","            dist_ecFEF2575prctecFEV1 = res2[ecFEF2575prctecFEV1.name].values\n","\n","            res3, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [AR],\n","                [\n","                    [HFEV1, HFEV1_obs],\n","                    [ecFEV1, row.ecFEV1],\n","                    [ecFEF2575prctecFEV1, row[\"ecFEF2575%ecFEV1\"]],\n","                ],\n","                get_messages=True,\n","            )\n","            dist_AR = res3[AR.name].values\n","\n","            # The probability of the data given the model is the expectation of the data given the model\n","            idx_obs_ecFEV1 = ecFEV1.get_bin_for_value(row.ecFEV1)[1]\n","            idx_obs_ecFEF2575 = ecFEF2575prctecFEV1.get_bin_for_value(\n","                row[\"ecFEF2575%ecFEV1\"]\n","            )[1]\n","\n","            # Get the probability of the data given the model\n","            p_ecFEV1 = dist_ecFEV1[idx_obs_ecFEV1]\n","            p_ecFEF2575 = dist_ecFEF2575prctecFEV1[idx_obs_ecFEF2575]\n","\n","            # Save information for this round\n","            AR_dist_given_M_matrix[n, :, h] = dist_AR\n","            log_p_D_given_M[n, h] = np.log(p_ecFEV1) + np.log(p_ecFEF2575)\n","            p_D_given_M[n, h] = p_ecFEV1 * p_ecFEF2575\n","\n","    # Compute the constant Cn_arr\n","    # Cn_arr = np.zeros(N_maybe_no_dups)\n","    Cn_arr = np.zeros(N_maybe_no_dups)\n","    HFEV1_cpt_truncated = np.array(\n","        [\n","            HFEV1.cpt[HFEV1.get_bin_for_value(HFEV1_obs)[1]]\n","            for HFEV1_obs in HFEV1_obs_list\n","        ]\n","    )\n","    for n, row in df_for_ID.iterrows():\n","        Cn_arr[n] = -np.log(np.matmul(p_D_given_M[n, :], HFEV1_cpt_truncated))\n","\n","    if debug:\n","        print(\"log(P(D|M)), first row\", log_p_D_given_M[0, :])\n","        print(\"Cn_mean\", np.mean(Cn_arr))\n","\n","    if speedup:\n","        # Put back the duplicates\n","        # Repeat each element in the array by the number in the array dups\n","        log_p_D_given_M = np.repeat(log_p_D_given_M, n_dups, axis=0)\n","        Cn_arr = np.repeat(Cn_arr, n_dups)\n","        p_D_given_M = np.repeat(p_D_given_M, n_dups, axis=0)\n","        AR_dist_given_M_matrix = np.repeat(AR_dist_given_M_matrix, n_dups, axis=0)\n","        if debug:\n","            print(\"P(D|M), first row, after applying duplicates\", log_p_D_given_M[:, 0])\n","            print(\"Cn_mean after applying duplicates\", np.mean(Cn_arr))\n","\n","    # Cn avg is the constant averaged over all the data\n","    Cn_arr_avg = np.mean(Cn_arr)\n","\n","    # For each HFEV1 model, given HFEV1_obs_list, we compute the log probability of the model given the data\n","    # log(P(M|D)) = 1/N * sum_n log(P(D|M)) + Cn_avg + log(P(M))\n","    log_p_M_given_D = np.zeros(H)\n","    for h, HFEV1_obs in enumerate(HFEV1_obs_list):\n","        log_p_M = np.log(HFEV1.cpt[HFEV1.get_bin_for_value(HFEV1_obs)[1]])\n","        log_p_M_given_D[h] = np.sum(log_p_D_given_M[:, h]) + log_p_M  # + Cn_arr_avg\n","\n","    # Exponentiating very negative numbers gives too small numbers\n","    # Setting the highest number to 1\n","    shift = 1 - log_p_M_given_D.max()\n","    log_p_M_given_D_shifted = log_p_M_given_D + shift\n","\n","    # Exponentiate and normalise\n","    p_M_given_D = np.exp(log_p_M_given_D_shifted)\n","    p_M_given_D = p_M_given_D / p_M_given_D.sum()\n","\n","    # Fill the p(M|D) array with zeros on the left, where the HFEV1_obs < max ecFEV1\n","    p_M_given_D_full = np.zeros(HFEV1.card)\n","    HFEV1_obs_idx = [\n","        HFEV1.get_bin_for_value(HFEV1_obs)[1] for HFEV1_obs in HFEV1_obs_list\n","    ]\n","    p_M_given_D_full[HFEV1_obs_idx] = p_M_given_D\n","\n","    # Add plot\n","    layout = [\n","        [{\"type\": \"scatter\", \"rowspan\": 1, \"colspan\": 1}, None, None],\n","        [{\"type\": \"heatmap\", \"rowspan\": 3, \"colspan\": 3}, None, None],\n","        [None, None, None],\n","        [None, None, None],\n","    ]\n","    fig = make_subplots(\n","        rows=np.shape(layout)[0],\n","        cols=np.shape(layout)[1],\n","        specs=layout,\n","        vertical_spacing=0.1,\n","    )\n","\n","    # Add HFEV1 posterior\n","    ih.plot_histogram(fig, HFEV1, p_M_given_D_full, 0, 6, 1, 1, annot=True)\n","\n","    # Add heatmap with AR posteriors\n","    AR_dist_matrix = np.matmul(AR_dist_given_M_matrix, p_M_given_D)\n","    df1 = pd.DataFrame(\n","        data=AR_dist_matrix,\n","        columns=AR.get_bins_str(),\n","        index=df_for_ID_in[\"Date Recorded\"].apply(lambda date: date.strftime(\"%Y-%m-%d\")),\n","    )\n","    colorscale = [\n","        [0, \"white\"],\n","        [0.01, \"red\"],\n","        [0.05, \"yellow\"],\n","        [0.1, \"cyan\"],\n","        [0.6, \"blue\"],\n","        [1, \"black\"],\n","    ]\n","\n","    fig.add_trace(\n","        go.Heatmap(z=df1.T, x=df1.index, y=df1.columns, coloraxis=\"coloraxis1\"),\n","        row=2,\n","        col=1,\n","    )\n","\n","    speedup = \" (with speedup)\" if speedup else \"\"\n","\n","    title = f\"{id} - Posterior HFEV1 after fusing all P(M_h|D)<br>AR prior: {ar_prior}{speedup}\"\n","    fig.update_layout(\n","        font=dict(size=12),\n","        height=700,\n","        width=1200,\n","        title=title,\n","        coloraxis1=dict(\n","            colorscale=colorscale,\n","            colorbar_x=1,\n","            colorbar_y=0.36,\n","            # colorbar_thickness=23,\n","            colorbar_len=0.77,\n","        ),\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=HFEV1.name, row=1, col=1)\n","    fig.update_yaxes(title_text=\"p\", row=1, col=1)\n","    fig.update_yaxes(title_text=AR.name, row=2, col=1)\n","    fig.update_xaxes(\n","        title_text=\"Date\",\n","        row=2,\n","        col=1,\n","        nticks=50,\n","        type=\"category\",\n","    )\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.png\", scale=3\n","        )\n","    else:\n","        fig.show()\n","\n","    return fig, p_M_given_D_full, p_M_given_D, AR_dist_given_M_matrix"]},{"cell_type":"code","execution_count":316,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["AR cpt shape: (45,), AR card 45\n","ID 513 - Number of HFEV1 specific models: 52, max ecFEV1: 3.37, first possible bin for HFEV1: [3.40; 3.45)\n","16 entries before speedup\n","15 entries after speedup\n","Number of duplicates 1, speedup removes 6.25% of entries\n"]}],"source":["ar_prior = \"breathe (2 days model, ecFEV1, ecFEF25-75)\"\n","# ar_prior = \"uniform\"\n","# p_M_given_D_plot, fig = compute_log_p_D_given_M_per_entry_per_HFEV1_obs(dftmp, debug=False, save=False, speedup=True, ar_prior=ar_prior)\n","\n","dftmp = df[df.ID == \"513\"]\n","fig, p_M_given_D_full, p_M_given_D, AR_dist_given_M_matrix = (\n","    compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","        dftmp, debug=False, save=True, speedup=True, ar_prior=ar_prior\n","    )\n",")"]},{"cell_type":"code","execution_count":317,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["AR cpt shape: (45,), AR card 45\n","ID 101 - Number of HFEV1 specific models: 84, max ecFEV1: 1.79, first possible bin for HFEV1: [1.80; 1.85)\n","1680 entries before speedup\n","135 entries after speedup\n","Number of duplicates 1545, speedup removes 91.96% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 117 - Number of HFEV1 specific models: 62, max ecFEV1: 2.88, first possible bin for HFEV1: [2.90; 2.95)\n","270 entries before speedup\n","195 entries after speedup\n","Number of duplicates 75, speedup removes 27.78% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 131 - Number of HFEV1 specific models: 73, max ecFEV1: 2.32, first possible bin for HFEV1: [2.35; 2.40)\n","29 entries before speedup\n","25 entries after speedup\n","Number of duplicates 4, speedup removes 13.79% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 132 - Number of HFEV1 specific models: 81, max ecFEV1: 1.93, first possible bin for HFEV1: [1.95; 2.00)\n","27 entries before speedup\n","18 entries after speedup\n","Number of duplicates 9, speedup removes 33.33% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 134 - Number of HFEV1 specific models: 35, max ecFEV1: 4.24, first possible bin for HFEV1: [4.25; 4.30)\n","97 entries before speedup\n","83 entries after speedup\n","Number of duplicates 14, speedup removes 14.43% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 139 - Number of HFEV1 specific models: 81, max ecFEV1: 1.95, first possible bin for HFEV1: [1.95; 2.00)\n","276 entries before speedup\n","148 entries after speedup\n","Number of duplicates 128, speedup removes 46.38% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 146 - Number of HFEV1 specific models: 72, max ecFEV1: 2.38, first possible bin for HFEV1: [2.40; 2.45)\n","278 entries before speedup\n","169 entries after speedup\n","Number of duplicates 109, speedup removes 39.21% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 177 - Number of HFEV1 specific models: 52, max ecFEV1: 3.39, first possible bin for HFEV1: [3.40; 3.45)\n","251 entries before speedup\n","95 entries after speedup\n","Number of duplicates 156, speedup removes 62.15% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 180 - Number of HFEV1 specific models: 77, max ecFEV1: 2.15, first possible bin for HFEV1: [2.15; 2.20)\n","262 entries before speedup\n","93 entries after speedup\n","Number of duplicates 169, speedup removes 64.50% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 191 - Number of HFEV1 specific models: 53, max ecFEV1: 3.31, first possible bin for HFEV1: [3.35; 3.40)\n","213 entries before speedup\n","157 entries after speedup\n","Number of duplicates 56, speedup removes 26.29% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 201 - Number of HFEV1 specific models: 69, max ecFEV1: 2.51, first possible bin for HFEV1: [2.55; 2.60)\n","509 entries before speedup\n","224 entries after speedup\n","Number of duplicates 285, speedup removes 55.99% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 202 - Number of HFEV1 specific models: 53, max ecFEV1: 3.31, first possible bin for HFEV1: [3.35; 3.40)\n","130 entries before speedup\n","94 entries after speedup\n","Number of duplicates 36, speedup removes 27.69% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 203 - Number of HFEV1 specific models: 78, max ecFEV1: 2.1, first possible bin for HFEV1: [2.10; 2.15)\n","845 entries before speedup\n","111 entries after speedup\n","Number of duplicates 734, speedup removes 86.86% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 253 - Number of HFEV1 specific models: 93, max ecFEV1: 1.35, first possible bin for HFEV1: [1.35; 1.40)\n","60 entries before speedup\n","35 entries after speedup\n","Number of duplicates 25, speedup removes 41.67% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 272 - Number of HFEV1 specific models: 83, max ecFEV1: 1.85, first possible bin for HFEV1: [1.85; 1.90)\n","800 entries before speedup\n","245 entries after speedup\n","Number of duplicates 555, speedup removes 69.38% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 405 - Number of HFEV1 specific models: 65, max ecFEV1: 2.75, first possible bin for HFEV1: [2.75; 2.80)\n","1035 entries before speedup\n","60 entries after speedup\n","Number of duplicates 975, speedup removes 94.20% of entries\n","AR cpt shape: (45,), AR card 45\n","ID 527 - Number of HFEV1 specific models: 100, max ecFEV1: 0.92, first possible bin for HFEV1: [1.00; 1.05)\n","5 entries before speedup\n","4 entries after speedup\n","Number of duplicates 1, speedup removes 20.00% of entries\n"]},{"data":{"text/plain":["ID\n","101    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","117    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","131    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","132    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","134    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","139    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","146    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","177    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","180    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","191    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","201    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","202    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","203    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","253    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","272    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","405    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","527    (Figure({\\n    'data': [{'histfunc': 'sum',\\n ...\n","dtype: object"]},"execution_count":317,"metadata":{},"output_type":"execute_result"}],"source":["interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","# ar_prior = \"breathe (2 days model, ecFEV1, ecFEF25-75)\"\n","ar_prior = \"uniform\"\n","\n","df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(\n","    lambda df: compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","        df, debug=False, save=True, speedup=True, ar_prior=ar_prior\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_for_ID = df[df.ID == \"131\"]\n","p_M_given_D, fig = compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","    df_for_ID, debug=True, save=False, speedup=False\n",")"]}],"metadata":{"kernelspec":{"display_name":"phd","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
