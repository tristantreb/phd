{"cells":[{"cell_type":"markdown","metadata":{},"source":["Idea of cutset conditioning: it's a way to run exact inference on a model with loops. You cut the loop by observing one of the variables in the loop to all the possible states, then fuse the results in a smart way.\n","\n"," Cutset Conditioning is a technique for solving nearly-tree-structured CSPs in which some variables are assigned to separately from the rest, removed from the constraint graph, and leaving a tree-structured CSP for those remaining.\n","\n"," Cutsets are some set of variables that are cut (severing edges) from the original constraint graph and solved separately.\n","\n"," Conditioning is the process of assigning a value to some variable in a cutset, performing forward checking on its neighbor domains before cutting, and finally, severing it from the original graph.\n","\n","https://forns.lmu.build/classes/spring-2019/cmsi-282/lecture-13M.html#backtracking++"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import src.data.breathe_data as bd\n","\n","# import src.inference.long_inf_slicing as slicing\n","import src.models.builders as mb\n","import src.data.helpers as dh\n","\n","# import src.models.var_builders as var_builders\n","import src.inference.helpers as ih\n","from plotly.subplots import make_subplots\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","# import src.models.helpers as mh\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Figure per entry that has the AR from obs FEF2575 on top and on the bottom the point mass AR obtained by repeating model runs with several point mass HFEV1 (3, 3.5, 4, 4.5, 5, etc)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:* Checking for same day measurements *\n"]}],"source":["df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx\")\n","# df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_with_idx\")"]},{"cell_type":"markdown","metadata":{},"source":["# Visualisations of the alignment between the message from FEF25-75 and from FEV1/HFEV1 factors to AR"]},{"cell_type":"markdown","metadata":{},"source":["### Two plots"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# With each run I should retrieve\n","# 1/ the message from FEF25-75%FEFV1 to AR\n","# 2/ the point mass message from the factor ecFEV1, HFEV1 to AR\n","# Use the point in time model, there is no shared variables.\n","\n","\n","def can_messages_align_for_ID(df_for_ID):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    id = df_for_ID.loc[0, \"ID\"]\n","    (\n","        model,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    FEV_to_AR_key = \"['ecFEV1 (L)', 'Healthy FEV1 (L)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    FEF2575_to_AR_key = (\n","        \"['ecFEF25-75 % ecFEV1 (%)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    )\n","\n","    HFEV1_obs_list = [2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5]\n","    colour_list = px.colors.sample_colorscale(\n","        \"YlGnBu\", [i / (len(HFEV1_obs_list) - 1) for i in range(len(HFEV1_obs_list))]\n","    )\n","\n","    df_for_ID = df_for_ID.sort_values(by=\"ecFEF2575%ecFEV1\", ascending=True)\n","    # Take 4 idx in 5, 30, 60, 95 percentiles of the data\n","    idx_list = list((len(df_for_ID) * np.array([0.05, 0.5, 0.95])).astype(int))\n","    df_for_ID_sub = df_for_ID.iloc[idx_list, :]\n","\n","    res_per_idx = []\n","\n","    for idx in df_for_ID_sub.index:\n","        FEV1_obs = df_for_ID.loc[idx, \"ecFEV1\"]\n","        FEF2575prctFEV1_obs = df_for_ID.loc[idx, \"ecFEF2575%ecFEV1\"]\n","        FEV_m_list = []\n","\n","        # Query AR\n","        for HFEV1_obs in HFEV1_obs_list:\n","            # HFEV1_obs must be > ecFEV1_obs\n","            evidence = [\n","                [ecFEV1, FEV1_obs],\n","                [ecFEF2575prctecFEV1, FEF2575prctFEV1_obs],\n","                [HFEV1, HFEV1_obs],\n","            ]\n","            _, messages = ih.infer_on_factor_graph(\n","                inf_alg, [AR], evidence, get_messages=True\n","            )\n","\n","            FEV_m_list.append(messages[FEV_to_AR_key])\n","            FEF2575_m = messages[FEF2575_to_AR_key]\n","\n","        res_per_idx.append([FEV1_obs, FEF2575prctFEV1_obs, FEV_m_list, FEF2575_m])\n","\n","    fig = make_subplots(rows=6, cols=1, vertical_spacing=0.05)\n","    plot_row = 1\n","    for FEV1_obs, FEF2575prctFEV1_obs, FEV_m_list, FEF2575_m in res_per_idx:\n","\n","        for HFEV1_obs, FEV_m, colour in zip(HFEV1_obs_list, FEV_m_list, colour_list):\n","            ih.plot_histogram(\n","                fig,\n","                AR,\n","                FEV_m,\n","                AR.a,\n","                AR.b,\n","                plot_row,\n","                1,\n","                name=f\"HFEV1 = {HFEV1_obs}\",\n","                annot=False,\n","            )\n","            # Change the last trace's colour\n","            fig.data[-1].marker.color = colour\n","            # Hide legend if plot_row > 1\n","            if plot_row > 1:\n","                fig.data[-1].showlegend = False\n","\n","        ih.plot_histogram(\n","            fig,\n","            AR,\n","            FEF2575_m,\n","            AR.a,\n","            AR.b,\n","            plot_row + 1,\n","            1,\n","            annot=False,\n","            title=AR.name,\n","            colour=\"grey\",\n","        )\n","        # hide this last trace's legend\n","        fig.data[-1].showlegend = False\n","        # Add message from ecFEV1/HFEV1 factor on y axis row 1 title\n","        fig.update_yaxes(title_text=f\"ecFEV1<br>{FEV1_obs:.2f}L\", row=plot_row, col=1)\n","        fig.update_yaxes(\n","            title_text=f\"ecFEF25-75%ecFEV1<br>{FEF2575prctFEV1_obs:.2f}%\",\n","            row=plot_row + 1,\n","            col=1,\n","        )\n","        plot_row += 2\n","\n","    # Reduce font size and margins\n","    title = f\"ID {id} - Can points mass messages from HFEV1, ecFEV1 align with messages from FEF25-75\"\n","    # Reduce margins between plots\n","    fig.update_layout(\n","        font=dict(size=8),\n","        margin=dict(l=10, r=10, t=30, b=10),\n","        height=750,\n","        width=600,\n","        barmode=\"overlay\",\n","        bargap=0.1,\n","        title=title,\n","    )\n","    fig.update_xaxes(title_standoff=6)\n","\n","    fig.write_image(\n","        dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.pdf\"\n","    )\n","    # fig.show()\n","\n","\n","interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","# df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(can_messages_align_for_ID)\n","\n","df_for_ID = df[df.ID == \"101\"]\n","can_messages_align_for_ID(df_for_ID)"]},{"cell_type":"markdown","metadata":{},"source":["### Heatmaps of FEF2575 messages vs FEV1 messages for different HFEV1"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n","/Users/tristan.trebaol/Desktop/PhD/Code/pgmpy/pgmpy/inference/ExactInference.py:1562: RuntimeWarning:\n","\n","invalid value encountered in divide\n","\n"]},{"data":{"text/plain":["ID\n","101    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","117    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","131    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","132    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","134    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","139    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","146    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","177    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","180    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","191    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","201    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","202    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","203    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","253    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","272    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","405    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","527    (Figure({\\n    'data': [{'colorscale': [[0.0, ...\n","dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# With each run I should retrieve\n","# 1/ the message from FEF25-75%FEFV1 to AR\n","# 2/ the point mass message from the factor ecFEV1, HFEV1 to AR\n","# Use the point in time model, there is no shared variables.\n","\n","\n","def can_messages_align_for_ID_heatmap(df_for_ID, save=True):\n","    df_for_ID.reset_index(inplace=True, drop=True)\n","    height = df_for_ID.loc[0, \"Height\"]\n","    age = df_for_ID.loc[0, \"Age\"]\n","    sex = df_for_ID.loc[0, \"Sex\"]\n","    (\n","        model,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(height, age, sex)\n","\n","    FEV_to_AR_key = \"['ecFEV1 (L)', 'Healthy FEV1 (L)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    FEF2575_to_AR_key = (\n","        \"['ecFEF25-75 % ecFEV1 (%)', 'Airway resistance (%)'] -> Airway resistance (%)\"\n","    )\n","\n","    HFEV1_obs_list = [2, 3, 4, 5]\n","    # Compare obs list to min obs fev1\n","    min_obs_fev1 = df_for_ID.ecFEV1.min()\n","    HFEV1_obs_list = [\n","        HFEV1_obs for HFEV1_obs in HFEV1_obs_list if HFEV1_obs > min_obs_fev1\n","    ]\n","\n","    # Dates on the xaxis, AR on the y axis\n","    FEV_m_arr = np.zeros((AR.card, len(df_for_ID)))\n","    FEF2575_m_arr = np.zeros((AR.card, len(df_for_ID)))\n","\n","    for i, row in df_for_ID.iterrows():\n","        FEV1_obs = row.ecFEV1\n","        FEF2575prctFEV1_obs = row[\"ecFEF2575%ecFEV1\"]\n","\n","        # Query AR\n","        FEV_m_one_day = np.zeros(AR.card)\n","        for HFEV1_obs in HFEV1_obs_list:\n","            # HFEV1_obs must be > ecFEV1_obs\n","            evidence = [\n","                [ecFEV1, FEV1_obs],\n","                [ecFEF2575prctecFEV1, FEF2575prctFEV1_obs],\n","                [HFEV1, HFEV1_obs],\n","            ]\n","            _, messages = ih.infer_on_factor_graph(\n","                inf_alg, [AR], evidence, get_messages=True\n","            )\n","\n","            # Since the messages are \"almost\" point mass (max over 2 bins)\n","            # we'll just put the value for the heatmap at the location of the mean\n","            AR_mean_val = AR.get_mean(messages[FEV_to_AR_key])\n","            AR_mean_idx = AR.get_bin_for_value(AR_mean_val)[1]\n","            # Add intensity value at the location of the AR mean\n","            FEV_m_one_day[AR_mean_idx] = HFEV1_obs\n","\n","        FEV_m_arr[:, i] = FEV_m_one_day\n","        fef2575_m = messages[FEF2575_to_AR_key]\n","        # Make sure the messages are normalised - yes it is the case indeed\n","        fef2575_m = fef2575_m / fef2575_m.sum()\n","        FEF2575_m_arr[:, i] = fef2575_m\n","\n","    df_for_ID[\"Date\"] = pd.to_datetime(df_for_ID[\"Date Recorded\"]).copy()\n","    df_for_ID[\"Date\"] = df_for_ID[\"Date\"].dt.strftime(\"%d-%m-%Y\")\n","\n","    fig = go.Figure(\n","        data=go.Heatmap(\n","            z=FEF2575_m_arr,\n","            x=df_for_ID[\"Date\"],\n","            y=AR.get_bins_str(),\n","            opacity=0.8,\n","            colorscale=\"Blues\",\n","            # Exclude from colour bar\n","            showscale=False,\n","        )\n","    )\n","\n","    colorscale = [\n","        [0, \"rgba(0, 0, 0, 0)\"],  # Transparent for value 0\n","        [1 / 5, \"rgba(0, 0, 0, 0)\"],  # Transparent for value 0\n","        [1 / 5, \"rgb(255, 245, 235)\"],  # Light orange for value 2\n","        [2 / 5, \"rgb(255, 245, 235)\"],  # Light orange for value 2\n","        [2 / 5, \"rgb(254, 230, 206)\"],  # Medium-light orange for value 3\n","        [3 / 5, \"rgb(254, 230, 206)\"],  # Medium-light orange for value 3\n","        [3 / 5, \"rgb(253, 174, 107)\"],  # Medium orange for value 4\n","        [4 / 5, \"rgb(253, 174, 107)\"],  # Medium orange for value 4\n","        [4 / 5, \"rgb(241, 105, 19)\"],  # Dark orange for value 5\n","        # [5/5, 'rgb(241, 105, 19)'],  # Dark orange for value 5\n","        # [5/5, 'rgb(217, 72, 1)'],  # Darker orange for value 6\n","        [1, \"rgb(217, 72, 1)\"],  # Darker orange for value 6\n","    ]\n","\n","    fig.add_traces(\n","        go.Heatmap(\n","            z=FEV_m_arr,\n","            x=df_for_ID[\"Date\"],\n","            y=AR.get_bins_str(),\n","            # Change colour\n","            colorscale=colorscale,\n","        )\n","    )\n","\n","    title = f\"{df_for_ID.loc[0, 'ID']} - Heatmaps messages alignment from HFEV1, ecFEV1 to AR and FEF25-75 to AR\"\n","    fig.update_layout(\n","        font=dict(size=6), height=600, width=len(df_for_ID) + 400, title=title\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=\"Date\", tickangle=45)\n","    fig.update_yaxes(title_text=\"Airway resistance (%)\")\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.png\",\n","            scale=3,\n","        )\n","    else:\n","        fig.show()\n","\n","    return fig, FEV_m_arr, FEF2575_m_arr\n","\n","\n","interesting_ids = [\n","    \"132\",\n","    \"146\",\n","    \"177\",\n","    \"180\",\n","    \"202\",\n","    \"527\",\n","    \"117\",\n","    \"131\",\n","    \"134\",\n","    \"191\",\n","    \"139\",\n","    \"253\",\n","    \"101\",\n","    # Also from consec values\n","    \"405\",\n","    \"272\",\n","    \"201\",\n","    \"203\",\n","]\n","\n","df[df.ID.isin(interesting_ids)].groupby(\"ID\").apply(can_messages_align_for_ID_heatmap)\n","\n","# df_for_ID = df[df.ID == \"191\"]\n","# fig, FEV_m_arr, FEF2575_m_arr = can_messages_align_for_ID_heatmap(df_for_ID, save=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Fusing the weights"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate computational speedup by avoiding to calculate doublons"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["(\n","    model,\n","    inf_alg,\n","    HFEV1,\n","    ecFEV1,\n","    AR,\n","    HO2Sat,\n","    O2SatFFA,\n","    IA,\n","    UO2Sat,\n","    O2Sat,\n","    ecFEF2575prctecFEV1,\n",") = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(120, 12, \"Male\")"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before: 14 h, After: 9 h. Speedup: 1.56\n","Before: 41260, After: 26456. Speedup: 1.56\n"]},{"data":{"text/plain":["ID\n","101      (1680, 2100.0, 206, 257.5)\n","123     (1128, 1410.0, 601, 751.25)\n","240    (1101, 1376.25, 509, 636.25)\n","133      (1066, 1332.5, 502, 627.5)\n","405     (1035, 1293.75, 234, 292.5)\n","                   ...             \n","225              (1, 1.25, 1, 1.25)\n","213              (1, 1.25, 1, 1.25)\n","516              (1, 1.25, 1, 1.25)\n","160              (1, 1.25, 1, 1.25)\n","428              (1, 1.25, 1, 1.25)\n","Length: 352, dtype: object"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["def get_speedup_prct_for_id(df_for_ID):\n","    # How many entries have the same bin in ecFEV1 and ecFEF2575%ecFEV1\n","    # This trick wouldn't improve the computation time much\n","    n_data_no_duplicates = len(\n","        df_for_ID.groupby(\n","            [\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\", \"idx O2 saturation (%)\"]\n","        )\n","        .size()\n","        .sort_values(ascending=False)\n","    )\n","    # 10 s for 10 entries\n","    time_per_entry = 12.5 / 10\n","    return (\n","        len(df_for_ID),\n","        len(df_for_ID) * time_per_entry,\n","        n_data_no_duplicates,\n","        n_data_no_duplicates * time_per_entry,\n","    )\n","\n","\n","times = df.groupby(\"ID\").apply(get_speedup_prct_for_id).sort_values(ascending=False)\n","\n","t_before = 0\n","t_after = 0\n","n_before = 0\n","n_after = 0\n","for i in range(len(times)):\n","    n_ops_b, t_ops_b, n_ops_a, t_ops_a = times.values[i]\n","    t_before += t_ops_b\n","    t_after += t_ops_a\n","    n_before += n_ops_b\n","    n_after += n_ops_a\n","print(\n","    f\"Before: {t_before/3600:.0f} h, After: {t_after/3600:.0f} h. Speedup: {t_before/t_after:.2f}\"\n",")\n","print(f\"Before: {n_before}, After: {n_after:}. Speedup: {n_before/n_after:.2f}\")\n","\n","times"]},{"cell_type":"markdown","metadata":{},"source":["### Actually fusing weights"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","    df_for_ID_in, debug=False, save=False, speedup=True, ar_prior=\"uniform\"\n","):\n","    df_for_ID_in = df_for_ID_in.copy().reset_index(drop=True)\n","    id = df_for_ID_in.loc[0, \"ID\"]\n","    height = df_for_ID_in.loc[0, \"Height\"]\n","    age = df_for_ID_in.loc[0, \"Age\"]\n","    sex = df_for_ID_in.loc[0, \"Sex\"]\n","\n","    (\n","        _,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        _,\n","        _,\n","        _,\n","        _,\n","        _,\n","        _,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n","        height, age, sex, ar_prior=ar_prior\n","    )\n","\n","    # HFEV1 can't be above max observed ecFEV1\n","    HFEV1_obs_list = HFEV1.midbins[\n","        HFEV1.midbins - HFEV1.bin_width / 2 >= df_for_ID_in.ecFEV1.max()\n","    ]\n","    print(\n","        f\"ID {id} - Number of HFEV1 specific models: {len(HFEV1_obs_list)}, max ecFEV1: {df_for_ID_in.ecFEV1.max()}, first possible bin for HFEV1: {HFEV1.get_bin_for_value(HFEV1_obs_list[0])[0]}\"\n","    )\n","\n","    N = len(df_for_ID_in)\n","    df_for_ID = df_for_ID_in.copy()\n","\n","    # Speed up code by removing duplicates and adding them later on\n","    if speedup:\n","        print(f\"{N} entries before speedup\")\n","        df_for_ID = df_for_ID.sort_values(\n","            by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], ascending=False\n","        )\n","        df_duplicates = (\n","            df_for_ID.groupby([\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"])\n","            .size()\n","            .reset_index()\n","        )\n","        df_duplicates.columns = [\n","            \"idx ecFEV1 (L)\",\n","            \"idx ecFEF2575%ecFEV1\",\n","            \"n duplicates\",\n","        ]\n","        df_duplicates = df_duplicates.sort_values(\n","            by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], ascending=False\n","        ).reset_index(drop=True)\n","        n_dups = df_duplicates[\"n duplicates\"].values\n","        # Keep only the first entry for each pair of ecFEV1 and ecFEF2575%ecFEV1]\n","        # Create df_for_ID without duplicates\n","        df_for_ID = df_for_ID.drop_duplicates(\n","            subset=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\"], keep=\"first\"\n","        ).reset_index(drop=True)\n","        print(f\"{len(df_for_ID)} entries after speedup\")\n","        print(\n","            f\"Number of duplicates {N - len(df_for_ID)}, speedup removes {(N-len(df_for_ID))/N*100:.2f}% of entries\"\n","        )\n","\n","    H = len(HFEV1_obs_list)\n","    N_maybe_no_dups = len(df_for_ID) if speedup else N\n","    log_p_D_given_M = np.zeros((N_maybe_no_dups, H))\n","    AR_dist_given_M_matrix = np.zeros((N_maybe_no_dups, AR.card, H))\n","\n","    # Get the joint probability of ecFEV1 and ecFEF2575 given the model for this individual\n","    # For each entry\n","    for n, row in df_for_ID.iterrows():\n","        if debug:\n","            print(f\"Processing row {n+1}/{N_maybe_no_dups}\")\n","\n","        # For each model given an HFEV1 observation\n","        for h, HFEV1_obs in enumerate(HFEV1_obs_list):\n","\n","            # Getting the joint probabilities of ecFEF2575 and ecFEV1 under the model\n","            res1, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEV1, ecFEF2575prctecFEV1],\n","                [[HFEV1, HFEV1_obs]],\n","                get_messages=True,\n","            )\n","            dist_ecFEV1 = res1[ecFEV1.name].values\n","\n","            # Observe both HFEV1 and ecFEV1 to compute the joint probability\n","            # P(ecFEV1, ecFEF2575 | HFEV1) = P(ecFEV1 | HFEV1) * P( ecFEF2575 | HFEV1, ecFEV1)\n","            res2, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEF2575prctecFEV1],\n","                [[HFEV1, HFEV1_obs], [ecFEV1, row.ecFEV1]],\n","                get_messages=True,\n","            )\n","            dist_ecFEF2575prctecFEV1 = res2[ecFEF2575prctecFEV1.name].values\n","\n","            res3, _ = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [AR],\n","                [\n","                    [HFEV1, HFEV1_obs],\n","                    [ecFEV1, row.ecFEV1],\n","                    [ecFEF2575prctecFEV1, row[\"ecFEF2575%ecFEV1\"]],\n","                ],\n","                get_messages=True,\n","            )\n","            dist_AR = res3[AR.name].values\n","\n","            # The probability of the data given the model is the expectation of the data given the model\n","            idx_obs_ecFEV1 = ecFEV1.get_bin_for_value(row.ecFEV1)[1]\n","            idx_obs_ecFEF2575 = ecFEF2575prctecFEV1.get_bin_for_value(\n","                row[\"ecFEF2575%ecFEV1\"]\n","            )[1]\n","\n","            # Get the probability of the data given the model\n","            p_ecFEV1 = dist_ecFEV1[idx_obs_ecFEV1]\n","            p_ecFEF2575 = dist_ecFEF2575prctecFEV1[idx_obs_ecFEF2575]\n","\n","            # Save information for this round\n","            AR_dist_given_M_matrix[n, :, h] = dist_AR\n","            log_p_D_given_M[n, h] = np.log(p_ecFEV1) + np.log(p_ecFEF2575)\n","\n","    if debug:\n","        print(\"log(P(D|M)), first row\", log_p_D_given_M[0, :])\n","\n","    if speedup:\n","        # Put back the duplicates\n","        # Repeat each element in the array by the number in the array dups\n","        log_p_D_given_M = np.repeat(log_p_D_given_M, n_dups, axis=0)\n","        AR_dist_given_M_matrix = np.repeat(AR_dist_given_M_matrix, n_dups, axis=0)\n","        if debug:\n","            print(\"P(D|M), first row, after applying duplicates\", log_p_D_given_M[:, 0])\n","\n","    # For each HFEV1 model, given HFEV1_obs_list, we compute the log probability of the model given the data\n","    # log(P(M|D)) = 1/N * sum_n log(P(D|M)) + Cn_avg + log(P(M))\n","    log_p_M_given_D = np.zeros(H)\n","    for h, HFEV1_obs in enumerate(HFEV1_obs_list):\n","        log_p_M = np.log(HFEV1.cpt[HFEV1.get_bin_for_value(HFEV1_obs)[1]])\n","        log_p_M_given_D[h] = np.sum(log_p_D_given_M[:, h]) + log_p_M\n","\n","    # Exponentiating very negative numbers gives too small numbers\n","    # Setting the highest number to 1\n","    shift = 1 - log_p_M_given_D.max()\n","    log_p_M_given_D_shifted = log_p_M_given_D + shift\n","\n","    # Exponentiate and normalise\n","    p_M_given_D = np.exp(log_p_M_given_D_shifted)\n","    p_M_given_D = p_M_given_D / p_M_given_D.sum()\n","\n","    # Fill the p(M|D) array with zeros on the left, where the HFEV1_obs < max ecFEV1\n","    p_M_given_D_full = np.zeros(HFEV1.card)\n","    HFEV1_obs_idx = [\n","        HFEV1.get_bin_for_value(HFEV1_obs)[1] for HFEV1_obs in HFEV1_obs_list\n","    ]\n","    p_M_given_D_full[HFEV1_obs_idx] = p_M_given_D\n","\n","    # Add plot\n","    layout = [\n","        [{\"type\": \"scatter\", \"rowspan\": 1, \"colspan\": 1}, None, None],\n","        [{\"type\": \"heatmap\", \"rowspan\": 3, \"colspan\": 3}, None, None],\n","        [None, None, None],\n","        [None, None, None],\n","    ]\n","    fig = make_subplots(\n","        rows=np.shape(layout)[0],\n","        cols=np.shape(layout)[1],\n","        specs=layout,\n","        vertical_spacing=0.1,\n","    )\n","\n","    # Add HFEV1 posterior\n","    ih.plot_histogram(fig, HFEV1, p_M_given_D_full, 0, 6, 1, 1, annot=True)\n","\n","    # Add heatmap with AR posteriors\n","    AR_dist_matrix = np.matmul(AR_dist_given_M_matrix, p_M_given_D)\n","    df1 = pd.DataFrame(\n","        data=AR_dist_matrix,\n","        columns=AR.get_bins_str(),\n","        index=df_for_ID_in[\"Date Recorded\"].apply(\n","            lambda date: date.strftime(\"%Y-%m-%d\")\n","        ),\n","    )\n","    colorscale = [\n","        [0, \"white\"],\n","        [0.01, \"red\"],\n","        [0.05, \"yellow\"],\n","        [0.1, \"cyan\"],\n","        [0.6, \"blue\"],\n","        [1, \"black\"],\n","    ]\n","\n","    fig.add_trace(\n","        go.Heatmap(z=df1.T, x=df1.index, y=df1.columns, coloraxis=\"coloraxis1\"),\n","        row=2,\n","        col=1,\n","    )\n","\n","    speedup = \" (with speedup)\" if speedup else \"\"\n","\n","    title = f\"{id} - Posterior HFEV1 after fusing all P(M_h|D)<br>AR prior: {ar_prior}{speedup}\"\n","    fig.update_layout(\n","        font=dict(size=12),\n","        height=700,\n","        width=1200,\n","        title=title,\n","        coloraxis1=dict(\n","            colorscale=colorscale,\n","            colorbar_x=1,\n","            colorbar_y=0.36,\n","            # colorbar_thickness=23,\n","            colorbar_len=0.77,\n","        ),\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=HFEV1.name, row=1, col=1)\n","    fig.update_yaxes(title_text=\"p\", row=1, col=1)\n","    fig.update_yaxes(title_text=AR.name, row=2, col=1)\n","    fig.update_xaxes(\n","        title_text=\"Date\",\n","        row=2,\n","        col=1,\n","        nticks=50,\n","        type=\"category\",\n","    )\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.png\",\n","            scale=3,\n","        )\n","    else:\n","        fig.show()\n","\n","    return fig, p_M_given_D_full, p_M_given_D, AR_dist_given_M_matrix"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ID 527 - Number of HFEV1 specific models: 100, max ecFEV1: 0.92, first possible bin for HFEV1: [1.00; 1.05)\n","5 entries before speedup\n","4 entries after speedup\n","Number of duplicates 1, speedup removes 20.00% of entries\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"histfunc":"sum","type":"histogram","x":[1,1.05,1.1,1.1500000000000001,1.2000000000000002,1.2500000000000002,1.3000000000000003,1.3500000000000003,1.4000000000000004,1.4500000000000004,1.5000000000000004,1.5500000000000005,1.6000000000000005,1.6500000000000006,1.7000000000000006,1.7500000000000007,1.8000000000000007,1.8500000000000008,1.9000000000000008,1.9500000000000008,2.000000000000001,2.0500000000000007,2.100000000000001,2.1500000000000012,2.200000000000001,2.250000000000001,2.300000000000001,2.3500000000000014,2.4000000000000012,2.450000000000001,2.5000000000000013,2.5500000000000016,2.6000000000000014,2.6500000000000012,2.7000000000000015,2.7500000000000018,2.8000000000000016,2.8500000000000014,2.9000000000000017,2.950000000000002,3.0000000000000018,3.0500000000000016,3.100000000000002,3.150000000000002,3.200000000000002,3.2500000000000018,3.300000000000002,3.3500000000000023,3.400000000000002,3.450000000000002,3.500000000000002,3.5500000000000025,3.6000000000000023,3.650000000000002,3.7000000000000024,3.7500000000000027,3.8000000000000025,3.8500000000000023,3.9000000000000026,3.950000000000003,4.000000000000003,4.0500000000000025,4.100000000000003,4.150000000000003,4.200000000000003,4.250000000000003,4.3000000000000025,4.350000000000003,4.400000000000003,4.450000000000003,4.5000000000000036,4.550000000000003,4.600000000000003,4.650000000000003,4.700000000000003,4.7500000000000036,4.800000000000003,4.850000000000003,4.900000000000004,4.950000000000004,5.0000000000000036,5.050000000000003,5.100000000000003,5.150000000000004,5.200000000000004,5.2500000000000036,5.300000000000004,5.350000000000004,5.400000000000004,5.450000000000004,5.5000000000000036,5.550000000000004,5.600000000000004,5.650000000000004,5.700000000000005,5.750000000000004,5.800000000000004,5.850000000000004,5.900000000000004,5.950000000000005],"xaxis":"x","xbins":{"end":6,"size":0.05,"start":0},"y":[7.2414941415692674e-12,3.396139239203526e-11,1.323512671073207e-10,4.660041345511291e-10,1.4196429563750845e-9,3.8325492081045855e-9,9.207609262020381e-9,2.0003506780751848e-8,4.049927521996456e-8,7.694256100468794e-8,1.3943883187670306e-7,2.469793043507069e-7,4.2999633062394007e-7,7.317500118382178e-7,0.0000012020621984869169,0.0000020705394879153814,0.0000035711860731191555,0.000005722250816931787,0.000008689575764105646,0.000012946019882047351,0.000019913843115987718,0.000030044953012258023,0.00004180328271807156,0.000058212216889587,0.00007899954237585124,0.00010782067835158284,0.00014492939963658608,0.00019323752474701629,0.00024859124262944284,0.00031653221443066204,0.00039352364580196817,0.0004775883718598738,0.0005777410149676161,0.0007024879720685252,0.0008553787969454627,0.001037499370815639,0.0012453643412627812,0.001464048592230535,0.0017121459885855637,0.002002889574879968,0.002375773783022438,0.0028101007466585304,0.003308179352769255,0.003875800982543607,0.0045185113987980165,0.005241411499788268,0.00604893254274487,0.006944589841394161,0.00793072084587458,0.009008215519058956,0.010176248743707756,0.011432026368242086,0.012770557772521991,0.014184468977441241,0.015663870390371957,0.01719629318872561,0.01876670666892976,0.020357627163148904,0.02194932545246516,0.0235201364722583,0.025046869461591657,0.026505312547268237,0.027870819667714503,0.029118962780850532,0.03022622749224105,0.031170725908168478,0.031932897944008096,0.03249617055836497,0.03284754464872088,0.03297808115702623,0.03288326155859383,0.032563203071991564,0.03202271548197911,0.03127119395699202,0.030322350276060388,0.029193792932934972,0.027906474133166916,0.026484028269517332,0.024952031609396373,0.023337216335307488,0.021666673549173825,0.01996707931119666,0.018263975335252654,0.016581131811638672,0.014940014314209462,0.013359370291331477,0.011854943695688503,0.010439319359319426,0.009121892203445463,0.007908950672946507,0.006803859197970611,0.005807321196351875,0.004917702226600763,0.0041313923528077424,0.0034431874740743357,0.002846671110076342,0.00233458067691731,0.0018991453676030013,0.0015323860979392847,0.0012263713423669668],"yaxis":"y"},{"coloraxis":"coloraxis","type":"heatmap","x":["2022-05-24","2022-05-25","2022-05-26","2022-05-27","2022-05-30"],"xaxis":"x2","y":["[0.0, 2.0)","[2.0, 4.0)","[4.0, 6.0)","[6.0, 8.0)","[8.0, 10.0)","[10.0, 12.0)","[12.0, 14.0)","[14.0, 16.0)","[16.0, 18.0)","[18.0, 20.0)","[20.0, 22.0)","[22.0, 24.0)","[24.0, 26.0)","[26.0, 28.0)","[28.0, 30.0)","[30.0, 32.0)","[32.0, 34.0)","[34.0, 36.0)","[36.0, 38.0)","[38.0, 40.0)","[40.0, 42.0)","[42.0, 44.0)","[44.0, 46.0)","[46.0, 48.0)","[48.0, 50.0)","[50.0, 52.0)","[52.0, 54.0)","[54.0, 56.0)","[56.0, 58.0)","[58.0, 60.0)","[60.0, 62.0)","[62.0, 64.0)","[64.0, 66.0)","[66.0, 68.0)","[68.0, 70.0)","[70.0, 72.0)","[72.0, 74.0)","[74.0, 76.0)","[76.0, 78.0)","[78.0, 80.0)","[80.0, 82.0)","[82.0, 84.0)","[84.0, 86.0)","[86.0, 88.0)","[88.0, 90.0)"],"yaxis":"y2","z":[[0,0,0,0,0],[0,0,0,0,0],[1.0982239403096803e-13,1.0781206853757962e-13,1.01944977372538e-13,1.01944977372538e-13,0],[1.0737800945347433e-12,1.0657042397062151e-12,1.0423277806336046e-12,1.0423277806336046e-12,0],[2.57680619494612e-12,2.5676927239671445e-12,2.5407146915313013e-12,2.5407146915313013e-12,0],[6.771165178561377e-12,6.7408260695111334e-12,6.651980692648176e-12,6.651980692648176e-12,0],[1.2946081177929353e-11,1.2916172730679964e-11,1.2829409623395483e-11,1.2829409623395483e-11,0],[3.0727204057374186e-11,3.059426168587992e-11,3.020090448226478e-11,3.020090448226478e-11,1.2885375733065485e-13],[5.896879080931638e-11,5.879434700256822e-11,5.827816660917536e-11,5.827816660917536e-11,1.1950391324046186e-12],[1.3701390860229397e-10,1.3652332141203291e-10,1.3512985860352575e-10,1.3512985860352575e-10,3.288696995723121e-12],[2.792850457152702e-10,2.785614616402797e-10,2.7651335584483783e-10,2.7651335584483783e-10,8.985850096840798e-12],[5.851480412686687e-10,5.835020194881684e-10,5.786468992692362e-10,5.786468992692362e-10,2.0066141869793307e-11],[1.2559879391143177e-9,1.2530702159113848e-9,1.2452991987847902e-9,1.2452991987847902e-9,4.6732352523397916e-11],[2.478146750731908e-9,2.472643501884767e-9,2.4571549701668183e-9,2.4571549701668183e-9,1.1445647851215917e-10],[4.960634430176518e-9,4.952249390676548e-9,4.928727209959787e-9,4.928727209959787e-9,2.5162859902536747e-10],[9.986535745870104e-9,9.967698934669421e-9,9.915188992924789e-9,9.915188992924789e-9,5.959926282548155e-10],[1.9269018545559248e-8,1.92447785246092e-8,1.918977862974599e-8,1.918977862974599e-8,1.3778563689535088e-9],[3.687298307005911e-8,3.6834400922814496e-8,3.67473766179594e-8,3.67473766179594e-8,2.9991161760552996e-9],[6.99984678684489e-8,6.99314755752102e-8,6.978515290370044e-8,6.978515290370044e-8,6.4471917709267e-9],[1.330517070497708e-7,1.32951305471681e-7,1.3279639441014933e-7,1.3279639441014933e-7,1.3686109011179226e-8],[2.577865502734764e-7,2.5752586295866075e-7,2.569967159528428e-7,2.569967159528428e-7,2.8633285980950405e-8],[5.045001931713633e-7,5.046596203054049e-7,5.063296021410452e-7,5.063296021410452e-7,5.916874957025479e-8],[0.0000010118888632154322,0.0000010109159855446157,0.0000010088805870504313,0.0000010088805870504313,1.2177719766590577e-7],[0.000002101173606766892,0.0000021034026463341474,0.0000021215935295649556,0.0000021215935295649556,2.5163331650260944e-7],[0.0000047932661999602146,0.000004786219081333839,0.000004772868412720197,0.000004772868412720197,5.397370451110235e-7],[0.000010425727176585556,0.00001041383111710681,0.00001037677868819972,0.00001037677868819972,0.0000011871233290745908],[0.00002170709729234199,0.000021699895787726057,0.000021781731789372995,0.000021781731789372995,0.0000027304862841679338],[0.000049495438213697046,0.000049432319928571676,0.00004920291482661842,0.00004920291482661842,0.000006803979260047736],[0.00010440756040174253,0.00010430606529361299,0.00010409777861346585,0.00010409777861346585,0.00001572590003310996],[0.00022157929483498462,0.00022149351340517017,0.00022168775854137393,0.00022168775854137393,0.00003792269566445903],[0.00048087417046219726,0.00048069111777832154,0.0004797522923177811,0.0004797522923177811,0.00009094325753263384],[0.0009875893252049802,0.000987793732057016,0.000987252413913349,0.000987252413913349,0.00021085397404251152],[0.0019537426728127977,0.001952415235321447,0.0019478283459434423,0.0019478283459434423,0.0004946302080978966],[0.004045604777618143,0.00404465996077895,0.004035911708652402,0.004035911708652402,0.0011137331756891468],[0.008320730065443144,0.008323256619315492,0.008338267173834117,0.008338267173834117,0.0024085961197431536],[0.01858496060765602,0.01858496060765602,0.01858496060765602,0.01858496060765602,0.005409853867471427],[0.041768506138488516,0.04176850613848851,0.041768506138488516,0.041768506138488516,0.012584032823506501],[0.09037301423674599,0.09037301423674599,0.09037301423674599,0.09037301423674599,0.03120230767242165],[0.17519156507595776,0.17519156507595776,0.1751915650759578,0.1751915650759578,0.07590995280022216],[0.2687374228466657,0.2687374228466657,0.2687374228466657,0.2687374228466657,0.16715148543850555],[0.263790515666952,0.26379051566695205,0.26379051566695205,0.26379051566695205,0.28740934923699557],[0.11642019899319461,0.11642019899319461,0.11642019899319461,0.11642019899319461,0.296124739940573],[0.008928712701363308,0.008928712701363308,0.008928712701363308,0.008928712701363308,0.11584078708162648],[0,0,0,0,0.003983337716658698],[0,0,0,0,0]]}],"layout":{"annotations":[{"font":{"size":8},"showarrow":false,"text":"4.44","x":4.4390684745887175,"xref":"x","y":0.03627588927272886,"yref":"y"}],"coloraxis":{"colorbar":{"len":0.77,"x":1,"y":0.36},"colorscale":[[0,"white"],[0.01,"red"],[0.05,"yellow"],[0.1,"cyan"],[0.6,"blue"],[1,"black"]]},"font":{"size":12},"height":700,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"527 - Posterior HFEV1 after fusing all P(M_h|D)<br>AR prior: uniform (with speedup)"},"width":1200,"xaxis":{"anchor":"y","domain":[0,0.2888888888888889],"nticks":20,"range":[0,6],"title":{"text":"Healthy FEV1 (L)"}},"xaxis2":{"anchor":"y2","domain":[0,1],"nticks":50,"title":{"text":"Date"},"type":"category"},"yaxis":{"anchor":"x","domain":[0.825,1],"title":{"text":"p"}},"yaxis2":{"anchor":"x2","domain":[0,0.7250000000000001],"title":{"text":"Airway resistance (%)"}}}}},"metadata":{},"output_type":"display_data"}],"source":["# ar_prior = \"breathe (2 days model, ecFEV1, ecFEF25-75)\"\n","ar_prior = \"uniform\"\n","# p_M_given_D_plot, fig = compute_log_p_D_given_M_per_entry_per_HFEV1_obs(dftmp, debug=False, save=False, speedup=True, ar_prior=ar_prior)\n","\n","dftmp = df[df.ID == \"527\"]\n","fig, p_M_given_D_full, p_M_given_D, AR_dist_given_M_matrix = (\n","    compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","        dftmp, debug=False, save=False, speedup=True, ar_prior=ar_prior\n","    )\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Infering HFEV1, AR, IA through time while observing ecFEV1, ecFEF25-75, SpO2"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of CPU cores: 10\n"]}],"source":["import os\n","import multiprocessing\n","\n","# Number of CPU cores\n","num_cores = os.cpu_count()  # or multiprocessing.cpu_count()\n","print(f\"Number of CPU cores: {num_cores}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import time\n","import itertools"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","    df_for_ID_in, debug=False, save=False, speedup=True, ar_prior=\"uniform\"\n","):\n","    df_for_ID_in = df_for_ID_in.copy().reset_index(drop=True)\n","    id = df_for_ID_in.loc[0, \"ID\"]\n","    height = df_for_ID_in.loc[0, \"Height\"]\n","    age = df_for_ID_in.loc[0, \"Age\"]\n","    sex = df_for_ID_in.loc[0, \"Sex\"]\n","\n","    (\n","        _,\n","        inf_alg,\n","        HFEV1,\n","        ecFEV1,\n","        AR,\n","        HO2Sat,\n","        O2SatFFA,\n","        IA,\n","        UO2Sat,\n","        O2Sat,\n","        ecFEF2575prctecFEV1,\n","    ) = mb.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n","        height, age, sex, ar_prior=ar_prior\n","    )\n","\n","    # HFEV1 can't be above max observed ecFEV1\n","    HFEV1_obs_list = HFEV1.midbins[\n","        HFEV1.midbins - HFEV1.bin_width / 2 >= df_for_ID_in.ecFEV1.max()\n","    ]\n","    # Create tuples of obs (HFEV1, HO2Sat) to observe\n","    H_obs_list = [\n","        list(zip([HFEV1_obs] * HO2Sat.card, HO2Sat.midbins))\n","        for HFEV1_obs in HFEV1_obs_list\n","    ]\n","    # Flatten the list\n","    H_obs_list = list(itertools.chain(*H_obs_list))\n","\n","    print(\n","        f\"ID {id} - Number of HFEV1, HO2Sat specific models: {len(H_obs_list)}, max ecFEV1: {df_for_ID_in.ecFEV1.max()}, first possible bin for HFEV1: {HFEV1.get_bin_for_value(HFEV1_obs_list[0])[0]}\"\n","    )\n","\n","    N = len(df_for_ID_in)\n","    df_for_ID = df_for_ID_in.copy()\n","\n","    # Speed up code by removing duplicates and adding them later on\n","    if speedup:\n","        print(f\"{N} entries before speedup\")\n","        df_for_ID = df_for_ID.sort_values(\n","            by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\", \"idx O2 saturation (%)\"],\n","            ascending=False,\n","        )\n","        df_duplicates = (\n","            df_for_ID.groupby(\n","                [\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\", \"idx O2 saturation (%)\"]\n","            )\n","            .size()\n","            .reset_index()\n","        )\n","        df_duplicates.columns = [\n","            \"idx ecFEV1 (L)\",\n","            \"idx ecFEF2575%ecFEV1\",\n","            \"idx O2 saturation (%)\",\n","            \"n duplicates\",\n","        ]\n","        df_duplicates = df_duplicates.sort_values(\n","            by=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\", \"idx O2 saturation (%)\"],\n","            ascending=False,\n","        ).reset_index(drop=True)\n","        n_dups = df_duplicates[\"n duplicates\"].values\n","        # Keep only the first entry for each pair of ecFEV1 and ecFEF2575%ecFEV1]\n","        # Create df_for_ID without duplicates\n","        df_for_ID = df_for_ID.drop_duplicates(\n","            subset=[\"idx ecFEV1 (L)\", \"idx ecFEF2575%ecFEV1\", \"idx O2 saturation (%)\"],\n","            keep=\"first\",\n","        ).reset_index(drop=True)\n","        print(f\"{len(df_for_ID)} entries after speedup\")\n","        print(\n","            f\"Number of duplicates {N - len(df_for_ID)}, speedup removes {(N-len(df_for_ID))/N*100:.2f}% of entries\"\n","        )\n","\n","    H = len(H_obs_list)\n","    N_maybe_no_dups = len(df_for_ID) if speedup else N\n","    log_p_D_given_M = np.zeros((N_maybe_no_dups, H))\n","    AR_dist_given_M_matrix = np.zeros((N_maybe_no_dups, AR.card, H))\n","\n","    # Get the joint probability of ecFEV1 and ecFEF2575 given the model for this individual\n","    # For each entry\n","    tic = time.time()\n","    for n, row in df_for_ID.iterrows():\n","        if debug:\n","            print(f\"Processing row {n+1}/{N_maybe_no_dups}\")\n","\n","        # For each model given an HFEV1 observation\n","        for h, (HFEV1_obs, HO2Sat_obs) in enumerate(H_obs_list):\n","\n","            # Getting the joint probabilities of ecFEF2575 and ecFEV1 under the model\n","            res1 = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEV1],\n","                [[HFEV1, HFEV1_obs], [HO2Sat, HO2Sat_obs]],\n","            )\n","            dist_ecFEV1 = res1[ecFEV1.name].values\n","\n","            # Observe both HFEV1 and ecFEV1 to compute the joint probability\n","            # P(ecFEV1, ecFEF2575, O2sat | HFEV1) = P(ecFEV1 | HFEV1) * P( ecFEF2575 | HFEV1, ecFEV1) * P( O2Sat | HFEV1, ecFEV1, ecFEF2575)\n","            res2 = ih.infer_on_factor_graph(\n","                inf_alg,\n","                [ecFEF2575prctecFEV1, AR],\n","                [[HFEV1, HFEV1_obs], [HO2Sat, HO2Sat_obs], [ecFEV1, row.ecFEV1]],\n","            )\n","            dist_ecFEF2575prctecFEV1 = res2[ecFEF2575prctecFEV1.name].values\n","\n","            # res3, _ = ih.infer_on_factor_graph(\n","            #     inf_alg,\n","            #     [O2Sat],\n","            #     [\n","            #         [HFEV1, HFEV1_obs],\n","            #        [HO2Sat, HO2Sat_obs],\n","            #         [ecFEV1, row.ecFEV1],\n","            #         [ecFEF2575prctecFEV1, row[\"ecFEF2575%ecFEV1\"]],\n","            #     ],\n","            #     get_messages=True,\n","            # )\n","            # dist_O2Sat = res3[O2Sat.name].values\n","\n","            # res4, _ = ih.infer_on_factor_graph(\n","            #     inf_alg,\n","            #     [AR],\n","            #     [\n","            #         [HFEV1, HFEV1_obs],\n","            #         [HO2Sat, HO2Sat_obs],\n","            #         [ecFEV1, row.ecFEV1],\n","            #         [ecFEF2575prctecFEV1, row[\"ecFEF2575%ecFEV1\"]],\n","            #         # [O2Sat, row[\"O2 Saturation\"]],\n","            #     ],\n","            #     get_messages=True,\n","            # )\n","\n","            # Use previously inferred AR, and add message from FEF25-75\n","            m_to_factor = ecFEF2575prctecFEV1.get_point_message(row[\"ecFEF2575%ecFEV1\"])\n","            factor_to_AR = np.matmul(m_to_factor, ecFEF2575prctecFEV1.cpt)\n","            factor_to_AR = factor_to_AR / factor_to_AR.sum()\n","\n","            dist_AR = res2[AR.name].values * factor_to_AR\n","            dist_AR = dist_AR / dist_AR.sum()\n","\n","            # The probability of the data given the model is the expectation of the data given the model\n","            idx_obs_ecFEV1 = ecFEV1.get_bin_for_value(row.ecFEV1)[1]\n","            idx_obs_ecFEF2575 = ecFEF2575prctecFEV1.get_bin_for_value(\n","                row[\"ecFEF2575%ecFEV1\"]\n","            )[1]\n","            # idx_obs_O2Sat = O2Sat.get_bin_for_value(row[\"O2 Saturation\"])[1]\n","\n","            # Get the probability of the data given the model\n","            p_ecFEV1 = dist_ecFEV1[idx_obs_ecFEV1]\n","            p_ecFEF2575 = dist_ecFEF2575prctecFEV1[idx_obs_ecFEF2575]\n","            # p_O2Sat = dist_O2Sat[idx_obs_O2Sat]\n","\n","            # Save information for this round\n","            AR_dist_given_M_matrix[n, :, h] = dist_AR\n","            log_p_D_given_M[n, h] = np.log(p_ecFEV1) + np.log(\n","                p_ecFEF2575\n","            )  # + np.log(p_O2Sat)\n","    toc = time.time()\n","    print(f\"Time for {N_maybe_no_dups} entries: {toc-tic:.2f} s\")\n","\n","    if debug:\n","        print(\"log(P(D|M)), first row\", log_p_D_given_M[0, :])\n","\n","    if speedup:\n","        # Put back the duplicates\n","        # Repeat each element in the array by the number in the array dups\n","        log_p_D_given_M = np.repeat(log_p_D_given_M, n_dups, axis=0)\n","        AR_dist_given_M_matrix = np.repeat(AR_dist_given_M_matrix, n_dups, axis=0)\n","        if debug:\n","            print(\"P(D|M), first row, after applying duplicates\", log_p_D_given_M[:, 0])\n","\n","    # For each HFEV1 model, given HFEV1_obs_list, we compute the log probability of the model given the data\n","    # log(P(M|D)) = 1/N * sum_n log(P(D|M)) + Cn_avg + log(P(M))\n","    log_p_M_given_D = np.zeros(H)\n","    for h, (HFEV1_obs, HO2Sat_obs) in enumerate(H_obs_list):\n","        log_p_M_hfev1 = np.log(HFEV1.cpt[HFEV1.get_bin_for_value(HFEV1_obs)[1]])\n","        log_p_M_ho2sat = np.log(HO2Sat.cpt[HO2Sat.get_bin_for_value(HO2Sat_obs)[1]])\n","        log_p_M_given_D[h] = (\n","            np.sum(log_p_D_given_M[:, h]) + log_p_M_hfev1 + log_p_M_ho2sat\n","        )\n","\n","    # Exponentiating very negative numbers gives too small numbers\n","    # Setting the highest number to 1\n","    shift = 1 - log_p_M_given_D.max()\n","    log_p_M_given_D_shifted = log_p_M_given_D + shift\n","\n","    # Exponentiate and normalise\n","    p_M_given_D = np.exp(log_p_M_given_D_shifted)\n","    p_M_given_D = p_M_given_D / p_M_given_D.sum()\n","    AR_dist_matrix = np.matmul(AR_dist_given_M_matrix, p_M_given_D)\n","\n","    # Reshape P(M|D) into a 2D array for each HFEV1_obs, HO2Sat_obs\n","    p_M_given_D = p_M_given_D.reshape((len(HFEV1_obs_list), HO2Sat.card))\n","\n","    # Fill the p(M|D) array with zeros on the left, where the HFEV1_obs < max ecFEV1\n","    n_impossible_hfev1_values = HFEV1.card - len(HFEV1_obs_list)\n","    p_M_given_D_full = np.vstack(\n","        [np.zeros((n_impossible_hfev1_values, HO2Sat.card)), p_M_given_D]\n","    )\n","\n","    # Get the probability of HFEV1\n","    p_HFEV1_given_D = p_M_given_D_full.sum(axis=1)\n","\n","    # Add plot\n","    layout = [\n","        [{\"type\": \"scatter\", \"rowspan\": 1, \"colspan\": 1}, None, None],\n","        [{\"type\": \"heatmap\", \"rowspan\": 3, \"colspan\": 3}, None, None],\n","        [None, None, None],\n","        [None, None, None],\n","    ]\n","    fig = make_subplots(\n","        rows=np.shape(layout)[0],\n","        cols=np.shape(layout)[1],\n","        specs=layout,\n","        vertical_spacing=0.1,\n","    )\n","\n","    # Add HFEV1 posterior\n","    ih.plot_histogram(fig, HFEV1, p_HFEV1_given_D, 0, 6, 1, 1, annot=True)\n","\n","    # Add heatmap with AR posteriors\n","    df1 = pd.DataFrame(\n","        data=AR_dist_matrix,\n","        columns=AR.get_bins_str(),\n","        index=df_for_ID_in[\"Date Recorded\"].apply(\n","            lambda date: date.strftime(\"%Y-%m-%d\")\n","        ),\n","    )\n","    colorscale = [\n","        [0, \"white\"],\n","        [0.01, \"red\"],\n","        [0.05, \"yellow\"],\n","        [0.1, \"cyan\"],\n","        [0.6, \"blue\"],\n","        [1, \"black\"],\n","    ]\n","\n","    fig.add_trace(\n","        go.Heatmap(z=df1.T, x=df1.index, y=df1.columns, coloraxis=\"coloraxis1\"),\n","        row=2,\n","        col=1,\n","    )\n","\n","    speedup = \" (with speedup)\" if speedup else \"\"\n","\n","    title = f\"{id} - Posterior HFEV1 after fusing all P(M_h|D)<br>AR prior: {ar_prior}{speedup}\"\n","    fig.update_layout(\n","        font=dict(size=12),\n","        height=700,\n","        width=1200,\n","        title=title,\n","        coloraxis1=dict(\n","            colorscale=colorscale,\n","            colorbar_x=1,\n","            colorbar_y=0.36,\n","            # colorbar_thickness=23,\n","            colorbar_len=0.77,\n","        ),\n","    )\n","    # Add Date on x axis\n","    fig.update_xaxes(title_text=HFEV1.name, row=1, col=1)\n","    fig.update_yaxes(title_text=\"p\", row=1, col=1)\n","    fig.update_yaxes(title_text=AR.name, row=2, col=1)\n","    fig.update_xaxes(\n","        title_text=\"Date\",\n","        row=2,\n","        col=1,\n","        nticks=50,\n","        type=\"category\",\n","    )\n","\n","    if save:\n","        fig.write_image(\n","            dh.get_path_to_main() + f\"/PlotsBreathe/Cutset_conditioning/{title}.png\",\n","            scale=3,\n","        )\n","    else:\n","        fig.show()\n","\n","    return fig, p_M_given_D_full, p_M_given_D, AR_dist_given_M_matrix\n","    # return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ID 527 - Number of HFEV1, HO2Sat specific models: 2000, max ecFEV1: 0.92, first possible bin for HFEV1: [1.00; 1.05)\n","5 entries before speedup\n","5 entries after speedup\n","Number of duplicates 0, speedup removes 0.00% of entries\n"]}],"source":["ar_prior = \"breathe (2 days model, ecFEV1, ecFEF25-75)\"\n","ar_prior = \"uniform\"\n","# p_M_given_D_plot, fig = compute_log_p_D_given_M_per_entry_per_HFEV1_obs(dftmp, debug=False, save=False, speedup=True, ar_prior=ar_prior)\n","\n","dftmp = df[df.ID == \"527\"]\n","fig, p_M_given_D_full, p_M_given_D, AR_dist_given_M_matrix = (\n","    compute_log_p_D_given_M_per_entry_per_HFEV1_obs(\n","        dftmp, debug=False, save=True, speedup=True, ar_prior=ar_prior\n","    )\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'UO2Sat' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mUO2Sat\u001b[49m\u001b[38;5;241m.\u001b[39mcpt\n","\u001b[0;31mNameError\u001b[0m: name 'UO2Sat' is not defined"]}],"source":["UO2Sat.cpt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"phd","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
