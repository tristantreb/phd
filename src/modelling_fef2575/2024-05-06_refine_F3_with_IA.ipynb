{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use the information about IA to refine F3. Initially, I buildt F3 using FEF25-75%FEV1 against FEV1-based-AR. The latter variable contains only the aspect of AR as measured by FEV1. In CF, high AR usually correlates with high IA. We can use this correlation to refine the uncertainty present in the FEV1-based-AR. The corrected FEV1-based-AR can therefore be closer to the true AR. We can use it to improve the model fo F3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.breathe_data as br\n",
    "import src.data.helpers as dh\n",
    "import src.models.helpers as mh\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.inference.helpers as ih\n",
    "import src.modelling_fef2575.cpt_and_plots as cpt_and_plots\n",
    "import src.models.var_builders as var_builders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need dataset with O2sat, FEV1, FEF25-75. Use as many datapoints as possible\n",
    "# Infer FEV1-based-AR using FEV1\n",
    "# Model F3 using FEV1-based-AR\n",
    "# Infer FEV1-FEF2575-based-AR using FEV1 and FEF25-75\n",
    "# Model F3 using FEV1-FEF2575-based-AR\n",
    "# Infer IA using FEV1-FEF2575-based-AR\n",
    "# Model AR-IA\n",
    "# Infer IA-FEV1-FEF2575-based-AR using FEV1, FEF25-75, IA\n",
    "# Model F3 using this new AR\n",
    "# Compare the two models: compare the mean, median, std-percentiles plots of both -> std should be smaller\n",
    "\n",
    "# Optionally repeat until std doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48978, 15)\n",
      "(32715, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date Recorded</th>\n",
       "      <th>FEV1</th>\n",
       "      <th>O2 Saturation</th>\n",
       "      <th>FEF2575</th>\n",
       "      <th>ecFEV1</th>\n",
       "      <th>ecFEF2575</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Predicted FEV1</th>\n",
       "      <th>Healthy O2 Saturation</th>\n",
       "      <th>ecFEV1 % Predicted</th>\n",
       "      <th>FEV1 % Predicted</th>\n",
       "      <th>O2 Saturation % Healthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>1.31</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.610061</td>\n",
       "      <td>97.150104</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>99.845492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>1.31</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.610061</td>\n",
       "      <td>97.150104</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>100.874827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>1.31</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.69</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.610061</td>\n",
       "      <td>97.150104</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>98.816157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>1.30</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.69</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.610061</td>\n",
       "      <td>97.150104</td>\n",
       "      <td>36.287474</td>\n",
       "      <td>36.010470</td>\n",
       "      <td>98.816157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.610061</td>\n",
       "      <td>97.150104</td>\n",
       "      <td>36.010470</td>\n",
       "      <td>35.456463</td>\n",
       "      <td>100.874827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Date Recorded  FEV1  O2 Saturation  FEF2575  ecFEV1  ecFEF2575  Age  \\\n",
       "0  101    2019-01-25  1.31           97.0     0.54    1.31       0.67   53   \n",
       "1  101    2019-01-26  1.31           98.0     0.57    1.31       0.67   53   \n",
       "2  101    2019-01-27  1.31           96.0     0.67    1.31       0.69   53   \n",
       "3  101    2019-01-28  1.30           96.0     0.69    1.31       0.69   53   \n",
       "4  101    2019-01-29  1.28           98.0     0.60    1.30       0.69   53   \n",
       "\n",
       "    Sex  Height  Predicted FEV1  Healthy O2 Saturation  ecFEV1 % Predicted  \\\n",
       "0  Male   173.0        3.610061              97.150104           36.287474   \n",
       "1  Male   173.0        3.610061              97.150104           36.287474   \n",
       "2  Male   173.0        3.610061              97.150104           36.287474   \n",
       "3  Male   173.0        3.610061              97.150104           36.287474   \n",
       "4  Male   173.0        3.610061              97.150104           36.010470   \n",
       "\n",
       "   FEV1 % Predicted  O2 Saturation % Healthy  \n",
       "0         36.287474                99.845492  \n",
       "1         36.287474               100.874827  \n",
       "2         36.287474                98.816157  \n",
       "3         36.010470                98.816157  \n",
       "4         35.456463               100.874827  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = br.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_PEF_Nan\")\n",
    "# Remove PEF related rows\n",
    "df = df.drop(columns=[\"PEF\", \"ecPEF (L/s)\", \"PEF (L/s)\"])\n",
    "# Remove NaN on FEV1, O2 saturation columns\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=[\"FEV1\", \"O2 Saturation\", \"FEF2575\"])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    HFEV1,\n",
    "    ecFEV1,\n",
    "    AR,\n",
    "    HO2Sat,\n",
    "    O2SatFFA,\n",
    "    IA,\n",
    "    UO2Sat,\n",
    "    O2Sat,\n",
    "    ecFEF2575prctecFEV1,\n",
    ") = var_builders.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n",
    "    180, 10, 'Male'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer FEV1-based-AR using FEV1\n",
    "\n",
    "# inf_res_df = ih.infer_vars_and_get_back_df(df,  observed_variables=[\"ecFEV1\", \"O2Sat\"])\n",
    "inf_res_df = ih.infer_vars_and_get_back_df(\n",
    "    df.iloc[np.r_[10:1300, 3000:4007, 10000:11000]],\n",
    "    variables_to_infer=[AR],\n",
    "    observed_variables=[ecFEV1, O2Sat],\n",
    "    ecFEF2575prctecFEV1_cpt=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the inferred AR back to the original dataframe\n",
    "df1 = pd.merge(df, inf_res_df, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sampled AR values: 90.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tristan.trebaol/Desktop/PhD/Code/phd/src/modelling_fef2575/cpt_and_plots.py:235: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_sampled.groupby(\"AR bin\")\n"
     ]
    }
   ],
   "source": [
    "# Model F3 using FEV1-based-AR\n",
    "\n",
    "def model_f3(df, AR, ar_col):\n",
    "    y_col = \"ecFEF2575%ecFEV1\"\n",
    "    df[\"ecFEF2575%ecFEV1\"] = df[\"ecFEF2575\"] / df[\"ecFEV1\"] * 100\n",
    "\n",
    "    # Parameters\n",
    "    n_samples = 100\n",
    "\n",
    "    ecFEF2575prctecFEV1 = mh.VariableNode(\n",
    "        \"ecFEF25-75 % ecFEV1 (%)\", 0, 200, 2, prior=None\n",
    "    )\n",
    "\n",
    "    df_sampled, df_f3 = cpt_and_plots.get_sampled_df_and_statistics_df(\n",
    "        df, n_samples, AR\n",
    "    )\n",
    "\n",
    "    cpt_and_plots.plot_F3_mean_and_percentiles_per_AR_bin(\n",
    "        df_f3, ar_col, y_col, save=True\n",
    "    )\n",
    "    cpt_f3 = cpt_and_plots.calc_plot_cpt_var_given_AR(\n",
    "        df_sampled, df_f3, n_samples, AR, ar_col, ecFEF2575prctecFEV1, y_col, save=True\n",
    "    )\n",
    "    return cpt_f3\n",
    "\n",
    "\n",
    "cpt_f3 = model_f3(df1, AR, \"FEV1-based-AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_res_df_2 = ih.infer_vars_and_get_back_df(\n",
    "    df.iloc[np.r_[10:1300, 3000:4007, 10000:11000]],\n",
    "    variables_to_infer=[AR],\n",
    "    observed_variables=[ecFEV1, O2Sat, ecFEF2575prctecFEV1],\n",
    "    ecFEF2575prctecFEV1_cpt=cpt_f3,\n",
    ")\n",
    "# Merge the inferred AR back to the original dataframe\n",
    "df2 = pd.merge(df, inf_res_df_2, on=[\"ID\", \"Date Recorded\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sampled AR values: 90.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tristan.trebaol/Desktop/PhD/Code/phd/src/modelling_fef2575/cpt_and_plots.py:235: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model F3 using FEV1-FEF2575-based-AR\n",
    "\n",
    "cpt_f3_2 = model_f3(df2, AR, \"FEV1-FEF2575-based-AR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.var_builders as var_builders\n",
    "import src.models.graph_builders as graph_builders\n",
    "from src.inference.inf_algs import apply_custom_bp\n",
    "\n",
    "\n",
    "def infer_vars_and_get_back_df(\n",
    "    df,\n",
    "    ecFEF2575prctecFEV1_cpt=None,\n",
    "    variables_to_infer=[\"AR\", \"IA\", \"HFEV1\", \"HO2Sat\", \"O2SatFFA\", \"UO2Sat\"],\n",
    "    observed_variables=[\"ecFEV1\", \"O2Sat\", \"ecFEF2575prctecFEV1\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Infer AR, IA, HFEV1, HO2Sat fo each entry in the dataset, for the given observed variables as evidence\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_vars_for_ID(df):\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        (\n",
    "            HFEV1,\n",
    "            ecFEV1,\n",
    "            AR,\n",
    "            HO2Sat,\n",
    "            O2SatFFA,\n",
    "            IA,\n",
    "            UO2Sat,\n",
    "            O2Sat,\n",
    "            ecFEF2575prctecFEV1,\n",
    "        ) = var_builders.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n",
    "            df.Height[0], df.Age[0], df.Sex[0]\n",
    "        )\n",
    "\n",
    "        # Update cpt to custom one if provided\n",
    "        if ecFEF2575prctecFEV1_cpt is not None:\n",
    "            ecFEF2575prctecFEV1.set_cpt(ecFEF2575prctecFEV1_cpt)\n",
    "\n",
    "        model = graph_builders.fev1_fef2575_o2sat_point_in_time_factor_graph(\n",
    "            HFEV1,\n",
    "            ecFEV1,\n",
    "            AR,\n",
    "            HO2Sat,\n",
    "            O2SatFFA,\n",
    "            IA,\n",
    "            UO2Sat,\n",
    "            O2Sat,\n",
    "            ecFEF2575prctecFEV1,\n",
    "            False,\n",
    "        )\n",
    "        inf_alg = apply_custom_bp(model)\n",
    "\n",
    "        variables = ih._get_vars_for_model(\n",
    "            variables_to_infer, AR, IA, HFEV1, HO2Sat, O2SatFFA, UO2Sat\n",
    "        )\n",
    "\n",
    "        def infer_and_unpack(row):\n",
    "            # Build evidence\n",
    "            evidence = []\n",
    "            if \"ecFEV1\" in observed_variables:\n",
    "                evidence.append([ecFEV1, row[\"ecFEV1\"]])\n",
    "            if \"O2Sat\" in observed_variables:\n",
    "                evidence.append([O2Sat, row[\"O2 Saturation\"]])\n",
    "            if \"ecFEF2575prctecFEV1\" in observed_variables:\n",
    "                evidence.append(\n",
    "                    [ecFEF2575prctecFEV1, row[\"ecFEF2575\"] / row[\"ecFEV1\"] * 100]\n",
    "                )\n",
    "\n",
    "            res = ih.infer_on_factor_graph(\n",
    "                inf_alg,\n",
    "                variables,\n",
    "                evidence,\n",
    "            )\n",
    "\n",
    "            res_values = (res[var.name].values for var in variables)\n",
    "\n",
    "            return row[\"Date Recorded\"], *res_values\n",
    "\n",
    "        res = df.apply(infer_and_unpack, axis=1)\n",
    "        return res\n",
    "\n",
    "    variables_to_infer_dict = {\n",
    "        i + 1: variables_to_infer[i] for i in range(len(variables_to_infer))\n",
    "    }\n",
    "    variables_to_infer_dict[0] = \"Date Recorded\"\n",
    "\n",
    "    resraw = df.groupby(\"ID\").apply(infer_vars_for_ID)\n",
    "    # resraw = df.iloc[np.r_[10:13, 3000:3007]].groupby(\"ID\").apply(infer_vars_for_ID)\n",
    "    res = (\n",
    "        resraw.apply(pd.Series)\n",
    "        .reset_index()\n",
    "        .rename(columns=variables_to_infer_dict)\n",
    "        .drop(columns=\"level_1\")\n",
    "    )\n",
    "\n",
    "    # Build model to get variables\n",
    "    (\n",
    "        HFEV1,\n",
    "        _,\n",
    "        AR,\n",
    "        HO2Sat,\n",
    "        O2SatFFA,\n",
    "        IA,\n",
    "        UO2Sat,\n",
    "        _,\n",
    "        _,\n",
    "    ) = var_builders.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n",
    "        160, 10, \"Female\"\n",
    "    )\n",
    "\n",
    "    print(variables_to_infer_dict)\n",
    "\n",
    "    def fn(model_var, row):\n",
    "        row.shape\n",
    "        return model_var.get_mean(row)\n",
    "\n",
    "    for model_var, str_var in ih._get_vars_and_str_for_model(\n",
    "        variables_to_infer, AR, IA, HFEV1, HO2Sat, O2SatFFA, UO2Sat\n",
    "    ):\n",
    "        print(res[str_var][0].shape)\n",
    "        print(model_var.name, str_var)\n",
    "        res[f\"{str_var} mean\"] = res[str_var].apply(lambda x: fn(model_var, x))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'IA', 2: 'AR', 0: 'Date Recorded'}\n",
      "(30,)\n",
      "Airway resistance (%) AR\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (30,) (45,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Infer IA using FEV1-FEF2575-based-AR\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m inf_res_df_3 \u001b[38;5;241m=\u001b[39m \u001b[43minfer_vars_and_get_back_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4007\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m11000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mecFEF2575prctecFEV1_cpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcpt_f3_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables_to_infer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecFEV1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mO2Sat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecFEF2575prctecFEV1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 120\u001b[0m, in \u001b[0;36minfer_vars_and_get_back_df\u001b[0;34m(df, ecFEF2575prctecFEV1_cpt, variables_to_infer, observed_variables)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res[str_var][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_var\u001b[38;5;241m.\u001b[39mname, str_var)\n\u001b[0;32m--> 120\u001b[0m     res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstr_var\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[29], line 120\u001b[0m, in \u001b[0;36minfer_vars_and_get_back_df.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res[str_var][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_var\u001b[38;5;241m.\u001b[39mname, str_var)\n\u001b[0;32m--> 120\u001b[0m     res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstr_var\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m res[str_var]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "Cell \u001b[0;32mIn[29], line 113\u001b[0m, in \u001b[0;36minfer_vars_and_get_back_df.<locals>.fn\u001b[0;34m(model_var, row)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(model_var, row):\n\u001b[1;32m    112\u001b[0m     row\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_var\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/phd/src/models/helpers.py:295\u001b[0m, in \u001b[0;36mVariableNode.get_mean\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean\u001b[39m(\u001b[38;5;28mself\u001b[39m, p):\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Returns the distribution's mean given an array of probabilities\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin_width\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (30,) (45,) "
     ]
    }
   ],
   "source": [
    "# Infer IA using FEV1-FEF2575-based-AR\n",
    "\n",
    "inf_res_df_3 = infer_vars_and_get_back_df(\n",
    "    df.iloc[np.r_[10:1300, 3000:4007, 10000:11000]],\n",
    "    ecFEF2575prctecFEV1_cpt=cpt_f3_2,\n",
    "    variables_to_infer=[\"IA\", \"AR\"],\n",
    "    observed_variables=[\"ecFEV1\", \"O2Sat\", \"ecFEF2575prctecFEV1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df, inf_res_df_3, on=[\"ID\", \"Date Recorded\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model the relationship between AR and IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' and 'p' must have same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m y_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIA mean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m ar_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEV1-FEF2575-based-AR\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m df_sampled, df_f3 \u001b[38;5;241m=\u001b[39m \u001b[43mcpt_and_plots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sampled_df_and_statistics_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIA mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m cpt_and_plots\u001b[38;5;241m.\u001b[39mplot_F3_mean_and_percentiles_per_AR_bin(df_f3, ar_col, y_col, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/phd/src/modelling_fef2575/cpt_and_plots.py:217\u001b[0m, in \u001b[0;36mget_sampled_df_and_statistics_df\u001b[0;34m(df, n_samples, AR, y_col)\u001b[0m\n\u001b[1;32m    212\u001b[0m df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR norm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_sampled\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mAR \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Create n AR samples per row\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAR norm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m df_sampled \u001b[38;5;241m=\u001b[39m df_sampled\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax sampled AR values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:965\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 965\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:981\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    984\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    985\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/phd/src/modelling_fef2575/cpt_and_plots.py:218\u001b[0m, in \u001b[0;36mget_sampled_df_and_statistics_df.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    212\u001b[0m df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR norm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_sampled\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mAR \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR\u001b[39m\u001b[38;5;124m\"\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Create n AR samples per row\u001b[39;00m\n\u001b[1;32m    217\u001b[0m df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_sampled\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mAR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAR norm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    221\u001b[0m df_sampled \u001b[38;5;241m=\u001b[39m df_sampled\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax sampled AR values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/phd/src/models/helpers.py:175\u001b[0m, in \u001b[0;36mVariableNode.sample\u001b[0;34m(self, n, p)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mRandomly select a midbins from the variable prior's distribution\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mIf the variable was continuous but has been discretised, it returns a random value inside the sampled bins range\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBy default it uses the variable's prior, but it can also use a custom distribution p\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     midbins \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmidbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     midbins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmidbins, n, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpt\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:968\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' and 'p' must have same size"
     ]
    }
   ],
   "source": [
    "# df[\"ecFEF2575%ecFEV1\"] = df[\"ecFEF2575\"] / df[\"ecFEV1\"] * 100\n",
    "\n",
    "# Parameters\n",
    "n_samples = 100\n",
    "\n",
    "# parameters\n",
    "IA = mh.VariableNode(\"Inactive alveoli (%)\", 0, 30, 1, prior={\"type\": \"uniform\"})\n",
    "AR = mh.VariableNode(\"Airway resistance (%)\", 0, 90, 2, prior=None)\n",
    "y_col = \"IA mean\"\n",
    "ar_col = \"FEV1-FEF2575-based-AR\"\n",
    "\n",
    "df_sampled, df_f3 = cpt_and_plots.get_sampled_df_and_statistics_df(\n",
    "    df3, n_samples, AR, \"IA mean\"\n",
    ")\n",
    "\n",
    "cpt_and_plots.plot_F3_mean_and_percentiles_per_AR_bin(df_f3, ar_col, y_col, save=True)\n",
    "# cpt_f3 = cpt_and_plots.calc_plot_cpt_var_given_AR(\n",
    "#     df_sampled, df_f3, n_samples, AR, ar_col, IA, y_col, save=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(30,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' and 'p' must have same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AR\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mn_samples, p\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR norm\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create n AR samples per row\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# df_sampled[\"AR sample\"] = df_sampled.apply(\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     lambda row: AR.sample(n=n_samples, p=row[\"AR norm\"]), axis=1\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sampled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m df_sampled \u001b[38;5;241m=\u001b[39m df_sampled\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax sampled AR values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(df_sampled[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR sample\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:965\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 965\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/phd/lib/python3.10/site-packages/pandas/core/apply.py:981\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    984\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    985\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m, in \u001b[0;36mfn\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_samples)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAR norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAR norm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/PhD/Code/phd/src/models/helpers.py:175\u001b[0m, in \u001b[0;36mVariableNode.sample\u001b[0;34m(self, n, p)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mRandomly select a midbins from the variable prior's distribution\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mIf the variable was continuous but has been discretised, it returns a random value inside the sampled bins range\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBy default it uses the variable's prior, but it can also use a custom distribution p\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     midbins \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmidbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     midbins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmidbins, n, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpt\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:968\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' and 'p' must have same size"
     ]
    }
   ],
   "source": [
    "df_sampled = df3.copy()\n",
    "df_sampled[\"AR sampled\"] = np.nan\n",
    "\n",
    "# Renormalise all AR distributions\n",
    "df_sampled[\"AR norm\"] = df_sampled.apply(lambda row: row.AR / sum(row[\"AR\"]), axis=1)\n",
    "\n",
    "\n",
    "def fn(row):\n",
    "    print(n_samples)\n",
    "    print(row[\"AR norm\"].shape)\n",
    "    return AR.sample(n=n_samples, p=row[\"AR norm\"])\n",
    "\n",
    "\n",
    "# Create n AR samples per row\n",
    "# df_sampled[\"AR sample\"] = df_sampled.apply(\n",
    "#     lambda row: AR.sample(n=n_samples, p=row[\"AR norm\"]), axis=1\n",
    "# )\n",
    "df_sampled[\"AR sample\"] = df_sampled.apply(fn, axis=1)\n",
    "\n",
    "df_sampled = df_sampled.explode(\"AR sample\").reset_index(drop=True)\n",
    "\n",
    "print(f'Max sampled AR values: {max(df_sampled[\"AR sample\"]):.2f}')\n",
    "\n",
    "df_sampled[\"AR bin\"] = pd.cut(\n",
    "    df_sampled[\"AR sample\"],\n",
    "    bins=np.arange(\n",
    "        np.floor(min(df_sampled[\"AR sample\"])),\n",
    "        np.ceil(max(df_sampled[\"AR sample\"])) + AR.bin_width,\n",
    "        AR.bin_width,\n",
    "    ),\n",
    ")\n",
    "\n",
    "df_f3 = (\n",
    "    df_sampled.groupby(\"AR bin\")\n",
    "    .agg(\n",
    "        mean=(y_col, \"mean\"),\n",
    "        std=(y_col, \"std\"),\n",
    "        median=(y_col, \"median\"),\n",
    "        p3=(y_col, lambda x: np.percentile(x, 3)),\n",
    "        p97=(y_col, lambda x: np.percentile(x, 97)),\n",
    "        p16=(y_col, lambda x: np.percentile(x, 16)),\n",
    "        p84=(y_col, lambda x: np.percentile(x, 84)),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_sampled[\"AR midbin\"] = df_sampled[\"AR bin\"].apply(\n",
    "    lambda x: x.left + AR.bin_width / 2\n",
    ")\n",
    "df_f3[\"AR midbin\"] = df_f3[\"AR bin\"].apply(lambda x: x.left + AR.bin_width / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AR.midbins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
