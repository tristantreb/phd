{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use the information about IA to refine F3. Initially, I buildt F3 using FEF25-75%FEV1 against FEV1-based-AR. The latter variable contains only the aspect of AR as measured by FEV1. In CF, high AR usually correlates with high IA. We can use this correlation to refine the uncertainty present in the FEV1-based-AR. The corrected FEV1-based-AR can therefore be closer to the true AR. We can use it to improve the model fo F3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.breathe_data as br\n",
    "import src.data.helpers as dh\n",
    "import src.models.helpers as mh\n",
    "import src.inference.helpers as ih\n",
    "import src.modelling_fef2575.cpt_and_plots as cpt_and_plots\n",
    "import src.models.var_builders as var_builders\n",
    "import src.models.graph_builders as graph_builders\n",
    "from src.inference.inf_algs import apply_bayes_net_bp, apply_factor_graph_bp\n",
    "import src.models.cpts.helpers as cpth\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    HFEV1,\n",
    "    ecFEV1,\n",
    "    AR,\n",
    "    HO2Sat,\n",
    "    O2SatFFA,\n",
    "    IA,\n",
    "    UO2Sat,\n",
    "    O2Sat,\n",
    "    ecFEF2575prctecFEV1,\n",
    ") = var_builders.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n",
    "    180, 10, \"Male\"\n",
    ")\n",
    "# (\n",
    "#     HFEV1,\n",
    "#     uecFEV1,\n",
    "#     ecFEV1,\n",
    "#     AR,\n",
    "#     HO2Sat,\n",
    "#     O2SatFFA,\n",
    "#     IA,\n",
    "#     UO2Sat,\n",
    "#     O2Sat,\n",
    "#     ecFEF2575prctecFEV1\n",
    "# ) = var_builders.o2sat_fev1_fef2575_point_in_time_model_noise_shared_healthy_vars_light(\n",
    "#     180, 10, \"Male\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan to refine F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need dataset with O2sat, FEV1, FEF25-75. Use as many datapoints as possible\n",
    "# Infer FEV1-based-AR using FEV1\n",
    "# Model F3 using FEV1-based-AR\n",
    "# Infer FEV1-FEF2575-based-AR using FEV1 and FEF25-75\n",
    "# Model F3 using FEV1-FEF2575-based-AR\n",
    "# Infer IA using FEV1-FEF2575-based-AR\n",
    "# Model AR-IA\n",
    "# Infer IA-FEV1-FEF2575-based-AR using FEV1, FEF25-75, IA\n",
    "# Model F3 using this new AR\n",
    "# Compare the two models: compare the mean, median, std-percentiles plots of both -> std should be smaller\n",
    "\n",
    "# Optionally repeat until std doesn't change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = br.load_meas_from_excel(\n",
    "    \"BR_O2_FEV1_FEF2575_with_idx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = br.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_PEF_Nan\")\n",
    "df = df.drop(columns=[\"PEF\", \"ecPEF (L/s)\", \"PEF (L/s)\"])\n",
    "df = df.dropna(subset=[\"FEV1\", \"O2 Saturation\", \"FEF2575\"])\n",
    "# df[\"ecFEF2575%ecFEV1\"] = df[\"FEF2575\"] / df[\"FEV1\"] * 100\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vars_and_get_back_df(\n",
    "    df,\n",
    "    variables_to_infer,\n",
    "    observed_variables,\n",
    "    ecFEF2575prctecFEV1_cpt=None,\n",
    "    IA_cpt=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Infer AR, IA, HFEV1, HO2Sat fo each entry in the dataset, for the given observed variables as evidence\n",
    "    \"\"\"\n",
    "\n",
    "    def infer_vars_for_ID(df):\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        # (\n",
    "        #     HFEV1,\n",
    "        #     ecFEV1,\n",
    "        #     AR,\n",
    "        #     HO2Sat,\n",
    "        #     O2SatFFA,\n",
    "        #     IA,\n",
    "        #     UO2Sat,\n",
    "        #     O2Sat,\n",
    "        #     ecFEF2575prctecFEV1,\n",
    "        # ) = var_builders.o2sat_fev1_fef2575_point_in_time_model_shared_healthy_vars(\n",
    "        #     df.Height[0], df.Age[0], df.Sex[0]\n",
    "        # )\n",
    "\n",
    "        # If with noise model\n",
    "        (\n",
    "            HFEV1,\n",
    "            uecFEV1,\n",
    "            ecFEV1,\n",
    "            AR,\n",
    "            HO2Sat,\n",
    "            O2SatFFA,\n",
    "            IA,\n",
    "            UO2Sat,\n",
    "            O2Sat,\n",
    "            ecFEF2575prctecFEV1,\n",
    "        ) = var_builders.o2sat_fev1_fef2575_point_in_time_model_noise_shared_healthy_vars_light(\n",
    "            df.Height[0], df.Age[0], df.Sex[0]\n",
    "        )\n",
    "\n",
    "        # Update cpt to custom one if provided\n",
    "        if ecFEF2575prctecFEV1_cpt is not None:\n",
    "            ecFEF2575prctecFEV1.set_cpt(ecFEF2575prctecFEV1_cpt)\n",
    "        if IA_cpt is None:\n",
    "            # model = graph_builders.fev1_fef2575_o2sat_point_in_time_factor_graph(\n",
    "            #     HFEV1,\n",
    "            #     ecFEV1,\n",
    "            #     AR,\n",
    "            #     HO2Sat,\n",
    "            #     O2SatFFA,\n",
    "            #     IA,\n",
    "            #     UO2Sat,\n",
    "            #     O2Sat,\n",
    "            #     ecFEF2575prctecFEV1,\n",
    "            #     False,\n",
    "            # )\n",
    "            model = graph_builders.fev1_fef2575_o2sat_point_in_time_noise_factor_graph(\n",
    "                HFEV1,\n",
    "                uecFEV1,\n",
    "                ecFEV1,\n",
    "                AR,\n",
    "                HO2Sat,\n",
    "                O2SatFFA,\n",
    "                IA,\n",
    "                UO2Sat,\n",
    "                O2Sat,\n",
    "                ecFEF2575prctecFEV1,\n",
    "                False,\n",
    "            )\n",
    "            inf_alg = apply_factor_graph_bp(model)\n",
    "        else:\n",
    "            # Else we model AR causing IA with the given CPT\n",
    "            IA.set_cpt(IA_cpt)\n",
    "            # Since this introduces a loop we have to use a Bayes Net to run the inference\n",
    "            # model = graph_builders.fev1_o2sat_fef2575_point_in_time_model(\n",
    "            #     HFEV1,\n",
    "            #     ecFEV1,\n",
    "            #     AR,\n",
    "            #     HO2Sat,\n",
    "            #     O2SatFFA,\n",
    "            #     IA,\n",
    "            #     UO2Sat,\n",
    "            #     O2Sat,\n",
    "            #     ecFEF2575prctecFEV1,\n",
    "            #     False,\n",
    "            # )\n",
    "            model = graph_builders.fev1_fef2575_o2sat_point_in_time_noise_factor_graph(\n",
    "                HFEV1,\n",
    "                uecFEV1,\n",
    "                ecFEV1,\n",
    "                AR,\n",
    "                HO2Sat,\n",
    "                O2SatFFA,\n",
    "                IA,\n",
    "                UO2Sat,\n",
    "                O2Sat,\n",
    "                ecFEF2575prctecFEV1,\n",
    "                False,\n",
    "            )\n",
    "            inf_alg = apply_bayes_net_bp(model)\n",
    "\n",
    "        def infer_and_unpack(row):\n",
    "            # Build evidence\n",
    "            evidence = [\n",
    "                [obs_var, row[obs_var.get_colname()]] for obs_var in observed_variables\n",
    "            ]\n",
    "\n",
    "            if IA_cpt is None:\n",
    "                res = ih.infer_on_factor_graph(\n",
    "                    inf_alg,\n",
    "                    variables_to_infer,\n",
    "                    evidence,\n",
    "                )\n",
    "            else:\n",
    "                # Infer on Bayes net\n",
    "                res = ih.infer(\n",
    "                    inf_alg,\n",
    "                    variables_to_infer,\n",
    "                    evidence,\n",
    "                )\n",
    "\n",
    "            res_values = (res[var.name].values for var in variables_to_infer)\n",
    "\n",
    "            return row[\"Date Recorded\"], *res_values\n",
    "\n",
    "        res = df.apply(infer_and_unpack, axis=1)\n",
    "        return res\n",
    "\n",
    "    variables_to_infer_dict = {\n",
    "        i + 1: variables_to_infer[i].get_abbr() for i in range(len(variables_to_infer))\n",
    "    }\n",
    "    variables_to_infer_dict[0] = \"Date Recorded\"\n",
    "\n",
    "    resraw = df.groupby(\"ID\").apply(infer_vars_for_ID)\n",
    "    # resraw = df.iloc[np.r_[10:13, 3000:3007]].groupby(\"ID\").apply(infer_vars_for_ID)\n",
    "    res = (\n",
    "        resraw.apply(pd.Series)\n",
    "        .reset_index()\n",
    "        .rename(columns=variables_to_infer_dict)\n",
    "        .drop(columns=\"level_1\")\n",
    "    )\n",
    "\n",
    "    for var in variables_to_infer:\n",
    "        res[f\"{var.get_abbr()} mean\"] = res[var.get_abbr()].apply(\n",
    "            lambda x: var.get_mean(x)\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model F3 using AR inferred from FEV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer FEV1-based-AR using FEV1\n",
    "\n",
    "# inf_res_df = infer_vars_and_get_back_df(\n",
    "#     df,\n",
    "#     # df.iloc[np.r_[10:1300, 3000:4007, 10000:11000]],\n",
    "#     variables_to_infer=[AR, IA],\n",
    "#     observed_variables=[ecFEV1, O2Sat],\n",
    "#     ecFEF2575prctecFEV1_cpt=None,\n",
    "# )\n",
    "# # Merge the inferred AR back to the original dataframe\n",
    "# df1 = pd.merge(df, inf_res_df, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "# df1.to_excel(\n",
    "#     dh.get_path_to_main()\n",
    "#     + \"ExcelFiles/BR/Refining_F3/infer_FEV1-based-AR_using_O2Sat_FEV1_noise_light.xlsx\",\n",
    "#     index=False,\n",
    "# )\n",
    "\n",
    "df1 = dh.load_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/Refining_F3/infer_AR_using_O2Sat_ecFEV1.xlsx\",\n",
    "    [\"AR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model F3 using FEV1-based-AR\n",
    "cpt_f3, df_f3, _ = cpt_and_plots.model_f3(\n",
    "    df1,\n",
    "    AR,\n",
    "    \"Airway resistance midbin in % (obs. var.: ecFEV1, O2 saturation)\",\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model F3 using AR inferred from FEV1 and FEF25-75 (using F3 to model F3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer FEV1-FEF2575-based-AR\n",
    "# inf_res_df_2 = infer_vars_and_get_back_df(\n",
    "#     df,\n",
    "#     # df.iloc[np.r_[10:1300, 3000:4007, 10000:11000]],\n",
    "#     variables_to_infer=[AR, IA],\n",
    "#     observed_variables=[ecFEV1, O2Sat, ecFEF2575prctecFEV1],\n",
    "#     ecFEF2575prctecFEV1_cpt=cpt_f3,\n",
    "# )\n",
    "# # # Merge the inferred AR back to the original dataframe\n",
    "# df2 = pd.merge(df, inf_res_df_2, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "# df2.to_excel(\n",
    "#     dh.get_path_to_main()\n",
    "#     + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR_using_O2Sat_FEV1_FEF2575.xlsx\",\n",
    "#     index=False,\n",
    "# )\n",
    "\n",
    "df2 = dh.load_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR_using_O2Sat_FEV1_FEF2575.xlsx\",\n",
    "    [\"AR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model F3 using FEV1-FEF2575-based-AR\n",
    "\n",
    "## TODO: why it gives nan when it's the first time I run it?\n",
    "cpt_f3_2, df_f3_2, _ = cpt_and_plots.model_f3(df2, AR, \"FEV1-FEF2575-based-AR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model AR-IA using AR inferred with FEV1 and FEF25-75 (using F3 refined with F3 once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer IA, AR using FEV1-FEF2575-based-AR\n",
    "\n",
    "# inf_res_df_3 = infer_vars_and_get_back_df(\n",
    "#     df,\n",
    "#     # df.iloc[np.r_[10:1300, 3000:4007, 10000:11000]],\n",
    "#     variables_to_infer=[IA, AR],\n",
    "#     observed_variables=[ecFEV1, O2Sat, ecFEF2575prctecFEV1],\n",
    "#     ecFEF2575prctecFEV1_cpt=cpt_f3_2,\n",
    "# )\n",
    "# df3 = pd.merge(df, inf_res_df_3, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "# df3.to_excel(\n",
    "#     dh.get_path_to_main()\n",
    "#     + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR-and-IA_using_O2Sat_FEV1_FEF2575.xlsx\",\n",
    "#     index=False,\n",
    "# )\n",
    "\n",
    "df3 = dh.load_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR-and-IA_using_O2Sat_FEV1_FEF2575.xlsx\",\n",
    "    [\"AR\", \"IA\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model the relationship between AR and IA, and add it to the model\n",
    "\n",
    "AR_bin_width = 4\n",
    "n_samples = 100\n",
    "\n",
    "df_sampled_3 = cpt_and_plots.get_sampled_df_and_statistics_df_for_IA(\n",
    "    df3, n_samples, AR, AR_bin_width, IA\n",
    ")\n",
    "\n",
    "# cpt_and_plots.plot_F3_mean_and_percentiles_per_AR_bin(df_f3, ar_col, y_col, save=True)\n",
    "\n",
    "ar_col = \"FEV1-FEF2575-based-AR\"\n",
    "cpt_ia_ar = cpt_and_plots.calc_plot_cpt_IA_given_AR(\n",
    "    df_sampled_3, AR, AR_bin_width, ar_col, IA, n_samples, save=True, debug=True\n",
    ")\n",
    "\n",
    "# The four last histograms have too few data to be reliable\n",
    "# Replacing them by the -11th\n",
    "idx_sixty_six_from_back = AR.card - AR.get_bin_for_value(66)[1]\n",
    "print(AR.get_bins_str()[-idx_sixty_six_from_back])\n",
    "for j in range(idx_sixty_six_from_back - 1):\n",
    "    cpt_ia_ar[:, -j - 1] = cpt_ia_ar[:, -idx_sixty_six_from_back]\n",
    "\n",
    "# Renormalise the CPT\n",
    "cpt_ia_ar = cpt_ia_ar / cpt_ia_ar.sum(axis=0)\n",
    "\n",
    "cpt_and_plots.check_IA_cpt(cpt_ia_ar, IA, AR, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.cpts.helpers as cpt\n",
    "\n",
    "\n",
    "def get_cpt(vars, suffix=None):\n",
    "    path_to_folder = dh.get_path_to_src() + \"models/cpts/\"\n",
    "    var_spec = map(\n",
    "        lambda var: f\"{cpt.name_to_abbr(var.name)}_{var.a}_{var.b}_{var.bin_width}\",\n",
    "        vars,\n",
    "    )\n",
    "    filename = \"_\".join(var_spec)\n",
    "\n",
    "    if suffix is not None:\n",
    "        filename = filename + suffix\n",
    "\n",
    "    arr = np.load(f\"{path_to_folder}{filename}.npy\")\n",
    "\n",
    "    assert len(vars) == len(arr.shape)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model F3 using AR inferred from AR-IA factor and FEV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Infer FEV1-based-AR with IA factor using FEV1\n",
    "\n",
    "# # Longer inference because of bayes net\n",
    "# inf_res_df_4 = infer_vars_and_get_back_df(\n",
    "#     df,\n",
    "#     variables_to_infer=[AR],\n",
    "#     observed_variables=[ecFEV1, O2Sat],\n",
    "#     ecFEF2575prctecFEV1_cpt=None,\n",
    "#     IA_cpt=get_cpt([IA, AR], \"_Dirichlet_prior\"),\n",
    "# )\n",
    "# df4 = pd.merge(df, inf_res_df_4, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "# # F4 is the IA-AR factor\n",
    "# df4.to_excel(\n",
    "#     dh.get_path_to_main()\n",
    "#     + \"ExcelFiles/BR/Refining_F3/infer_FEV1-based-AR_using_O2Sat_FEV1_F4-with-dirichlet-prior.xlsx\",\n",
    "#     index=False,\n",
    "# )\n",
    "\n",
    "df4 = dh.load_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/infer_FEV1-based-AR_using_O2Sat_FEV1_F4-with-dirichlet-prior.xlsx\",\n",
    "    [\"AR\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model F3 using FEV1-based-AR with IA factor\n",
    "cpt_f3_4, df_f3_4, _ = cpt_and_plots.model_f3(df4, AR, \"FEV1-based-AR with F4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model F3 using AR inferred from FEV1, FEF25-75 (refined with itself once), and the AR-IA factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer FEV1-FEF2575-based-AR with IA factor using FEV1 and F4\n",
    "\n",
    "inf_res_df_5 = infer_vars_and_get_back_df(\n",
    "    df,\n",
    "    # df.iloc[np.r_[10:1300, 3000:4007]],\n",
    "    variables_to_infer=[AR, IA],\n",
    "    observed_variables=[ecFEV1, O2Sat, ecFEF2575prctecFEV1],\n",
    "    ecFEF2575prctecFEV1_cpt=cpt_f3_2,\n",
    "    IA_cpt=cpt_ia_ar,\n",
    ")\n",
    "df5 = pd.merge(df, inf_res_df_5, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "df5.to_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR_using_O2Sat_FEV1_F4-with-dirichlet-prior.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.merge(df, inf_res_df_5, on=[\"ID\", \"Date Recorded\"], how=\"inner\")\n",
    "df5.to_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR_using_O2Sat_FEV1_F4.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model F3 using FEV1-based-AR with IA factor\n",
    "cpt_f3_5, df_f3_5, _ = cpt_and_plots.model_f3(df5, AR, \"FEV1-FEF2575-based-AR with F4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model F3 using AR from the two days model (FEV1, O2Sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas = br.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_with_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_tmp = dh.load_excel(\n",
    "    f\"{dh.get_path_to_main()}/ExcelFiles/BR/Refining_F3/infer_AR_with_two_days_model_O2Sat_FEV1.xlsx\",\n",
    "    [AR.name],\n",
    "    [\"Day\"],\n",
    ").drop(columns=[\"Unnamed: 0\", HO2Sat.name, IA.name, HFEV1.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6_tmp.merge(\n",
    "    df_meas, left_on=[\"ID\", \"Day\"], right_on=[\"ID\", \"Date Recorded\"], how=\"inner\"\n",
    ")\n",
    "print(df_meas.shape, \"length raw meas\")\n",
    "print(df6_tmp.shape, \"length two days model output\")\n",
    "print(df6.shape, \"length merged\")\n",
    "df6 = df6.drop(\n",
    "    columns=[\n",
    "        \"Day\",\n",
    "        \"FEV1\",\n",
    "        \"O2 Saturation\",\n",
    "        \"FEF2575\",\n",
    "        # \"ecFEV1\",\n",
    "        # \"ecFEF2575\",\n",
    "        \"Sex\",\n",
    "        \"Height\",\n",
    "        \"Age\",\n",
    "        \"Predicted FEV1\",\n",
    "        \"Healthy O2 Saturation\",\n",
    "        \"ecFEV1 % Predicted\",\n",
    "        \"FEV1 % Predicted\",\n",
    "        \"O2 Saturation % Healthy\",\n",
    "        \"idx ecFEV1 (L)\",\n",
    "        \"idx ecFEF25-75 % ecFEV1 (%)\",\n",
    "        \"idx O2 saturation (%)\",\n",
    "    ]\n",
    ").rename(columns={AR.name: \"AR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model F3\n",
    "cpt_f3_6, df_f3_6, _ = cpt_and_plots.model_f3(\n",
    "    df6,\n",
    "    AR,\n",
    "    \"Airway resistance midbin in %<br>Inferred using the two days model (Obs. var.: ecFEV1, O2 saturation)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model F3 using AR from two days model (ecFEV1), with add mult ecfev1 noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7_tmp = dh.load_excel(\n",
    "    f\"{dh.get_path_to_main()}/ExcelFiles/BR/Refining_F3/infer_AR_using_two_days_model_ecFEV1_ecfev1noiseaddmult.xlsx\",\n",
    "    [AR.name],\n",
    "    [\"Day\"],\n",
    ").drop(columns=[HO2Sat.name, HFEV1.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df7_tmp.to_excel(\n",
    "#     f\"{dh.get_path_to_main()}/ExcelFiles/BR/Refining_F3/infer_AR_using_two_days_model_ecFEV1_ecfev1noiseaddmult.xlsx\",\n",
    "#     index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meas = br.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df7_tmp.merge(\n",
    "    df_meas, left_on=[\"ID\", \"Day\"], right_on=[\"ID\", \"Date Recorded\"], how=\"inner\"\n",
    ")\n",
    "print(df_meas.shape, \"length raw meas\")\n",
    "print(df7_tmp.shape, \"length two days model output\")\n",
    "print(df7.shape, \"length merged\")\n",
    "df7 = df7.drop(\n",
    "    columns=[\n",
    "        \"Day\",\n",
    "        \"FEV1\",\n",
    "        \"O2 Saturation\",\n",
    "        \"FEF2575\",\n",
    "        # \"ecFEV1\",\n",
    "        # \"ecFEF2575\",\n",
    "        \"Sex\",\n",
    "        \"Height\",\n",
    "        \"Age\",\n",
    "        \"Predicted FEV1\",\n",
    "        \"Healthy O2 Saturation\",\n",
    "        \"ecFEV1 % Predicted\",\n",
    "        \"FEV1 % Predicted\",\n",
    "        \"O2 Saturation % Healthy\",\n",
    "        \"idx ecFEV1 (L)\",\n",
    "        \"idx ecFEF25-75 % ecFEV1 (%)\",\n",
    "        \"idx O2 saturation (%)\",\n",
    "    ]\n",
    ").rename(columns={AR.name: \"AR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model F3\n",
    "cpt_f3_7, df_f3_7, _ = cpt_and_plots.model_f3(\n",
    "    df7,\n",
    "    AR,\n",
    "    \"Airway resistance midbin in %<br>Two days model (ecFEV1, addmult ecfev1 noise)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_traces_F3_mean_and_percentiles_per_AR_bin(fig, df_f3, dash_style=\"solid\"):\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=df_f3[\"AR midbin\"],\n",
    "            y=df_f3[\"mean\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"blue\", dash=dash_style),\n",
    "            name=f\"Mean\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=df_f3[\"AR midbin\"],\n",
    "            y=df_f3[\"median\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"purple\", dash=dash_style),\n",
    "            name=f\"Median\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=df_f3[\"AR midbin\"],\n",
    "            y=df_f3[\"p16\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"red\", dash=dash_style),\n",
    "            name=f\"16th prctile\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=df_f3[\"AR midbin\"],\n",
    "            y=df_f3[\"p84\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"red\", dash=dash_style),\n",
    "            name=f\"84th prctile\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=df_f3[\"AR midbin\"],\n",
    "            y=df_f3[\"p3\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"green\", dash=dash_style),\n",
    "            name=f\"3th prctile\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_traces(\n",
    "        go.Scatter(\n",
    "            x=df_f3[\"AR midbin\"],\n",
    "            y=df_f3[\"p97\"],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"green\", dash=dash_style),\n",
    "            name=f\"97th prctile\",\n",
    "        )\n",
    "    )\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# df_f3 - F3 from FEV1-based-AR\n",
    "# df_f3_2 - F3 from FEV1-FEF2575-based-AR\n",
    "# df_f3_4 - F3 from FEV1-based-AR with IA-AR factor\n",
    "# F3 from FEV1-FEF2575-based-AR\n",
    "\n",
    "# ['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot']\n",
    "\n",
    "fig = go.Figure()\n",
    "add_traces_F3_mean_and_percentiles_per_AR_bin(fig, df_f3, \"dot\")\n",
    "dot_name = \"AR from FEV1\"\n",
    "add_traces_F3_mean_and_percentiles_per_AR_bin(fig, df_f3_2, \"dash\")\n",
    "dash_name = \"AR from FEV1 and FEF25-75\"\n",
    "add_traces_F3_mean_and_percentiles_per_AR_bin(fig, df_f3_6, \"solid\")\n",
    "solid_name = \"AR from two days model (FEV1 and O2sat)\"\n",
    "fig.add_annotation(\n",
    "    x=1.1,\n",
    "    y=1.15,\n",
    "    text=f\"dot: {dot_name}<br>dash: {dash_name}<br>solid: {solid_name}\",\n",
    "    xref=\"paper\",\n",
    "    yref=\"paper\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=12),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title=f\"Airway resistance midbin (%)\",\n",
    "    tickvals=np.floor(list(df_f3[\"AR midbin\"].values)),\n",
    ")\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.update_yaxes(title=\"ecFEF2575prctecFEV1 (%)\")\n",
    "title = f\"F3 statistics\"\n",
    "fig.update_layout(title=title, width=1200, height=700)\n",
    "# fig.write_image(\n",
    "#     f\"{dh.get_path_to_main()}PlotsBreathe/AR_modelling/CPT - Refined F3 - with Dirichlet prior.pdf\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanitize and save CPT P(ecFEF25-75|AR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_f3_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From graph, the dat is safe until 71% AR included (after too few data, and curve go up)\n",
    "idx_cut = AR.get_bin_for_value(73)[1]\n",
    "cptsave = cpt_f3_7[:, :idx_cut]\n",
    "# Replicate the last column to 100%\n",
    "cptsave = np.hstack(\n",
    "    (\n",
    "        cptsave,\n",
    "        np.tile(\n",
    "            cptsave[:, -1].reshape(-1, 1), AR.get_bin_for_value(100)[1] - idx_cut + 1\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptsave.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, title = cpth.plot_2d_cpt(cptsave, ecFEF2575prctecFEV1, AR, p_range=[0, 0.06], invert=True, height=4000, vspace=0.001, y_label_two_lines=True)\n",
    "# Save in CPTs\n",
    "fig.write_image(\n",
    "    f\"{dh.get_path_to_main()}PlotsBreathe/CPTs/CPT - P(AR|ecFEF25-75%ecFEV1) two days model (ecFEV1, addmult ecfev1 noise).pdf\"\n",
    ")\n",
    "# fig.write_image(\n",
    "#     f\"{dh.get_path_to_main()}PlotsBreathe/CPTs/CPT - P(ecFEF25-75%ecFEV1|AR) two days model (ecFEV1, addmult ecfev1 noise).pdf\"\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth.save_cpt(\n",
    "    [ecFEF2575prctecFEV1, AR], cptsave, suffix=\"_ecfev1_2_days_model_add_mult_noise\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ecFEF25-75%ecFEV1 vs AR sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled, df_f3 = cpt_and_plots.get_sampled_df_and_statistics_df(df3, 1, AR)\n",
    "df_sampled_tmp = df_sampled[df_sampled[\"ecFEF2575%ecFEV1\"] < 200]\n",
    "cpt_and_plots.plot_FEF2575_ratio_with_IA(\n",
    "    df_sampled_tmp, \"AR sample\", \"ecFEF2575%ecFEV1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the relationship between AR and IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = dh.load_excel(\n",
    "    dh.get_path_to_main()\n",
    "    + \"ExcelFiles/BR/Refining_F3/infer_FEV1-FEF2575-based-AR-and-IA_using_O2Sat_FEV1_FEF2575.xlsx\",\n",
    "    [\"AR\", \"IA\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between IA and AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df3, x=\"AR mean\", y=\"IA mean\", color=\"ID\")\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.update_layout(width=1000, height=600, title=f\"IA vs AR\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is there fewer points with high IA where AR is in 25-50%?\n",
    "# Outlying IA values are specific to a few (5) individuals. We just don't have an individual which is in the 25-50%.\n",
    "# It makes sense to add Dirichlet data prior\n",
    "df3[(df3[\"AR mean\"] < 30) & (df3[\"IA mean\"] > 8)].drop(columns=[\"AR\", \"IA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between IA and AR after sampling (+ Dirichlet input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_bin_width = 10  # Not necessary for sampling, hence putting a high value\n",
    "n_samples = 20\n",
    "df_sampled_tmp = cpt_and_plots.get_sampled_df_and_statistics_df_for_IA(\n",
    "    df3, n_samples, AR, AR_bin_width, IA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generated_dirichlet_fake_data_prior(df, AR, IA, n):\n",
    "    dirichlet_data = pd.DataFrame()\n",
    "    for ar_low, ar_high in AR.get_bins_arr():\n",
    "        for ia_low, ia_high in IA.get_bins_arr():\n",
    "            dirichlet_sample = pd.DataFrame(\n",
    "                {\n",
    "                    \"AR sample\": np.random.uniform(ar_low, ar_high, n),\n",
    "                    \"IA sample\": np.random.uniform(ia_low, ia_high, n),\n",
    "                }\n",
    "            )\n",
    "            dirichlet_data = pd.concat([dirichlet_data, dirichlet_sample])\n",
    "\n",
    "    df[\"Dirichlet\"] = False\n",
    "    dirichlet_data[\"Dirichlet\"] = True\n",
    "\n",
    "    return pd.concat([df, dirichlet_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dirichlet input\n",
    "AR_bin_width = 4\n",
    "IA_bin_width = 1\n",
    "df_sampled_tmp = df_sampled_tmp[[\"IA sample\", \"AR sample\"]]\n",
    "df_sampled_tmp = cpt_and_plots.add_binned_up_var(\n",
    "    df_sampled_tmp, \"AR sample\", \"AR\", AR_bin_width\n",
    ")\n",
    "df_sampled_tmp = cpt_and_plots.add_binned_up_var(\n",
    "    df_sampled_tmp, \"IA sample\", \"IA\", IA_bin_width\n",
    ")\n",
    "\n",
    "# For each AR bin and for each IA bin, add a Dirichlet prior of 10 uniformly distributed datapoints\n",
    "n_dirichlet = 1  # 20 samples with bin width of 10 = 4 samples with bin width of 2\n",
    "\n",
    "# Using bins with full resolution\n",
    "df_sampled_tmp_dirichet = add_generated_dirichlet_fake_data_prior(\n",
    "    df_sampled_tmp, AR, IA, n_dirichlet\n",
    ")\n",
    "print(df_sampled_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_sampled_tmp, x=\"AR sample\", y=\"IA sample\", color=\"ID\")\n",
    "# fig = px.scatter(df_sampled_tmp_dirichet, x=\"AR sample\", y=\"IA sample\", color='Dirichlet')\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.update_layout(width=1000, height=600, title=f\"IA vs AR, {n_samples} samples\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_bin_width = 4\n",
    "IA_bin_width = 1\n",
    "n_samples = 100\n",
    "ar_col = \"FEV1-FEF2575-based AR\"\n",
    "\n",
    "df_sampled_3 = cpt_and_plots.get_sampled_df_for_AR_IA(df3, n_samples, AR, IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dirichlet prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dirichlet fake data\n",
    "print(df_sampled_3.shape)\n",
    "# 4m datapoints is way to much, we need to randomly pick a subset of 100k of it\n",
    "\n",
    "n_dirichlet = 1\n",
    "df_sampled_3_dirichlet = add_generated_dirichlet_fake_data_prior(\n",
    "    df_sampled_3, AR, IA, n_dirichlet\n",
    ")\n",
    "\n",
    "n_samples_filtered = 300000\n",
    "df_sampled_3_dirichlet_reduced = df_sampled_3_dirichlet.sample(n_samples_filtered)\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_sampled_3_dirichlet_reduced, x=\"AR sample\", y=\"IA sample\", color=\"Dirichlet\"\n",
    ")\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    title=f\"IA vs AR, {n_samples_filtered} samples drawn after a {n_samples}x supersampling\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin up variables\n",
    "df_sample_fit = df_sampled_3_dirichlet\n",
    "# df_sample_fit = df_sampled_3\n",
    "\n",
    "df_sample_fit = cpt_and_plots.add_binned_up_var(\n",
    "    df_sample_fit, \"AR sample\", \"AR\", AR_bin_width\n",
    ")\n",
    "df_sample_fit = cpt_and_plots.add_binned_up_var(\n",
    "    df_sample_fit, \"IA sample\", \"IA\", IA_bin_width\n",
    ")\n",
    "\n",
    "ar_groups = np.sort(list(df_sample_fit[\"AR midbin\"].unique()))\n",
    "ar_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Boltzmann MLE/MSE, custom exp MSE, Log series MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "cpt_ia_ar = np.zeros([IA.card, len(ar_groups), 4])\n",
    "\n",
    "# ar_groups_with_n = df_sample_fit['AR midbin'].value_counts().sort_index()\n",
    "# ar_group_index = list(map(lambda ar_value: f\"AR={ar_value:g}%\", ar_groups_with_n.index))\n",
    "# ar_group_count = list(map(lambda ar_count: f\"n={ar_count}\", ar_groups_with_n.values))\n",
    "# ar_group_legend = [f\"AR midbin={ar_group_index:g}%<br>n={ar_group_count}\" for ar_group_index, ar_group_count in zip(ar_groups_with_n.index, ar_groups_with_n.values)]\n",
    "\n",
    "\n",
    "# f\"AR={ar_group}%<br>n={df_tmp['IA sample'].shape[0]}\n",
    "\n",
    "for fit_id in [1, 2, 3, 4]:\n",
    "\n",
    "    fig = make_subplots(\n",
    "        cols=2,\n",
    "        rows=len(ar_groups),\n",
    "        shared_xaxes=\"all\",\n",
    "        # y_title=\"Probability\",\n",
    "        x_title=\"Inactive alveoli midbin value (%)\",\n",
    "        # row_titles=ar_group_legend,\n",
    "        column_titles=[\n",
    "            \"Probabilities given in linear scale\",\n",
    "            \"Probabilities given in log scale\",\n",
    "        ],\n",
    "        # vertical_spacing=0.02,\n",
    "        horizontal_spacing=0.04,\n",
    "    )\n",
    "\n",
    "    for idx, ar_group in enumerate(ar_groups):\n",
    "        df_tmp = df_sample_fit[df_sample_fit[\"AR midbin\"] == ar_group].copy()\n",
    "\n",
    "        # Create histogram data for IA, binned by IA bins\n",
    "        s_ia_hist = df_tmp[\"IA midbin\"].value_counts()\n",
    "\n",
    "        # Add 10% of the data distributed evenly on each bin\n",
    "        # print(\"dirichlet factor\", round(s_ia_hist.sum() * 0.1 / IA.card))\n",
    "        # s_ia_hist_dirichlet = s_ia_hist  # + round(s_ia_hist.sum() * 0.1 / IA.card)\n",
    "        # s_ia_hist_dirichlet = s_ia_hist  + 100\n",
    "        # s_ia_hist_norm = s_ia_hist_dirichlet / s_ia_hist_dirichlet.sum()\n",
    "        s_ia_hist_norm = s_ia_hist / s_ia_hist.sum()\n",
    "\n",
    "        x = np.array(s_ia_hist_norm.index)\n",
    "        p = s_ia_hist_norm.values\n",
    "\n",
    "        # The boltzmann distribution is defined for integer values (not float)\n",
    "        # That means we can't use the midbin value of the IA bins (since it's usually a float)\n",
    "        # Instead we'll designate the bin by its lower boundary\n",
    "        # Input data: the midbin value (uniform approximation within each bin).\n",
    "        # Output data fetched using the bin's lower boundary value\n",
    "\n",
    "        def get_y_for_fit(fit_id):\n",
    "            # Boltzmann fit with MLE\n",
    "            if fit_id == 1:\n",
    "                bounds = [(0, 2), (IA.card, IA.card)]\n",
    "                result = stats.fit(\n",
    "                    stats.boltzmann, df_tmp[\"IA midbin\"], bounds, method=\"mle\"\n",
    "                )\n",
    "                dist_name = \"Boltzmann\"\n",
    "                params_str = f\"param={result.params.lambda_:.4g}\"\n",
    "                print(f\"{result}\")\n",
    "                y_fit = stats.boltzmann(*result.params).pmf(IA.bins)\n",
    "\n",
    "            # Log series fit with MLE\n",
    "            if fit_id == 2:\n",
    "                bounds = [(0, 1)]\n",
    "                result = stats.fit(\n",
    "                    stats.logser, df_tmp[\"IA midbin\"].to_numpy() + 1, bounds\n",
    "                )\n",
    "                dist_name = \"Log-Series\"\n",
    "                params_str = f\"param={result.params.p:.4g}\"\n",
    "                print(f\"{result}\")\n",
    "                y_fit = stats.logser(*result.params).pmf(IA.bins + 1)\n",
    "\n",
    "            # Fit decay with MSE\n",
    "            if fit_id == 3:\n",
    "                dist_name = \"Exponential with MSE\"\n",
    "\n",
    "                def func(x, A, K, C):\n",
    "                    # C = 0\n",
    "                    # return K * x + np.log(A)\n",
    "                    return A * np.exp(-x / K) + C\n",
    "\n",
    "                def objective(params, x, y):\n",
    "                    return np.sum((func(x, *params) - y) ** 2)\n",
    "\n",
    "                # Initial guess for parameters\n",
    "                initial_guess = [1, 1, 0]\n",
    "                # Enforce constraint: function can't give negative value\n",
    "                cons = {\n",
    "                    \"type\": \"ineq\",\n",
    "                    \"fun\": lambda params: func(x, *params),\n",
    "                }\n",
    "                # cons = {}\n",
    "                # Minimize the objective function with the constraint\n",
    "                result = minimize(\n",
    "                    objective, initial_guess, args=(x, p), constraints=cons\n",
    "                )\n",
    "                A, K, C = result.x\n",
    "                print(f\"A: {A:.5f}, K: {K:.5f}, C: {C:.5f}\")\n",
    "                params_str = f\"A={A:.2g}<br>K={K:.2g}<br>C={C:.2g}\"\n",
    "                # params_str = f\"{A:.2g},{K:.2g},{C:.2g}\"\n",
    "                y_fit = func(IA.midbins, A, K, C)\n",
    "\n",
    "            if fit_id == 4:\n",
    "                # Fit Boltzmann with MSE\n",
    "                dist_name = \"Boltzmann with MSE\"\n",
    "\n",
    "                def func(x, lambda_):\n",
    "                    # C = 0\n",
    "                    # return K * x + np.log(A)\n",
    "                    return (\n",
    "                        (1 - np.exp(-lambda_))\n",
    "                        * np.exp(-lambda_ * x)\n",
    "                        / (1 - np.exp(-lambda_ * IA.card))\n",
    "                    )\n",
    "\n",
    "                def objective(params, x, y):\n",
    "                    return np.sum((func(x, *params) - y) ** 2)\n",
    "\n",
    "                # Initial guess for parameters\n",
    "                initial_guess = [0.8]\n",
    "                # Enforce constraint: function can't give negative value\n",
    "                cons = {\n",
    "                    \"type\": \"ineq\",\n",
    "                    \"fun\": lambda params: func(x, *params),\n",
    "                }\n",
    "                # cons = {}\n",
    "                # Minimize the objective function with the constraint\n",
    "                result = minimize(\n",
    "                    objective, initial_guess, args=(x, p), constraints=cons\n",
    "                )\n",
    "                [lambda_] = result.x\n",
    "                print(f\"lambda_={lambda_:.5g}\")\n",
    "                params_str = f\"param={lambda_:.4g}\"\n",
    "                y_fit = func(IA.midbins, result.x)\n",
    "            return y_fit, dist_name, params_str\n",
    "\n",
    "        y_fit_plot, dist_name, params_str = get_y_for_fit(fit_id)\n",
    "        cpt_ia_ar[:, idx, fit_id - 1] = y_fit_plot\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=x,\n",
    "                y=p,\n",
    "                name=\"Inferred inactive alveoli data\",\n",
    "                marker=dict(color=\"#0072b2\"),\n",
    "                legendgroup=\"2\",\n",
    "                showlegend=True if idx == 0 else False,\n",
    "            ),\n",
    "            col=1,\n",
    "            row=idx + 1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=IA.midbins,\n",
    "                y=y_fit_plot,\n",
    "                name=f\"Fitted {dist_name} distribution\",\n",
    "                marker=dict(color=\"#d55e00\"),\n",
    "                legendgroup=\"1\",\n",
    "                showlegend=True if idx == 0 else False,\n",
    "            ),\n",
    "            col=1,\n",
    "            row=idx + 1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=x,\n",
    "                y=p,\n",
    "                name=\"Inactive alveoli data\",\n",
    "                marker=dict(color=\"#0072b2\"),\n",
    "                legendgroup=\"2\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            col=2,\n",
    "            row=idx + 1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=IA.midbins,\n",
    "                y=y_fit_plot,\n",
    "                name=f\"Fitted {dist_name} distribution\",\n",
    "                marker=dict(color=\"#d55e00\"),\n",
    "                legendgroup=\"1\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            col=2,\n",
    "            row=idx + 1,\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(\n",
    "            title=f\"Probability<br><br>AR={ar_group:g}%<br>n={df_tmp['IA sample'].shape[0]}<br>{params_str}\",\n",
    "            col=1,\n",
    "            row=idx + 1,\n",
    "            range=[0, 0.64],\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            type=\"log\", col=2, row=idx + 1, range=[np.log(10e-5), np.log(1)]\n",
    "        )\n",
    "\n",
    "    fig.update_xaxes(tickvals=IA.midbins)\n",
    "    title = f\"AR-IA CPT with {dist_name} fit - distribution of inactive alveoli (IA) given each bin of airway resistance ({len(ar_groups)} AR groups)\"\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1600,\n",
    "        height=3500,\n",
    "        font=dict(size=9),\n",
    "        # title=f\"P({IA.name} | Airway resistance in % (ar_col))\",\n",
    "        title=f\"{title}<br> using {n_samples} pairs of samples drawn from AR and IA's inferred distributions as input data\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    )\n",
    "    fig.update_annotations(font_size=10)\n",
    "    # fig.show()\n",
    "    fig.write_image(\n",
    "        dh.get_path_to_main()\n",
    "        # + f\"PlotsBreathe/AR_modelling/CPT IA-AR - 22 groups/{title}.pdf\"\n",
    "        + f\"PlotsBreathe/AR_modelling/CPT IA-AR - 22 groups - with Dirichlet fake data/{title}.pdf\"\n",
    "    )\n",
    "\n",
    "# An Botlzmann fit is not ideal: with an exponential decay, the decay rate has to be small enough to prevent 0 probabilities for high IA values\n",
    "# Exponential decay is too strong\n",
    "# Try log decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_ia_ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "fig = go.Figure()\n",
    "lambda_, N = 0.3, 100\n",
    "rv1 = stats.boltzmann(lambda_, N, loc=0)\n",
    "rv2 = stats.logser(p=0.7)\n",
    "rv3 = stats.poisson(mu=10)\n",
    "res1 = rv1.pmf(IA.bins)\n",
    "res2 = rv2.pmf(IA.bins + 1)\n",
    "# res3 = rv3.pmf(IA.bins+1)\n",
    "fig.add_trace(go.Bar(x=IA.midbins, y=res1 / sum(res1), name=\"Boltzmann\"))\n",
    "fig.add_trace(go.Bar(x=IA.midbins, y=res2 / sum(res2), name=\"Log-series\"))\n",
    "# fig.add_trace(go.Bar(x=IA.midbins, y=res3/sum(res3), name='Poisson'))\n",
    "# rv2 = stats.planck()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse IA-AR cpt (with AR rebinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.inference.helpers as ih\n",
    "\n",
    "AR_rebinned = mh.VariableNode(\n",
    "    \"Airway resistance (%)\", 0, 90, 4, prior={\"type\": \"uniform\"}\n",
    ")\n",
    "\n",
    "# cpt_ia_ar = cpt.get_cpt([IA, AR])\n",
    "print(cpt_ia_ar.shape)\n",
    "print(\"IA dim\", IA.card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cpt using import src.models.cpts.helpers as cpt_helpers.plot_2d_cpt\n",
    "\n",
    "# Create subplots\n",
    "# n_ar_bins = AR.card\n",
    "# n_ar_bins = len(ar_groups)\n",
    "\n",
    "# fig = make_subplots(rows=n_ar_bins, cols=1, shared_xaxes=True, vertical_spacing=0.005)\n",
    "\n",
    "# for i in range(n_ar_bins):\n",
    "#     p = cpt_ia_ar[:, i, 1]\n",
    "#     ih.plot_histogram(fig, IA, p, IA.a, IA.b, i+1, 1, colour='#0072b2', annot=False)\n",
    "#     fig.update_yaxes(title_text=f\"AR={AR_rebinned.midbins[i]:2g}%\", row=i + 1, col=1)\n",
    "\n",
    "# title = f\"IA-AR CPT with Dirichlet prior - IA given AR ({len(ar_groups)} AR groups)\"\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=title,\n",
    "#     width=500,\n",
    "#     height=1300,\n",
    "#     showlegend=False,\n",
    "#     font=dict(size=8),\n",
    "# )\n",
    "# # fig.show()\n",
    "# fig.write_image(\n",
    "#     dh.get_path_to_main()\n",
    "#     + f\"PlotsBreathe/AR_modelling/{title}.pdf\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cpt using import src.models.cpts.helpers as cpt_helpers.plot_2d_cpt\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=IA.card, cols=1, shared_xaxes=True, vertical_spacing=0.003)\n",
    "\n",
    "for i in range(IA.card):\n",
    "    p = cpt_ia_ar[i, :, 1] / sum(cpt_ia_ar[i, :, 1])\n",
    "    ih.plot_histogram(\n",
    "        fig,\n",
    "        AR_rebinned,\n",
    "        p,\n",
    "        AR_rebinned.a,\n",
    "        AR_rebinned.b,\n",
    "        i + 1,\n",
    "        1,\n",
    "        colour=\"#0072b2\",\n",
    "        annot=False,\n",
    "    )\n",
    "    fig.update_yaxes(title_text=f\"IA={IA.midbins[i]}%\", row=i + 1, col=1)\n",
    "    # Add tickvals on x axis\n",
    "    fig.update_xaxes(tickvals=ar_groups, row=i + 1, col=1)\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=76,\n",
    "        x1=90,\n",
    "        y0=0,\n",
    "        y1=0.37,\n",
    "        line=dict(color=\"red\", width=1),\n",
    "        fillcolor=\"red\",\n",
    "        opacity=0.2,\n",
    "        row=i + 1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"Airway resistance midbin (%)\", row=IA.card, col=1)\n",
    "fig.update_yaxes(range=[0, 0.37], tickvals=[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35])\n",
    "\n",
    "title = f\"IA-AR CPT with Dirichlet prior - AR given IA ({len(ar_groups)} AR groups)\"\n",
    "\n",
    "fig.update_layout(\n",
    "    title=title,\n",
    "    width=600,\n",
    "    height=2500,\n",
    "    showlegend=False,\n",
    "    font=dict(size=8),\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_image(dh.get_path_to_main() + f\"PlotsBreathe/AR_modelling/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format CPT to full AR resolution, analyse it and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.models.cpts.helpers as cpt\n",
    "\n",
    "cpt_ia_ar.shape\n",
    "\n",
    "print(AR.card)\n",
    "print(AR_rebinned.card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the AR dim for 45 bins instead of 22\n",
    "cpt_ia_ar_final = np.zeros([IA.card, AR.card])\n",
    "\n",
    "# Each bin is replicated 2 times\n",
    "for i in range(cpt_ia_ar.shape[1] - 1):\n",
    "    for j in [0, 1]:\n",
    "        print(i * 2 + j)\n",
    "        cpt_ia_ar_final[:, i * 2 + j] = cpt_ia_ar[:, i, 1]\n",
    "\n",
    "# After AR 72-76%, replicate the same data\n",
    "print(f\"Unreliable data at bin: {AR.get_bin_for_value(76)}\")\n",
    "for i in np.arange(38, AR.card):\n",
    "    cpt_ia_ar_final[:, i] = cpt_ia_ar_final[:, 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "plot_bins = range(AR.card)\n",
    "vspace = 0.003\n",
    "height = 2500\n",
    "title = (\n",
    "    f\"IA-AR full CPT with Dirichlet prior - IA given AR ({len(ar_groups)} AR groups)\"\n",
    ")\n",
    "\n",
    "# plot_bins = np.arange(0, AR.card, 6)\n",
    "# vspace=0.02\n",
    "# height=700\n",
    "# title = f\"IA-AR full CPT with Dirichlet prior - IA given AR ({len(ar_groups)} AR groups) - summary\"\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(plot_bins), cols=1, shared_xaxes=True, vertical_spacing=vspace\n",
    ")\n",
    "\n",
    "for i, idx in enumerate(plot_bins):\n",
    "    p = cpt_ia_ar_final[:, idx]\n",
    "    ih.plot_histogram(fig, IA, p, IA.a, IA.b, i + 1, 1, colour=\"#0072b2\", annot=False)\n",
    "    fig.update_yaxes(\n",
    "        title_text=f\"{AR.midbins[idx]:2g}%\", row=i + 1, col=1, range=[0, 0.6]\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=title,\n",
    "    width=500,\n",
    "    height=height,\n",
    "    showlegend=False,\n",
    "    font=dict(size=8),\n",
    ")\n",
    "# # fig.show()\n",
    "# fig.write_image(\n",
    "#     dh.get_path_to_main()\n",
    "#     + f\"PlotsBreathe/AR_modelling/{title}.pdf\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "plot_bins = IA.bins.astype(int)\n",
    "vspace = 0.003\n",
    "height = 2500\n",
    "title = (\n",
    "    f\"IA-AR full CPT with Dirichlet prior - AR given IA ({len(ar_groups)} AR groups)\"\n",
    ")\n",
    "\n",
    "# plot_bins = np.arange(0, IA.card, 4)\n",
    "# vspace=0.02\n",
    "# height=700\n",
    "# title = f\"IA-AR full CPT with Dirichlet prior - AR given IA ({len(ar_groups)} AR groups) - summary\"\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=len(plot_bins), cols=1, shared_xaxes=True, vertical_spacing=vspace\n",
    ")\n",
    "\n",
    "for i, idx in enumerate(plot_bins):\n",
    "    p = cpt_ia_ar_final[idx, :] / sum(cpt_ia_ar_final[idx, :])\n",
    "    ih.plot_histogram(fig, AR, p, AR.a, AR.b, i + 1, 1, colour=\"#0072b2\", annot=False)\n",
    "    fig.update_yaxes(title_text=f\"IA={IA.midbins[idx]}%\", row=i + 1, col=1)\n",
    "    # Add tickvals on x axis\n",
    "    fig.update_xaxes(tickvals=ar_groups, row=i + 1, col=1)\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=76,\n",
    "        x1=90,\n",
    "        y0=0,\n",
    "        y1=0.37,\n",
    "        line=dict(color=\"yellow\", width=1),\n",
    "        fillcolor=\"yellow\",\n",
    "        opacity=0.2,\n",
    "        row=i + 1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"Airway resistance midbin (%)\", row=IA.card, col=1)\n",
    "fig.update_yaxes(range=[0, 0.1], tickvals=[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=title,\n",
    "    width=600,\n",
    "    height=height,\n",
    "    showlegend=False,\n",
    "    font=dict(size=8),\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_image(dh.get_path_to_main() + f\"PlotsBreathe/AR_modelling/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try this cpt\n",
    "import src.models.cpts.helpers as cpt\n",
    "\n",
    "cpt.save_cpt([IA, AR], cpt_ia_ar_final, \"_Dirichlet_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
