{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement of the through time factor\n",
    "\n",
    "\n",
    "AR change factor card: ARxARxS\n",
    "\n",
    "\n",
    "S is the variable that controls the standard deviation parameter of the gaussian noise added to the previous day's airway resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import src.models.helpers as mh\n",
    "import src.models.cpts.helpers as cpth\n",
    "import src.data.breathe_data as bd\n",
    "import src.modelling_ar.ar as ar\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR = mh.VariableNode(\"Airway resistance (%)\", 0, 90, 2, prior=None)\n",
    "AR1 = mh.VariableNode(\"Airway resistance day 1 (%)\", 0, 90, 2, prior=None)\n",
    "AR2 = mh.VariableNode(\"Airway resistance day 2 (%)\", 0, 90, 2, prior=None)\n",
    "# AR = mh.VariableNode(\"Airway resistance (%)\", 0, 90, 1, prior=None)\n",
    "# AR1 = mh.VariableNode(\"Airway resistance day 1 (%)\", 0, 90, 1, prior=None)\n",
    "# AR2 = mh.VariableNode(\"Airway resistance day 2 (%)\", 0, 90, 1, prior=None)\n",
    "# S = mh.DiscreteVariableNode(\"AR change factor shape\", 1, 27, 1, prior=None)\n",
    "# S.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights into different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each bin of AR is uniformly distributed\n",
    "# P(AR2 | AR1 = [0, 2]) is the convolution of a laplace distribution with a uniform distribution\n",
    "\n",
    "\n",
    "# Let's just take the midbin for now\n",
    "def laplace_pdf(x, mu, b):\n",
    "    return 1 / (2 * b) * np.exp(-np.abs(x - mu) / b)\n",
    "\n",
    "\n",
    "def gaussian_pdf(x, mu, sigma):\n",
    "    return 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "\n",
    "\n",
    "y_laplace = laplace_pdf(AR2.midbins, AR1.midbins[10], 5)\n",
    "y_laplace = y_laplace / np.sum(y_laplace)\n",
    "\n",
    "y_laplace = laplace_pdf(AR2.midbins, AR1.midbins[10], 5)\n",
    "y_laplace = y_laplace / np.sum(y_laplace)\n",
    "\n",
    "y_gaussian = gaussian_pdf(AR2.midbins, AR1.midbins[10], 5)\n",
    "y_gaussian = y_gaussian / np.sum(y_gaussian)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=AR2.midbins, y=y_laplace, mode=\"markers+lines\"))\n",
    "# fig.add_trace(go.Scatter(x=AR2.midbins, y=y_gaussian, mode='markers+lines'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot histogram plot for AR2 samples using go figure\n",
    "fig = go.Figure()\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=AR2.midbins,\n",
    "        y=cpt[:, 10, 4],\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=5, color=\"black\"),\n",
    "        line=dict(width=1.5, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"Validation of numerical computation of U({ar_down}, {ar_up}) x Laplace(U, s={shape})<br>against sampling (n={n})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR1 = mh.VariableNode(\"Airway resistance day 1 (%)\", 0, 90, 2, prior=None)\n",
    "AR2 = mh.VariableNode(\"Airway resistance day 2 (%)\", 0, 90, 2, prior=None)\n",
    "\n",
    "cpt = np.zeros((AR2.card, AR1.card))\n",
    "\n",
    "sigma_spike = 0.2\n",
    "sigma_tails = 10\n",
    "weight_spike = 0.2\n",
    "\n",
    "for i, z in enumerate(AR2.get_bins_arr()):\n",
    "    for j, y in enumerate(AR1.get_bins_arr()):\n",
    "        cpt[i, j] = ar.p_uniform_x_gmm(\n",
    "            z[0], z[1], y[0], y[1], sigma_spike, sigma_tails, weight_spike\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt /= cpt.sum(axis=0)\n",
    "# Add extra dimension to cpt\n",
    "cpt = np.expand_dims(cpt, axis=2)\n",
    "cpt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate against sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(AR2 | AR1 = [0, 2]) is the convolution of a laplace distribution with a uniform distribution\n",
    "# Sample AR1\n",
    "def sample_from_uniform_x_gmm(ar1, ar2, sigma_spike, sigma_tails, weight_spike, n):\n",
    "    n_spike = int(n * weight_spike)\n",
    "    n_tail = n - n_spike\n",
    "    ar1_spike = np.random.uniform(ar1, ar2, n_spike)\n",
    "    ar1_tail = np.random.uniform(ar1, ar2, n_tail)\n",
    "\n",
    "    ar2_spike = np.random.normal(ar1_spike, sigma_spike)\n",
    "    ar2_tail = np.random.normal(ar1_tail, sigma_tails)\n",
    "\n",
    "    return np.concatenate([ar2_spike, ar2_tail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "z = AR1.get_bins_arr()[j]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "xbins = np.arange(AR.a, AR.b + AR.bin_width / 2, AR.bin_width)\n",
    "\n",
    "for n in [200000000, 20000000, 10000000, 8000000, 6000000, 4000000, 2000000]:\n",
    "    ar2_samples = sample_from_uniform_x_gmm(\n",
    "        z[0], z[1], sigma_spike, sigma_tails, weight_spike, n\n",
    "    )\n",
    "    hist, bins = np.histogram(ar2_samples, bins=xbins)\n",
    "    hist_norm = hist / len(ar2_samples)\n",
    "\n",
    "    print(f\"n={n}, abs diff = {np.sum(np.abs(hist_norm - cpt[:, j, 0]))}\")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=ar2_samples,\n",
    "        histnorm=\"probability\",\n",
    "        xbins=dict(size=AR2.bin_width, start=AR2.a, end=AR2.b),\n",
    "    )\n",
    ")\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=AR2.midbins,\n",
    "        y=cpt[:, j, 0],\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"Numerical computation of U({z[0]}, {z[1]}) x <br>{weight_spike} Gauss(U, s={sigma_spike}) + {1-weight_spike} Gauss(U, s={sigma_tails})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = mh.DiscreteVariableNode(\"AR change factor shape\", 1, 1, 1, prior=None)\n",
    "\n",
    "cpth.save_cpt(\n",
    "    [AR, AR, S],\n",
    "    cpt,\n",
    "    f\"_shape_factor_Gmain{sigma_spike}_Gtails{sigma_tails}_w{weight_spike}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[(0.001, 0.1, 1), (0.005, 0.1, 1), (0.01, 0.1, 1), (0.05, 0.1, 1), (0.1, 0.1, 1), (0.5, 0.1, 1), (1, 0.1, 1), (1.5, 0.1, 1), (2, 0.1, 1)]\n"
     ]
    }
   ],
   "source": [
    "# mean = 1\n",
    "# sigma_spike = [1, 3, 5]\n",
    "# sigma_tails = [10, 30, 50]\n",
    "# weight_spike = [0.5, 0.7, 0.9]\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# mean = 1\n",
    "# sigma_spike = [1]\n",
    "# sigma_tails = [10]\n",
    "# weight_spike = [0.7, 0.73, 0.76, 0.79, 0.81, 0.84, 0.87, 0.9, 0.93, 0.96, 0.99]\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# mean = 1\n",
    "# sigma_spike = [0.2, 0.4, 1]\n",
    "# sigma_tails = [1, 4, 10]\n",
    "# weight_spike = [0.9, 0.95, 1]\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# _shape_factor_main_tail_card28\n",
    "# sigma_spike = [0.01, 0.03, 0.05, 0.1]\n",
    "# sigma_tails = [0.1, 0.2, 0.5, 0.8, 1.1, 1.4]\n",
    "# weight_spike = [0.7]\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# params = [\n",
    "#     (0.01, 0.1, 0.7),\n",
    "#     (0.01, 0.2, 0.7),\n",
    "#     (0.01, 0.5, 0.7),\n",
    "#     (0.01, 0.8, 0.7),\n",
    "#     (0.01, 1.1, 0.7),\n",
    "#     (0.01, 1.4, 0.7),\n",
    "#     (0.03, 0.1, 0.7),\n",
    "#     (0.03, 0.2, 0.7),\n",
    "#     (0.03, 0.5, 0.7),\n",
    "#     (0.03, 0.8, 0.7),\n",
    "#     (0.03, 1.1, 0.7),\n",
    "#     (0.03, 1.4, 0.7),\n",
    "#     (0.05, 0.1, 0.7),\n",
    "#     (0.05, 0.2, 0.7),\n",
    "#     (0.05, 0.5, 0.7),\n",
    "#     (0.05, 0.8, 0.7),\n",
    "#     (0.05, 1.1, 0.7),\n",
    "#     (0.05, 1.4, 0.7),\n",
    "#     (0.1, 0.2, 0.7),\n",
    "#     (0.1, 0.5, 0.7),\n",
    "#     (0.1, 0.8, 0.7),\n",
    "#     (0.1, 1.1, 0.7),\n",
    "#     (0.1, 1.4, 0.7),\n",
    "#     (0.15, 0.2, 0.7),\n",
    "#     (0.15, 0.5, 0.7),\n",
    "#     (0.15, 0.8, 0.7),\n",
    "#     (0.15, 1.1, 0.7),\n",
    "#     (0.15, 1.4, 0.7),\n",
    "# ]\n",
    "\n",
    "#\n",
    "# sigma_spike = [0.001, 0.003, 0.007, 0.01, 0.025]\n",
    "# sigma_tails = [0.01, 0.03, 0.07, 0.1, 0.15]\n",
    "# weight_spike = [0.7]\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "# params = [\n",
    "#     (0.001, 0.01, 0.7),\n",
    "#     (0.001, 0.03, 0.7),\n",
    "#     (0.001, 0.07, 0.7),\n",
    "#     (0.001, 0.1, 0.7),\n",
    "#     (0.001, 0.15, 0.7),\n",
    "#     (0.003, 0.01, 0.7),\n",
    "#     (0.003, 0.03, 0.7),\n",
    "#     (0.003, 0.07, 0.7),\n",
    "#     (0.003, 0.1, 0.7),\n",
    "#     (0.003, 0.15, 0.7),\n",
    "#     (0.007, 0.01, 0.7),\n",
    "#     (0.007, 0.03, 0.7),\n",
    "#     (0.007, 0.07, 0.7),\n",
    "#     (0.007, 0.1, 0.7),\n",
    "#     (0.007, 0.15, 0.7),\n",
    "#     (0.01, 0.03, 0.7),\n",
    "#     (0.01, 0.07, 0.7),\n",
    "#     (0.01, 0.1, 0.7),\n",
    "#     (0.01, 0.15, 0.7),\n",
    "#     (0.025, 0.03, 0.7),\n",
    "#     (0.025, 0.07, 0.7),\n",
    "#     (0.025, 0.1, 0.7),\n",
    "#     (0.025, 0.15, 0.7),\n",
    "# ]\n",
    "\n",
    "# Fit a signle laplace\n",
    "sigma_spike = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 1.5, 2]\n",
    "sigma_tails = [0.1]\n",
    "weight_spike = [1]\n",
    "laplace_main = True\n",
    "params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "print(len(params))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/v2r6yn111s3gpdf8lzf72xvw0000gn/T/ipykernel_40081/1187734051.py:32: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AR1 = mh.VariableNode(\"Airway resistance day 1 (%)\", 0, 90, 2, prior=None)\n",
    "AR2 = mh.VariableNode(\"Airway resistance day 2 (%)\", 0, 90, 2, prior=None)\n",
    "S = mh.DiscreteVariableNode(\"AR change factor shape\", 1, len(params), 1, prior=None)\n",
    "\n",
    "cpt = np.zeros((AR2.card, AR1.card, S.card))\n",
    "\n",
    "main_is_laplace = laplace_main\n",
    "for s, (sigma_spike, sigma_tails, weight_spike) in enumerate(params):\n",
    "\n",
    "    pdf = np.zeros(AR2.card)\n",
    "    for i, z in enumerate(AR2.get_bins_arr()):\n",
    "        y = AR1.get_bins_arr()[0]\n",
    "        pdf[i] = ar.p_uniform_x_gmm(\n",
    "            z[0],\n",
    "            z[1],\n",
    "            y[0],\n",
    "            y[1],\n",
    "            sigma_spike,\n",
    "            sigma_tails,\n",
    "            weight_spike,\n",
    "            main_is_laplace,\n",
    "        )\n",
    "\n",
    "    # Shift and associate to the next bin\n",
    "    for i in range(AR2.card):\n",
    "        for j in range(AR1.card):\n",
    "            if i >= j:\n",
    "                cpt[i, j, s] = pdf[i - j]\n",
    "            else:\n",
    "                cpt[i, j, s] = pdf[j - i]\n",
    "    # Then normalise\n",
    "    cpt /= cpt.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test middle, right\n",
    "i = 20\n",
    "y = AR1.get_bins_arr()[i]\n",
    "pdf = np.zeros(AR2.card)\n",
    "for j, z in enumerate(AR2.get_bins_arr()):\n",
    "    pdf[j] = ar.p_uniform_x_gmm(\n",
    "        z[0], z[1], y[0], y[1], sigma_spike, sigma_tails, weight_spike, laplace_main\n",
    "    )\n",
    "pdf = pdf / np.sum(pdf)\n",
    "assert np.allclose(pdf, cpt[:, i, 0]), f\"pdf={pdf}\\ncpt={cpt[:, i, 0]}\"\n",
    "\n",
    "i = -1\n",
    "y = AR1.get_bins_arr()[i]\n",
    "pdf = np.zeros(AR2.card)\n",
    "for j, z in enumerate(AR2.get_bins_arr()):\n",
    "    pdf[j] = ar.p_uniform_x_gmm(\n",
    "        z[0], z[1], y[0], y[1], sigma_spike, sigma_tails, weight_spike, laplace_main\n",
    "    )\n",
    "pdf = pdf / np.sum(pdf)\n",
    "assert np.allclose(pdf, cpt[:, i, 0]), f\"pdf={pdf}\\ncpt={cpt[:, i, 0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth.save_cpt([AR, AR, S], cpt, f\"_shape_factor_main_tail_card{len(params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 20\n",
    "z = AR1.get_bins_arr()[j]\n",
    "\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(\n",
    "#     go.Histogram(\n",
    "#         x=AR2_samples,\n",
    "#         histnorm=\"probability\",\n",
    "#         xbins=dict(size=AR2.bin_width, start=AR2.a, end=AR2.b),\n",
    "#     )\n",
    "# )\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=AR2.midbins,\n",
    "        y=cpt[:, j, 2],\n",
    "        # mode=\"markers+lines\",\n",
    "        # marker=dict(size=5, color=\"black\"),\n",
    "        # line=dict(width=1.5, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"Numerical computation of U({z[0]}, {z[1]}) x <br>{weight_spike} Gauss(U, s={sigma_spike}) + {1-weight_spike} Gauss(U, s={sigma_tails})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t, norm\n",
    "\n",
    "mean = 0.5\n",
    "sigma_spike = 0.5\n",
    "sigma_tails = 5  # 20,\n",
    "weight_spike = 0.7  # Between 0.7 and 0.3\n",
    "\n",
    "\n",
    "def get_pdf(\n",
    "    x,\n",
    "    mean,\n",
    "    sigma_spike,\n",
    "    sigma_tails,\n",
    "    weight_spike,\n",
    "    laplace_main=False,\n",
    "    laplace_tails=False,\n",
    "):\n",
    "    if laplace_main:\n",
    "        pdf_spike = ar.pdf_laplace(x, mean, sigma_spike)\n",
    "    else:\n",
    "        pdf_spike = norm.pdf(x, mean, sigma_spike)\n",
    "    if laplace_tails:\n",
    "        pdf_tails = ar.pdf_laplace(x, mean, sigma_tails)\n",
    "    else:\n",
    "        pdf_tails = norm.pdf(x, mean, sigma_tails)\n",
    "    pdf = weight_spike * pdf_spike + (1 - weight_spike) * pdf_tails\n",
    "\n",
    "    pdf /= np.sum(pdf)\n",
    "    return pdf\n",
    "\n",
    "\n",
    "pdf = get_pdf(AR.midbins, mean, sigma_spike, sigma_tails, weight_spike, True, True)\n",
    "\n",
    "# Same plot with plotly xpress\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=AR.midbins, y=pdf, mode=\"markers+lines\"))\n",
    "# fig.update_yaxes(range=[-0.01, max(pdf) + 0.01])\n",
    "# log x axis\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"I can run {np.power(24,1/3)} experiments in 8h for the 3 days case scenario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CPT\n",
    "\n",
    "# Longest taking 1300s = 20 min\n",
    "\n",
    "# 1: gris serach on 3 params\n",
    "mean = 1\n",
    "sigma_spike = [1, 3, 5]\n",
    "sigma_tails = [10, 30, 50]\n",
    "weight_spike = [0.5, 0.7, 0.9]\n",
    "laplace_main = False\n",
    "laplace_tail = False\n",
    "params = list(itertools.product(sigma_spike, sigma_tails, weight_spike))\n",
    "print(len(params))\n",
    "print(params)\n",
    "\n",
    "# 2: focus on the main std\n",
    "# mean = 1\n",
    "# sigma_spike = [0.5, 1, 1.5, 2, 2.5]\n",
    "# weight_spike = 0.7\n",
    "# sigma_tails = 30\n",
    "# laplace = [False, True]\n",
    "\n",
    "# params = list(itertools.product(sigma_spike, laplace))\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# 3: focus on the tails std\n",
    "# mean = 1\n",
    "# sigma_spike = 0.5\n",
    "# weight_spike = 0.7\n",
    "# sigma_tails = [5, 15, 30]\n",
    "# laplace_main = True\n",
    "# laplace_tail = True\n",
    "\n",
    "# params = sigma_tails\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# 4: using best matching set from 1, finely optimise the weight\n",
    "# Vary the weight\n",
    "# mean = 1\n",
    "# sigma_spike = 0.2\n",
    "# weight_spike = [0.59, 0.61, 0.64, 0.67, 0.7, 0.73, 0.76, 0.79, 0.81, 0.84, 0.87, 0.9, 0.93, 0.96, 0.99]\n",
    "# sigma_tail = 30\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = weight_spike\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# 5: using best matchin weight, finely optimise the spike std\n",
    "# mean = 1\n",
    "# sigma_spike = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# weight_spike = 0.73\n",
    "# sigma_tail = 30\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = sigma_spike\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "# 6: using best matchin weight and spike std, finely optimise the tail std\n",
    "# mean = 0.5\n",
    "# # mean = 1\n",
    "# sigma_spike = 0.2\n",
    "# weight_spike = 0.73\n",
    "# sigma_tail = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "# laplace_main = False\n",
    "# laplace_tail = False\n",
    "# params = sigma_tail\n",
    "# print(len(params))\n",
    "# print(params)\n",
    "\n",
    "cpt = np.zeros((AR2.card, AR1.card, len(params)))\n",
    "\n",
    "for s in range(len(params)):\n",
    "    sigma_tail = params[s]\n",
    "    # sigma_spike, sigma_tails, weight_spike = params[s]\n",
    "    pdf = get_pdf(\n",
    "        AR.midbins,\n",
    "        mean,\n",
    "        sigma_spike,\n",
    "        sigma_tail,\n",
    "        weight_spike,\n",
    "        laplace_main,\n",
    "        laplace_tail,\n",
    "    )\n",
    "\n",
    "    for i in range(AR1.card):\n",
    "        for j in range(AR2.card):\n",
    "            if j >= i:\n",
    "                cpt[j, i, s] = pdf[j - i]\n",
    "            else:\n",
    "                cpt[j, i, s] = pdf[i - j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR = mh.VariableNode(\"Airway resistance (%)\", 0, 90, 2, prior=None)\n",
    "AR1 = mh.VariableNode(\"Airway resistance day 1 (%)\", 0, 90, 2, prior=None)\n",
    "AR2 = mh.VariableNode(\"Airway resistance day 2 (%)\", 0, 90, 2, prior=None)\n",
    "S = mh.DiscreteVariableNode(\"AR change factor shape\", 1, len(params), 1)\n",
    "\n",
    "# cpth.save_cpt([AR, AR, S], cpt, f\"_shape_factor{S.card}_stdtail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Gaussian CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finale Gaussian CPT\n",
    "\n",
    "# mean = 1\n",
    "mean = 0.5\n",
    "sigma_spike = 0.2\n",
    "weight_spike = 0.73\n",
    "sigma_tail = 10\n",
    "laplace_main = False\n",
    "laplace_tail = False\n",
    "\n",
    "S = mh.DiscreteVariableNode(\"AR change factor shape\", 1, 1, 1, prior=None)\n",
    "\n",
    "cpt = np.zeros((AR2.card, AR1.card, S.card))\n",
    "\n",
    "pdf = get_pdf(\n",
    "    AR.midbins,\n",
    "    mean,\n",
    "    sigma_spike,\n",
    "    sigma_tail,\n",
    "    weight_spike,\n",
    "    laplace_main,\n",
    "    laplace_tail,\n",
    ")\n",
    "\n",
    "for i in range(AR1.card):\n",
    "    for j in range(AR2.card):\n",
    "        if j >= i:\n",
    "            cpt[j, i, 0] = pdf[j - i]\n",
    "        else:\n",
    "            cpt[j, i, 0] = pdf[i - j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get previous ctp that gave good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = mh.DiscreteVariableNode(\"AR change factor shape\", 2, 10, 2, prior=None)\n",
    "\n",
    "cpt_old = cpth.get_cpt([AR, AR, S], f\"_shape_factor_what_is_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = 22\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=AR.midbins, y=cpt[:, bin, 0], mode=\"markers+lines\"))\n",
    "fig.add_trace(go.Bar(x=AR.midbins, y=cpt_old[:, bin, 0]))\n",
    "# fig.update_yaxes(range=[-0.01, max(pdf) + 0.01])\n",
    "# Add AR.name on x axis\n",
    "fig.update_xaxes(title=AR.name)\n",
    "title = f\"P(AR2 |AR1 = {AR.get_bins_str()[bin]})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ecFEV1 change in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data.helpers as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bd.load_meas_from_excel(\"BR_O2_FEV1_FEF2575_conservative_smoothing_with_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dump = np.array([])\n",
    "\n",
    "for id in df.ID.unique():\n",
    "    dftmp, _, _ = dh.find_longest_consec_series(df[df.ID == id], n_days=3)\n",
    "    dftmp[\"ecFEV1 shifted\"] = dftmp[\"ecFEV1\"].shift(1)\n",
    "    dftmp[\"ecFEV1 diff\"] = dftmp[\"ecFEV1 shifted\"] - dftmp[\"ecFEV1\"]\n",
    "    diff = dftmp[\"ecFEV1 diff\"].dropna().values\n",
    "    diff_dump = np.concatenate((diff_dump, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot of diff_dump using go figure\n",
    "fig = go.Figure()\n",
    "# Add histogram plot with 50 bins\n",
    "xbins = dict(start=-2.05, end=2, size=0.1)\n",
    "fig.add_trace(go.Histogram(x=diff_dump, xbins=xbins))\n",
    "# Add title and x axis label\n",
    "fig.update_layout(\n",
    "    title=\"Histogram of ecFEV1 diff\", xaxis_title=\"ecFEV1 diff\", width=700, height=400\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate CPT\n",
    "fig = go.Figure()\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=AR2.midbins,\n",
    "        y=cpt[:, 0, 0],\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=5, color=\"black\"),\n",
    "        line=dict(width=1.5, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform + laplace dist convolution validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "\n",
    "\n",
    "def pdf_laplace(x, mu, s):\n",
    "    return 1 / (2 * s) * np.exp(-np.abs(x - mu) / s)\n",
    "\n",
    "\n",
    "def sampler_uniform_x_laplace(n, a, b, s):\n",
    "    \"\"\"\n",
    "    Y ~ U(a, b)\n",
    "    Z ~ Laplace(mu=Y, s=s)\n",
    "    \"\"\"\n",
    "    y_samples = np.random.uniform(a, b, n)\n",
    "    z_samples = np.random.laplace(y_samples, s)\n",
    "    return y_samples, z_samples\n",
    "\n",
    "\n",
    "n = 1000000\n",
    "ar_down, ar_up = AR1.get_bins_arr()[20]\n",
    "shape = 5\n",
    "AR1_samples, AR2_samples = sampler_uniform_x_laplace(n, ar_down, ar_up, shape)\n",
    "# Remove samples outside AR2 range\n",
    "AR2_samples = AR2_samples[(AR2_samples >= AR2.a) & (AR2_samples <= AR2.b)]\n",
    "\n",
    "# Create plot histogram plot for AR2 samples using go figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=AR2_samples,\n",
    "        histnorm=\"probability\",\n",
    "        xbins=dict(size=AR2.bin_width, start=AR2.a, end=AR2.b),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def pdf_uniform_x_laplace(z1, y1, y2, s, abserr_tol=1e-10):\n",
    "    \"\"\"\n",
    "    Y ~ U(y1, y2)\n",
    "    Z ~ Laplace(mu=Y, s=s)\n",
    "    Returns P(z=z1| y1 < y < y2)\n",
    "    \"\"\"\n",
    "\n",
    "    def conv_fn(y, z, s):\n",
    "        return pdf_laplace(z, y, s) / (y2 - y1) / y\n",
    "\n",
    "    val, abserr = integrate.quad(conv_fn, y1, y2, args=(z1, s))\n",
    "    if abserr > abserr_tol:\n",
    "        raise ValueError(\n",
    "            f\"Absolute error after solving the integral is too high {abserr}\"\n",
    "        )\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "p_ar2 = np.array([pdf_uniform_x_laplace(z, ar_down, ar_up, shape) for z in AR2.midbins])\n",
    "p_ar2 = np.array(p_ar2) / np.sum(p_ar2)\n",
    "\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=AR2.midbins,\n",
    "        y=p_ar2,\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=5, color=\"black\"),\n",
    "        line=dict(width=1.5, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"Validation of numerical computation of U({ar_down}, {ar_up}) x Laplace(U, s={shape})<br>against sampling (n={n})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get P(z1 < z < z2 | y1 < y < y2)\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "\n",
    "def pdf_laplace(x, mu, s):\n",
    "    return 1 / (2 * s) * np.exp(-np.abs(x - mu) / s)\n",
    "\n",
    "\n",
    "def sampler_uniform_x_laplace(n, a, b, s):\n",
    "    \"\"\"\n",
    "    Y ~ U(a, b)\n",
    "    Z ~ Laplace(mu=Y, s=s)\n",
    "    \"\"\"\n",
    "    y_samples = np.random.uniform(a, b, n)\n",
    "    z_samples = np.random.laplace(y_samples, s)\n",
    "    return y_samples, z_samples\n",
    "\n",
    "\n",
    "n = 1000000\n",
    "ar_down, ar_up = AR1.get_bins_arr()[22]\n",
    "shape = 5\n",
    "AR1_samples, AR2_samples = sampler_uniform_x_laplace(n, ar_down, ar_up, shape)\n",
    "# Remove samples outside AR2 range\n",
    "AR2_samples = AR2_samples[(AR2_samples >= AR2.a) & (AR2_samples <= AR2.b)]\n",
    "\n",
    "\n",
    "def p_uniform_x_laplace(z1, z2, y1, y2, s, abserr_tol=1e-10, debug=True):\n",
    "    \"\"\"\n",
    "    Y ~ U(y1, y2)\n",
    "    Z ~ Laplace(mu=Y, s=s)\n",
    "    Returns P(z1 < z < z2 | y1 < y < y2)\n",
    "    \"\"\"\n",
    "\n",
    "    def conv_fn(z, y, s):\n",
    "        return pdf_laplace(z, y, s) / (y2 - y1) / y\n",
    "\n",
    "    val, abserr = integrate.dblquad(\n",
    "        conv_fn, y1, y2, z1, z2, args=[s], epsabs=abserr_tol\n",
    "    )\n",
    "    if abserr > abserr_tol and debug:\n",
    "        print(\n",
    "            f\"Warning - Absolute error after solving the integral is too high {abserr}, z1 = {z1}, z2 = {z2}, y1 = {y1}, y2 = {y2}\"\n",
    "        )\n",
    "\n",
    "    return val\n",
    "\n",
    "\n",
    "p_ar2 = np.array(\n",
    "    [\n",
    "        p_uniform_x_laplace(z1, z2, ar_down, ar_up, shape)\n",
    "        for z1, z2 in AR2.get_bins_arr()\n",
    "    ]\n",
    ")\n",
    "p_ar2 = np.array(p_ar2) / np.sum(p_ar2)\n",
    "\n",
    "\n",
    "# Create plot histogram plot for AR2 samples using go figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=AR2_samples,\n",
    "        histnorm=\"probability\",\n",
    "        xbins=dict(size=AR2.bin_width, start=AR2.a, end=AR2.b),\n",
    "    )\n",
    ")\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=AR2.midbins,\n",
    "        y=p_ar2,\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=5, color=\"black\"),\n",
    "        line=dict(width=1.5, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"Validation of numerical computation of U({ar_down}, {ar_up}) x Laplace(U, s={shape})<br>against sampling (n={n})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CPT\n",
    "\n",
    "cpt = np.zeros((AR2.card, AR2.card, S.card))\n",
    "\n",
    "\n",
    "def distribute_pdf_along_child_var(var, pdf, pdf_peek_idx):\n",
    "    \"\"\"\n",
    "    Use when the child and the parent vars have the same parameters\n",
    "    pdf is a distribution of the noise for a bin of the parent's var\n",
    "    The noise is always the same\n",
    "    This function will shift the pdf along the child's bins to create a CPT\n",
    "\n",
    "    Typically pdf_peek_idx = var.card // 2\n",
    "    \"\"\"\n",
    "    cpt = np.zeros((var.card, var.card))\n",
    "\n",
    "    for bin_idx, bin in enumerate(var.get_bins_arr()):\n",
    "        pdf_trunc = np.zeros(var.card)\n",
    "        peek_diff = pdf_peek_idx - bin_idx\n",
    "        if peek_diff == 0:\n",
    "            pdf_trunc = pdf\n",
    "        elif peek_diff > 0:\n",
    "            pdf_trunc[0:-peek_diff] = pdf[peek_diff:]\n",
    "        else:\n",
    "            pdf_trunc[-peek_diff:] = pdf[:peek_diff]\n",
    "        # Norm the pdf\n",
    "        pdf_trunc /= np.sum(pdf_trunc)\n",
    "        cpt[:, bin_idx] = pdf_trunc\n",
    "    return cpt\n",
    "\n",
    "\n",
    "for s_idx, s in enumerate(S.values):\n",
    "    # Compute p_ar2 for the middle bin of AR1\n",
    "    middle_bin = AR1.card // 2\n",
    "    ar_down, ar_up = AR1.get_bins_arr()[middle_bin]\n",
    "    # Compute p_ar2, for a variable 3 times wider than AR2\n",
    "    # AR_mock = mh.VariableNode(\"Mock var\", -90, 180, 2, prior=None)\n",
    "    p_ar2 = np.array(\n",
    "        [\n",
    "            p_uniform_x_laplace(z1, z2, ar_down, ar_up, s)\n",
    "            for z1, z2 in AR2.get_bins_arr()\n",
    "        ]\n",
    "    )\n",
    "    p_ar2 = np.array(p_ar2) / np.sum(p_ar2)\n",
    "    cpt[:, :, s_idx] = distribute_pdf_along_child_var(AR2, p_ar2, middle_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: when sliding the pdf to the left, values on the right are wrong, and vice versa\n",
    "\n",
    "Since at max you slide by 45 units, need to add 45 ot the left and to the right: -45; 90\n",
    "\n",
    "Since the distribution is symmetric, you can just do 0, 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot histogram plot for AR2 samples using go figure\n",
    "fig = go.Figure()\n",
    "# Add scatter plot with markers on ar2_dist\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=AR2.midbins,\n",
    "        y=cpt[:, 10, 4],\n",
    "        mode=\"markers+lines\",\n",
    "        marker=dict(size=5, color=\"black\"),\n",
    "        line=dict(width=1.5, color=\"black\"),\n",
    "    )\n",
    ")\n",
    "fig.update_xaxes(title=\"Airway resistance day 2 (%)\")\n",
    "title = f\"Validation of numerical computation of U({ar_down}, {ar_up}) x Laplace(U, s={shape})<br>against sampling (n={n})\"\n",
    "fig.update_layout(title=title, showlegend=False, width=700, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpth.save_cpt([AR, AR, S], cpt, \"_shape_factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
