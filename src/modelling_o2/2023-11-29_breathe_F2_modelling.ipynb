{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "from pgmpy.models import BayesianNetwork\n",
    "\n",
    "import src.modelling_o2.o2satffa as o2satffa\n",
    "import src.models.helpers as mh\n",
    "import src.models.builders as mb\n",
    "import src.inference.helpers as ih\n",
    "\n",
    "\n",
    "plotsdir = \"../../../../PlotsBreathe/O2_modelling/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{plotsdir}airwayresistance_o2satffa_df.xlsx\", index_col=0)\n",
    "df.ID = df.ID.astype(str)\n",
    "# To excel\n",
    "# df.to_excel(f\"{plotsdir}airwayresistance_o2satffa_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer O2SatFFA after observing FEV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_up_to_O2SatFFA(hfev1_prior, ho2sat_prior):\n",
    "    \"\"\"\n",
    "    This is a point in time model with\n",
    "    FEV1 = HFEV1 * (1-AR)\n",
    "    O2SatFFA = HO2Sat * drop_func(AR)\n",
    "\n",
    "    The model is the same as build_HFEV1_AB_FEV1(), with Airway Blockage renamed to Airway Resistance.\n",
    "    \"\"\"\n",
    "    print(\"*** Building FEV1 and O2 point in time model ***\")\n",
    "\n",
    "    # Setting resolution of 0.05 to avoud rounding errors for AR\n",
    "    HFEV1 = mh.variableNode(\"Healthy FEV1 (L)\", 1, 6, 0.05, prior=hfev1_prior)\n",
    "    AR = mh.variableNode(\"Airway Resistance (%)\", 0, 90, 1, prior={\"type\": \"uniform\"})\n",
    "    ecFEV1 = mh.variableNode(\"FEV1 (L)\", 0, 6, 0.05, prior=None)\n",
    "    # Lowest predicted FEV1 is 15% (AR = 1-predictedFEV1)\n",
    "    HO2Sat = mh.variableNode(\n",
    "        \"Healthy O2 Saturation (%)\", 90, 100, 0.5, prior=ho2sat_prior\n",
    "    )\n",
    "    # Highest drop is 93% (for AR = 90%), hence the lowest O2SatFFA is 90 * 0.93 = 83.7%\n",
    "    O2SatFFA = mh.variableNode(\n",
    "        \"O2 Sat if fully functional alveoli (%)\", 80, 100, 0.5, prior=None\n",
    "    )\n",
    "\n",
    "    prior_hfev1 = TabularCPD(\n",
    "        variable=HFEV1.name,\n",
    "        variable_card=len(HFEV1.bins),\n",
    "        values=HFEV1.prior,\n",
    "        evidence=[],\n",
    "        evidence_card=[],\n",
    "    )\n",
    "    prior_ho2sat = TabularCPD(\n",
    "        variable=HO2Sat.name,\n",
    "        variable_card=len(HO2Sat.bins),\n",
    "        values=HO2Sat.prior,\n",
    "        evidence=[],\n",
    "        evidence_card=[],\n",
    "    )\n",
    "    prior_ar = TabularCPD(\n",
    "        variable=AR.name,\n",
    "        variable_card=len(AR.bins),\n",
    "        values=AR.prior,\n",
    "        evidence=[],\n",
    "        evidence_card=[],\n",
    "    )\n",
    "    cpt_fev1 = TabularCPD(\n",
    "        variable=ecFEV1.name,\n",
    "        variable_card=len(ecFEV1.bins),\n",
    "        values=mh.calc_pgmpy_cpt_X_x_1_minus_Y(HFEV1, AR, ecFEV1),\n",
    "        evidence=[HFEV1.name, AR.name],\n",
    "        evidence_card=[len(HFEV1.bins), len(AR.bins)],\n",
    "    )\n",
    "    cpt_o2_sat_ffa = TabularCPD(\n",
    "        variable=O2SatFFA.name,\n",
    "        variable_card=len(O2SatFFA.bins),\n",
    "        values=o2satffa.calc_cpt(O2SatFFA, HO2Sat, AR, debug=False),\n",
    "        evidence=[HO2Sat.name, AR.name],\n",
    "        evidence_card=[len(HO2Sat.bins), len(AR.bins)],\n",
    "    )\n",
    "\n",
    "    model = BayesianNetwork(\n",
    "        [\n",
    "            (HFEV1.name, ecFEV1.name),\n",
    "            (AR.name, ecFEV1.name),\n",
    "            (HO2Sat.name, O2SatFFA.name),\n",
    "            (AR.name, O2SatFFA.name),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.add_cpds(cpt_fev1, prior_ar, prior_hfev1, prior_ho2sat, cpt_o2_sat_ffa)\n",
    "\n",
    "    model.check_model()\n",
    "    inf_alg = BeliefPropagation(model)\n",
    "    return (model, inf_alg, HFEV1, ecFEV1, AR, HO2Sat, O2SatFFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer airway resistance using the model\n",
    "for id in df.ID.unique():\n",
    "    # for id in [\"101\"]:\n",
    "    df_for_ID = df[df.ID == id].copy().reset_index()\n",
    "    print(f\"\\nRunning for ID {id}, with {len(df_for_ID)} observations\")\n",
    "    # Take one element of the df for ID at column height\n",
    "    height = df_for_ID.Height[0]\n",
    "    sex = df_for_ID.Sex[0]\n",
    "    hfev1_prior = {\n",
    "        \"type\": \"default\",\n",
    "        \"height\": height,\n",
    "        \"age\": df_for_ID.Age[0],\n",
    "        \"sex\": sex,\n",
    "    }\n",
    "    ho2sat_prior = {\n",
    "        \"type\": \"default\",\n",
    "        \"height\": height,\n",
    "        \"sex\": sex,\n",
    "    }\n",
    "    tic = time.time()\n",
    "    (\n",
    "        model,\n",
    "        inf_alg,\n",
    "        HFEV1,\n",
    "        ecFEV1,\n",
    "        AR,\n",
    "        HO2Sat,\n",
    "        O2SatFFA,\n",
    "    ) = model_up_to_O2SatFFA(hfev1_prior, ho2sat_prior)\n",
    "    print(f\"model took {time.time() - tic} seconds to build\")\n",
    "\n",
    "    tic = time.time()\n",
    "    df_for_ID[\"AR from FEV1\"] = np.nan\n",
    "    df_for_ID[\"AR from ecFEV1\"] = np.nan\n",
    "    df_for_ID[\"O2SatFFA from FEV1\"] = np.nan\n",
    "    df_for_ID[\"O2SatFFA from ecFEV1\"] = np.nan\n",
    "    fev1s_tmp = []\n",
    "    ecfev1s_tmp = []\n",
    "    for i in range(len(df_for_ID)):\n",
    "        fev1_obs = df_for_ID.loc[i, \"FEV1\"]\n",
    "        ecfev1_obs = df_for_ID.loc[i, \"ecFEV1\"]\n",
    "\n",
    "        # FEV1\n",
    "        if fev1_obs in fev1s_tmp:\n",
    "            df_for_ID.loc[i, \"AR from FEV1\"] = df_for_ID.loc[\n",
    "                df_for_ID[\"FEV1\"] == fev1_obs, \"AR from FEV1\"\n",
    "            ].values[0]\n",
    "            df_for_ID.loc[i, \"O2SatFFA from FEV1\"] = df_for_ID.loc[\n",
    "                df_for_ID[\"FEV1\"] == fev1_obs, \"O2SatFFA from FEV1\"\n",
    "            ].values[0]\n",
    "        else:\n",
    "            res_ar_for_fev1 = ih.infer(\n",
    "                inf_alg, [AR], [[ecFEV1, fev1_obs]], show_progress=False\n",
    "            )\n",
    "            df_for_ID.loc[i, \"AR from FEV1\"] = AR.get_mean(res_ar_for_fev1.values)\n",
    "\n",
    "            res_o2satffa_for_fev1 = ih.infer(\n",
    "                inf_alg, [O2SatFFA], [[ecFEV1, fev1_obs]], show_progress=False\n",
    "            )\n",
    "            df_for_ID.loc[i, \"O2SatFFA from FEV1\"] = O2SatFFA.get_mean(\n",
    "                res_o2satffa_for_fev1.values\n",
    "            )\n",
    "\n",
    "        # ecFEV1\n",
    "        if ecfev1_obs in ecfev1s_tmp:\n",
    "            df_for_ID.loc[i, \"AR from ecFEV1\"] = df_for_ID.loc[\n",
    "                df_for_ID[\"ecFEV1\"] == ecfev1_obs, \"AR from ecFEV1\"\n",
    "            ].values[0]\n",
    "\n",
    "            df_for_ID.loc[i, \"O2SatFFA from ecFEV1\"] = df_for_ID.loc[\n",
    "                df_for_ID[\"ecFEV1\"] == ecfev1_obs, \"O2SatFFA from ecFEV1\"\n",
    "            ].values[0]\n",
    "        else:\n",
    "            res_ar_for_ecfev1 = ih.infer(\n",
    "                inf_alg, [AR], [[ecFEV1, ecfev1_obs]], show_progress=False\n",
    "            )\n",
    "            df_for_ID.loc[i, \"AR from ecFEV1\"] = AR.get_mean(res_ar_for_ecfev1.values)\n",
    "\n",
    "            res_o2satffa_for_ecfev1 = ih.infer(\n",
    "                inf_alg, [O2SatFFA], [[ecFEV1, ecfev1_obs]], show_progress=False\n",
    "            )\n",
    "            df_for_ID.loc[i, \"O2SatFFA from ecFEV1\"] = O2SatFFA.get_mean(\n",
    "                res_o2satffa_for_ecfev1.values\n",
    "            )\n",
    "\n",
    "        fev1s_tmp = np.append(fev1s_tmp, fev1_obs)\n",
    "        ecfev1s_tmp = np.append(ecfev1s_tmp, ecfev1_obs)\n",
    "    print(f\"inference took {time.time() - tic} seconds to run\")\n",
    "\n",
    "    # Add to df\n",
    "    df.loc[df.ID == id, \"AR from ecFEV1 (%)\"] = df_for_ID[\"AR from ecFEV1\"].values\n",
    "    df.loc[df.ID == id, \"AR from FEV1 (%)\"] = df_for_ID[\"AR from FEV1\"].values\n",
    "\n",
    "    df.loc[df.ID == id, \"O2SatFFA from ecFEV1 (%)\"] = df_for_ID[\n",
    "        \"O2SatFFA from ecFEV1\"\n",
    "    ].values\n",
    "    df.loc[df.ID == id, \"O2SatFFA from FEV1 (%)\"] = df_for_ID[\n",
    "        \"O2SatFFA from FEV1\"\n",
    "    ].values\n",
    "\n",
    "# IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
    "# Happens when the results becomes too close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ID 101, 0.05 resolution takes 50s + 12s to run\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add title: inferred O2SatFFA from ecFEV1 vs. AR\n",
    "title = \"Inferred O2SatFFA vs. AR\"\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"AR from ecFEV1 (%)\",\n",
    "    y=\"O2SatFFA from ecFEV1 (%)\",\n",
    "    title=title,\n",
    "    hover_data=[\"ID\", \"ecFEV1\"],\n",
    ")\n",
    "# Reduce marker size\n",
    "fig.update_traces(marker=dict(size=2))\n",
    "fig.update_layout(font=dict(size=10), title=title)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"O2SatFFA from ecFEV1 (%)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"O2Sat % O2SatFFA\"] = df[\"O2 Saturation\"] / df[\"O2SatFFA from ecFEV1 (%)\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = (\n",
    "    f\"O2Sat % Inferred O2SatFFA vs. AR ({df.ID.nunique()} IDs, {len(df)} datapoints)\"\n",
    ")\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"AR from ecFEV1 (%)\",\n",
    "    y=\"O2Sat % O2SatFFA\",\n",
    "    title=title,\n",
    "    hover_data=[\"ID\", \"ecFEV1\"],\n",
    ")\n",
    "# Reduce marker size\n",
    "fig.update_traces(marker=dict(size=2), opacity=0.3)\n",
    "fig.update_layout(font=dict(size=10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.o2_fev1_analysis.partition as partition\n",
    "\n",
    "O2_col = \"O2Sat % O2SatFFA\"\n",
    "# O2_col = \"O2SatFFA from ecFEV1 (%)\"\n",
    "\n",
    "# # Create 3 equally spaced bins for Airway Resistance\n",
    "# df[\"AR group\"] = partition.partition_in_n_equal_groups(\n",
    "#     df[\"Airway Resistance mean from ecFEV1 (%)\"], 5\n",
    "# )\n",
    "\n",
    "# Cut Airway Resistance into bins of 0-20, 20-40, 40-60, 60-80\n",
    "df[\"AR group\"] = pd.cut(\n",
    "    df[\"AR from ecFEV1 (%)\"],\n",
    "    bins=np.arange(0, 100, 20),\n",
    "    include_lowest=False,\n",
    ")\n",
    "\n",
    "group_labels = df[\"AR group\"].unique()\n",
    "print(f\"AR groups: {group_labels}\")\n",
    "\n",
    "# Create subplot with 3 rows\n",
    "fig = make_subplots(\n",
    "    rows=len(group_labels) - 1, cols=1, shared_xaxes=True, vertical_spacing=0.02\n",
    ")\n",
    "# On first subplot add histogram of Drop from O2 Saturation FFA (%) for 1st AR group\n",
    "for i in range(len(group_labels) - 1):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df[df[\"AR group\"] == group_labels[i]][O2_col],\n",
    "            name=f\"Airway Resistance {group_labels[i]}\",\n",
    "            # Bin size of 1\n",
    "            xbins=dict(start=75, end=110, size=0.2),\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "\n",
    "title = f\"Distribution of {O2_col} for different Airway Resistance groups\"\n",
    "fig.update_layout(\n",
    "    title=title,\n",
    "    font=dict(size=10),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title_text=\"O2 Saturation in % of O2 Saturation if Fully Functional Alveoli\",\n",
    "    row=len(group_labels) - 1,\n",
    "    col=1,\n",
    ")\n",
    "# Save\n",
    "fig.write_image(f\"{plotsdir}{title}.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove measurement noise and ho2sat model spread to get F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the overall distribution of O2SatFFA with airway resistance\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "O2_col = \"O2Sat % O2SatFFA\"\n",
    "\n",
    "\n",
    "def o2sat_prct_o2satffa_displot(array):\n",
    "    fig = ff.create_distplot(\n",
    "        [array],\n",
    "        [\"O2Sat % O2SatFFA\"],\n",
    "        bin_size=0.2,\n",
    "        show_rug=False,\n",
    "        show_curve=True,\n",
    "        histnorm=\"probability density\",\n",
    "        colors=[\"#636EFA\"],\n",
    "    )\n",
    "\n",
    "    fig.update_layout(font=dict(size=10))\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"O2 Saturation in % of O2 Saturation if Fully Functional Alveoli\"\n",
    "    )\n",
    "    fig.show()\n",
    "    return -1\n",
    "\n",
    "\n",
    "o2sat_prct_o2satffa_displot(df[O2_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a gaussian distribution\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def fit_gaussian(array, bin_width=0.2):\n",
    "    # Print data median\n",
    "    mu, std = stats.norm.fit(array)\n",
    "    print(f\"Unconstrained gaussian fit - mu: {mu}, std: {std}\")\n",
    "    # Redo a fit with a fixed mu\n",
    "    mu = np.median(array)\n",
    "    std = stats.norm.fit(array, floc=mu)[1]\n",
    "    print(f\"Gaussian fit with mu = median - mu: {mu}, std: {std}\")\n",
    "    # Redo a fit using the same mu, but taking the std as the std of the right hand side from the median\n",
    "    mu = np.median(array)\n",
    "    right_hand_side = array[array > mu]\n",
    "    std = np.sqrt(np.sum((right_hand_side - mu) ** 2) / len(array))\n",
    "    print(\n",
    "        f\"Gaussian fit centered on median, defining std to the right hand side deviation from median - mu: {mu}, std: {std}\"\n",
    "    )\n",
    "\n",
    "    # Then plot the pdf on top of the histogram\n",
    "    # Create x vector from 75 to 110 with bin_width\n",
    "    x = np.arange(75, 110, bin_width)\n",
    "    pdf = stats.norm.pdf(x, mu, std)\n",
    "    # Normalise pdf\n",
    "    # pdf = pdf / np.sum(pdf)\n",
    "    # print(sum(pdf))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=array,\n",
    "            name=f\"O2Sat % O2SatFFA\",\n",
    "            xbins=dict(start=75, end=110, size=bin_width),\n",
    "            histnorm=\"probability density\",\n",
    "        )\n",
    "    )\n",
    "    # Add gaussian fit\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=pdf,\n",
    "            mode=\"lines\",\n",
    "            name=\"Gaussian fit\",\n",
    "            line=dict(color=\"black\", width=1),\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=f\"Distribution of O2Sat % O2SatFFA for different airway resistance groups\",\n",
    "        font=dict(size=10),\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"O2 Saturation in % of O2 Saturation if Fully Functional Alveoli\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "fit_gaussian(df[O2_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the O2 saturation with gaussian noise to smooth the histogram.\n",
    "\n",
    "That means for each O2Sat value, get the denoised distribution, sample 100 O2Sat values from this distribution.\n",
    "Thus each O2Sat value has equal weight in this new denoised dataset.\n",
    "\n",
    "Then replot the histogram and redo the gaussian fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.modelling_o2.o2sat as o2sat\n",
    "\n",
    "\n",
    "def smart_sample(bins, p):\n",
    "    \"\"\"\n",
    "    Smartly sampling so as to respect the probability distribution\n",
    "    \"\"\"\n",
    "    n_vals_per_bin_arr = p * 100\n",
    "    n_vals_per_bin_arr = np.round(n_vals_per_bin_arr)\n",
    "    n_vals_per_bin_arr = n_vals_per_bin_arr.astype(int)\n",
    "\n",
    "    # Create an array with n times the values of the bin\n",
    "    bin_vals = np.repeat(bins, n_vals_per_bin_arr)\n",
    "    return bin_vals\n",
    "\n",
    "\n",
    "def get_unbiased_o2sat_set_from_value(o2sat_obs, bin_width=0.1, n_samples=100000):\n",
    "    O2Sat = o2sat.emulate_gaussian_distribution(o2sat_obs, bin_width=bin_width)\n",
    "    # sample = O2Sat.sample(n_samples)\n",
    "    sample = smart_sample(O2Sat.bins, O2Sat.prior[:, 0])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many points should you sample to have a good representation of the distribution? -> 100000\n",
    "bin_width = 0.2\n",
    "sample = get_unbiased_o2sat_set_from_value(100, bin_width=bin_width, n_samples=100)\n",
    "print(f\"Sample size: {len(sample)}\")\n",
    "\n",
    "# Plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=sample,\n",
    "        name=f\"O2SatFFA\",\n",
    "        xbins=dict(start=75, end=110, size=bin_width),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    font=dict(size=10),\n",
    "    xaxis=dict(range=[80, 100]),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove AR group 60, 80\n",
    "print(f\"Removing group label: {group_labels[0]}\")\n",
    "df_trusted_drop = df[df[\"AR group\"] != group_labels[0]]\n",
    "print(f\"Initial entries: {len(df)}, after removing AR group 80: {len(df_trusted_drop)}\")\n",
    "\n",
    "\n",
    "def calc_unbiased_o2sat_prct_o2satffa(o2sat_obs, o2satffa, bin_width, n_samples):\n",
    "    unbiased_o2sat = get_unbiased_o2sat_set_from_value(o2sat_obs, bin_width, n_samples)\n",
    "    return unbiased_o2sat / o2satffa * 100\n",
    "\n",
    "\n",
    "print(\"Initially N values:\", len(df_trusted_drop))\n",
    "\n",
    "unbiased_o2sat_prct_o2satffa = df_trusted_drop.apply(\n",
    "    lambda x: calc_unbiased_o2sat_prct_o2satffa(\n",
    "        x[\"O2 Saturation\"], x[\"O2SatFFA from ecFEV1 (%)\"], bin_width=0.2, n_samples=1000\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unbiased_o2sat_prct_o2satffa_flat = np.concatenate(unbiased_o2sat_prct_o2satffa.values)\n",
    "print(\"N values:\", len(unbiased_o2sat_prct_o2satffa_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2sat_prct_o2satffa_displot(unbiased_o2sat_prct_o2satffa_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_gaussian(unbiased_o2sat_prct_o2satffa_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce hist by AR groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce the plot with the 3 AR groups\n",
    "df[\"Unbiased O2Sat % O2SatFFA\"] = df.apply(\n",
    "    lambda x: calc_unbiased_o2sat_prct_o2satffa(\n",
    "        x[\"O2 Saturation\"], x[\"O2SatFFA from ecFEV1 (%)\"], bin_width=0.2, n_samples=1000\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "import src.o2_fev1_analysis.partition as partition\n",
    "\n",
    "O2_col = \"Unbiased O2Sat % O2SatFFA\"\n",
    "\n",
    "# Cut Airway Resistance into bins of 0-20, 20-40, 40-60, 60-80\n",
    "df[\"AR group\"] = pd.cut(\n",
    "    df[\"AR from ecFEV1 (%)\"],\n",
    "    bins=np.arange(0, 100, 20),\n",
    "    include_lowest=False,\n",
    ")\n",
    "\n",
    "group_labels = df[\"AR group\"].unique()\n",
    "print(f\"AR groups: {group_labels}\")\n",
    "\n",
    "# Create subplot with 3 rows\n",
    "fig = make_subplots(\n",
    "    rows=len(group_labels) - 1, cols=1, shared_xaxes=True, vertical_spacing=0.02\n",
    ")\n",
    "# On first subplot add histogram of Drop from O2 Saturation FFA (%) for 1st AR group\n",
    "for i in range(len(group_labels) - 1):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=np.concatenate(df[df[\"AR group\"] == group_labels[i]][O2_col].values),\n",
    "            name=f\"Airway Resistance {group_labels[i]}\",\n",
    "            # Bin size of 1\n",
    "            xbins=dict(start=75, end=110, size=0.2),\n",
    "            # histnorm=\"probability density\",\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "\n",
    "title = f\"Distribution of {O2_col} for different airway resistance groups\"\n",
    "fig.update_layout(\n",
    "    title=title,\n",
    "    font=dict(size=10),\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title_text=\"Unbiased O2Sat%O2SatFFA\",\n",
    "    row=len(group_labels) - 1,\n",
    "    col=1,\n",
    ")\n",
    "# Save\n",
    "fig.write_image(f\"{plotsdir}{title}.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
